{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKvr9DC6x9QM"
   },
   "source": [
    "# Object Detection\n",
    "* 2 people in a group\n",
    "* Deadline: 10/13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zPl8L7qx9QP"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "- PASCAL VOC 2007\n",
    "  - Number of class: 20\n",
    "  - The data list is provided in the google drive. However, you have to download the training/testing data from http://host.robots.ox.ac.uk/pascal/VOC/voc2007/. \n",
    "    - Train/Val data: 5011\n",
    "        - Each row contains one image and its bounding boxes.\n",
    "        - filename ($x_{min}$, $y_{min}$, $x_{max}$, $y_{max}$, $label$) $\\times$ object_num\n",
    "        - class idx starts from 1\n",
    "    - Test data: 4951\n",
    "        - filename ($x_{min}$, $y_{min}$, $x_{max}$, $y_{max}$, $label$) $\\times$ object_num\n",
    "        - class idx starts from 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXto_Mqqx9QQ"
   },
   "source": [
    "### Loading your data into Google Colab with Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20080,
     "status": "ok",
     "timestamp": 1664613762229,
     "user": {
      "displayName": "夏宇澄",
      "userId": "12299807091212530744"
     },
     "user_tz": -480
    },
    "id": "uZ4-AYFzx9QQ",
    "outputId": "303d704d-b754-426b-8e91-5a7e34f1b342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_NUM = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knUoH4P4x9QR"
   },
   "source": [
    "## Resnet50 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1664613766309,
     "user": {
      "displayName": "夏宇澄",
      "userId": "12299807091212530744"
     },
     "user_tz": -480
    },
    "id": "ykAGukXsx9QS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "from torchvision.models.resnet import model_urls\n",
    "from torchsummary import summary\n",
    "\n",
    "class classify_bottleneck(nn.Module):\n",
    "  expansion = 1\n",
    "\n",
    "  def __init__(self, inplanes, planes, stride=1, block_type='A'):\n",
    "    super(classify_bottleneck, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=2, bias=False,dilation=2)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "    self.conv3 = nn.Conv2d(planes, planes, kernel_size=1, bias=False)\n",
    "    self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    self.downsample = nn.Sequential()\n",
    "    if stride != 1 or block_type=='B':\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(self.expansion*planes)\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = F.relu(self.bn2(self.conv2(out)))\n",
    "    out = self.bn3(self.conv3(out))\n",
    "    out += self.downsample(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "class ResNetYoloV1(nn.Module):\n",
    "\n",
    "    def __init__(self, resnet_type):\n",
    "\t\n",
    "        resnet_spec = {18: (BasicBlock, [2, 2, 2, 2], [64, 64, 128, 256, 512], 'resnet18'),\n",
    "\t\t       34: (BasicBlock, [3, 4, 6, 3], [64, 64, 128, 256, 512], 'resnet34'),\n",
    "\t\t       50: (Bottleneck, [3, 4, 6, 3], [64, 256, 512, 1024, 2048], 'resnet50'),\n",
    "\t\t       101: (Bottleneck, [3, 4, 23, 3], [64, 256, 512, 1024, 2048], 'resnet101'),\n",
    "\t\t       152: (Bottleneck, [3, 8, 36, 3], [64, 256, 512, 1024, 2048], 'resnet152')}\n",
    "        block, layers, channels, name = resnet_spec[resnet_type]\n",
    "        \n",
    "        self.name = name\n",
    "        self.inplanes = 64\n",
    "        super(ResNetYoloV1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.layer5 = self._make_classify_layer(in_channels=2048) #2048*14*14\n",
    "\n",
    "        self.conv_end = nn.Conv2d(256, 30, kernel_size=3, stride=2, padding=1, bias=False)#30*7*7\n",
    "        self.bn_end = nn.BatchNorm2d(30)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_classify_layer(self,in_channels):\n",
    "        layers = []\n",
    "        layers.append(classify_bottleneck(inplanes=in_channels, planes=256, block_type='B'))\n",
    "        layers.append(classify_bottleneck(inplanes=256, planes=256))\n",
    "        layers.append(classify_bottleneck(inplanes=256, planes=256))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "        # x4 layer output size: (B, 2048, 7, 7)\n",
    "        x5 = self.layer5(x4)\n",
    "        x = self.conv_end(x5)\n",
    "        x = self.bn_end(x)\n",
    "        x = torch.sigmoid(x) #归一化到0-1\n",
    "        # x = x.view(-1,7,7,30)\n",
    "        x = x.permute(0,2,3,1) #(-1,7,7,30)\n",
    "        return x\n",
    "\n",
    "    def init_weights(self):\n",
    "        org_resnet = torch.utils.model_zoo.load_url(model_urls[self.name])\n",
    "        # drop orginal resnet fc layer, add 'None' in case of no fc layer, that will raise error\n",
    "        org_resnet.pop('fc.weight', None)\n",
    "        org_resnet.pop('fc.bias', None)\n",
    "\n",
    "        self.load_state_dict(org_resnet)\n",
    "        print(\"Initialize resnet from model zoo\")\n",
    "\n",
    "def load_change_weights(model, model_name):\n",
    "  \n",
    "  org_resnet = torch.utils.model_zoo.load_url(model_urls[model_name])\n",
    "  org_resnet.pop('fc.weight', None)\n",
    "  org_resnet.pop('fc.bias', None)\n",
    "\n",
    "  dd = model.state_dict()\n",
    "  for k in org_resnet.keys():\n",
    "      # print(k)\n",
    "      if k in dd.keys() and not k.startswith('fc'):\n",
    "          # print('yes')\n",
    "          dd[k] = org_resnet[k]\n",
    "  model.load_state_dict(dd)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kj7b4Idx9QT"
   },
   "source": [
    "### Assignment\n",
    "You are required to build a model to perform object detection on the provided Pascal VOC dataset in this project.\n",
    "Here are some hints that help you to accomplish the project successfully.\n",
    "\n",
    "### Hints\n",
    "- YOLOv1 is the simplest and suggested model to be implemented.\n",
    "- Be careful of the normalization techniques on bounding boxes.\n",
    "    1. normalize the height and width with image size to fall into 0 and 1\n",
    "    2. x and y coordinates are parameterized to be the offsets of a particular grid cell and also bounded by 0 and 1\n",
    "- Loss function has a great impact on training stability.\n",
    "    1. loss function is the most important in this project, especially in calculating IOU\n",
    "    2. only one bounding box predictor is responsible for each object\n",
    "    3. weights for different types of losses\n",
    "    4. predict the square root of height and width instead of predicting them directly\n",
    "- Data augmentation.\n",
    "    1. It contains only 5011 images in total. Furthermore, the labels are highly imbalanced.\n",
    "    2. Random scaling and translations are applied when training YOLO.\n",
    "    3. Note that the bounding box coordinates have to be changed accordingly if the image was transformed.\n",
    "\n",
    "### Evaluation Metric\n",
    "- Please evaluate your model on Pascal VOC testing set using Mean Average Precision (mAP).\n",
    "- Write a brief report including your implementation, performance and  qualitative results(visualize bounding box on some images). \n",
    "- For more detailed explanation of mAP, please follow https://github.com/rafaelpadilla/Object-Detection-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1664613312162,
     "user": {
      "displayName": "夏宇澄",
      "userId": "12299807091212530744"
     },
     "user_tz": -480
    },
    "id": "57fbGJtQdhTA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MRA4OTgoeYy"
   },
   "source": [
    "## Dataset & data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1664613768703,
     "user": {
      "displayName": "夏宇澄",
      "userId": "12299807091212530744"
     },
     "user_tz": -480
    },
    "id": "-unQlvZTocGb"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class yoloDataset(data.Dataset):\n",
    "    image_size = 448 # Size to be aligned\n",
    "\n",
    "    # Parsing data list\n",
    "    def __init__(self,root,list_file,train,transform):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.fnames = []\n",
    "        self.boxes = []\n",
    "        self.labels = []\n",
    "        self.mean = (123,117,104) # RGB\n",
    "\n",
    "        # Cat multiple list files together.\n",
    "        '''if isinstance(list_file, list):\n",
    "            # This is especially useful for voc07/voc12 combination.\n",
    "            tmp_file = '/tmp/listfile.txt'\n",
    "            os.system('cat %s > %s' % (' '.join(list_file), tmp_file))\n",
    "            list_file = tmp_file'''\n",
    "\n",
    "        with open(list_file) as f:\n",
    "            lines  = f.readlines()\n",
    "\n",
    "        # format of each line: filename (x_min, y_min, x_max, y_max, label) * object_num\n",
    "        for line in lines:\n",
    "            splited = line.strip().split() # .strip(): reomove space, tab from the end of each line\n",
    "            self.fnames.append(splited[0])\n",
    "            num_boxes = (len(splited) - 1) // 5\n",
    "            box=[]\n",
    "            label=[]\n",
    "            for i in range(num_boxes):\n",
    "                x = float(splited[1+5*i])\n",
    "                y = float(splited[2+5*i])\n",
    "                x2 = float(splited[3+5*i])\n",
    "                y2 = float(splited[4+5*i])\n",
    "                c = splited[5+5*i]\n",
    "                box.append([x,y,x2,y2])\n",
    "                label.append(int(c)+1) # +1: since the idx start from 0\n",
    "            self.boxes.append(torch.Tensor(box))\n",
    "            self.labels.append(torch.LongTensor(label))\n",
    "        self.num_samples = len(self.boxes)\n",
    "\n",
    "    # Getting single transformed, preprocessed image and its target\n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.fnames[idx]\n",
    "        img = cv2.imread(os.path.join(self.root+fname))\n",
    "        boxes = self.boxes[idx].clone()\n",
    "        labels = self.labels[idx].clone()\n",
    "\n",
    "        # Randomly transforming image\n",
    "        if self.train:\n",
    "            #img = self.random_bright(img)\n",
    "            img, boxes = self.random_flip(img, boxes)\n",
    "            img,boxes = self.randomScale(img,boxes)\n",
    "            img = self.randomBlur(img)\n",
    "            img = self.RandomBrightness(img)\n",
    "            img = self.RandomHue(img)\n",
    "            img = self.RandomSaturation(img)\n",
    "            img,boxes,labels = self.randomShift(img,boxes,labels)\n",
    "            img,boxes,labels = self.randomCrop(img,boxes,labels)\n",
    "\n",
    "        # #debug: showing the transformed image\n",
    "        # box_show = boxes.numpy().reshape(-1)\n",
    "        # # print(box_show)\n",
    "        # img_show = self.BGR2RGB(img)\n",
    "        # pt1=(int(box_show[0]),int(box_show[1])); pt2=(int(box_show[2]),int(box_show[3]))\n",
    "        # cv2.rectangle(img_show,pt1=pt1,pt2=pt2,color=(0,255,0),thickness=1)\n",
    "        # plt.figure()\n",
    "        \n",
    "        # plt.imshow(img_show)\n",
    "        # plt.show()\n",
    "        # #debug\n",
    "\n",
    "        h,w,_ = img.shape\n",
    "        boxes /= torch.Tensor([w,h,w,h]).expand_as(boxes) \n",
    "        # .expand_as(other): expand this tensor as other\n",
    "        # [w, h, w, h] (1, 4) will be expanded to (#box, 4)\n",
    "\n",
    "        img = self.BGR2RGB(img) # because pytorch pretrained model use RGB\n",
    "        img = self.subMean(img,self.mean)\n",
    "        img = cv2.resize(img,(self.image_size,self.image_size))\n",
    "        target = self.encoder(boxes,labels) # 7x7x30, where 30 = 5*2(xywh+confidence for 2 boxes) + 20(classes)\n",
    "        for t in self.transform:\n",
    "            img = t(img)\n",
    "\n",
    "        return img,target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    # Utils\n",
    "    # Encoding the boxes, labels for single image\n",
    "    def encoder(self,boxes,labels):\n",
    "        grid_num = GRID_NUM\n",
    "        target = torch.zeros((grid_num,grid_num,30))\n",
    "        cell_size = 1./grid_num\n",
    "        wh = boxes[:,2:]-boxes[:,:2]\n",
    "        cxcy = (boxes[:,2:]+boxes[:,:2])/2\n",
    "        for i in range(cxcy.size()[0]):\n",
    "            cxcy_sample = cxcy[i]\n",
    "            ij = (cxcy_sample/cell_size).ceil()-1 #\n",
    "            target[int(ij[1]),int(ij[0]),4] = 1\n",
    "            target[int(ij[1]),int(ij[0]),9] = 1\n",
    "            target[int(ij[1]),int(ij[0]),int(labels[i])+9] = 1\n",
    "            xy = ij*cell_size # upper left coordinates of corresponding grid\n",
    "            delta_xy = (cxcy_sample -xy)/cell_size\n",
    "            target[int(ij[1]),int(ij[0]),2:4] = wh[i]\n",
    "            target[int(ij[1]),int(ij[0]),:2] = delta_xy\n",
    "            target[int(ij[1]),int(ij[0]),7:9] = wh[i]\n",
    "            target[int(ij[1]),int(ij[0]),5:7] = delta_xy\n",
    "        return target\n",
    "\n",
    "    def BGR2RGB(self,img):\n",
    "        return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    def BGR2HSV(self,img):\n",
    "        return cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    def HSV2BGR(self,img):\n",
    "        return cv2.cvtColor(img,cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    def subMean(self,bgr,mean):\n",
    "        mean = np.array(mean, dtype=np.float32)\n",
    "        bgr = bgr - mean\n",
    "        return bgr\n",
    "    \n",
    "    def RandomBrightness(self,bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h,s,v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5,1.5])\n",
    "            v = v*adjust\n",
    "            v = np.clip(v, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h,s,v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def RandomSaturation(self,bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h,s,v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5,1.5])\n",
    "            s = s*adjust\n",
    "            s = np.clip(s, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h,s,v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def RandomHue(self,bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h,s,v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5,1.5])\n",
    "            h = h*adjust\n",
    "            h = np.clip(h, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h,s,v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def randomBlur(self,bgr):\n",
    "        if random.random()<0.5:\n",
    "            bgr = cv2.blur(bgr,(5,5))\n",
    "        return bgr\n",
    "\n",
    "    def randomShift(self,bgr,boxes,labels):\n",
    "        center = (boxes[:,2:]+boxes[:,:2])/2\n",
    "        if random.random() <0.5:\n",
    "            height,width,c = bgr.shape\n",
    "            after_shfit_image = np.zeros((height,width,c),dtype=bgr.dtype)\n",
    "            after_shfit_image[:,:,:] = (104,117,123) #bgr\n",
    "            shift_x = random.uniform(-width*0.2,width*0.2)\n",
    "            shift_y = random.uniform(-height*0.2,height*0.2)\n",
    "            #print(bgr.shape,shift_x,shift_y)\n",
    "            #原图像的平移\n",
    "            if shift_x>=0 and shift_y>=0:\n",
    "                after_shfit_image[int(shift_y):,int(shift_x):,:] = bgr[:height-int(shift_y),:width-int(shift_x),:]\n",
    "            elif shift_x>=0 and shift_y<0:\n",
    "                after_shfit_image[:height+int(shift_y),int(shift_x):,:] = bgr[-int(shift_y):,:width-int(shift_x),:]\n",
    "            elif shift_x <0 and shift_y >=0:\n",
    "                after_shfit_image[int(shift_y):,:width+int(shift_x),:] = bgr[:height-int(shift_y),-int(shift_x):,:]\n",
    "            elif shift_x<0 and shift_y<0:\n",
    "                after_shfit_image[:height+int(shift_y),:width+int(shift_x),:] = bgr[-int(shift_y):,-int(shift_x):,:]\n",
    "\n",
    "            shift_xy = torch.FloatTensor([[int(shift_x),int(shift_y)]]).expand_as(center)\n",
    "            center = center + shift_xy\n",
    "            mask1 = (center[:,0] >0) & (center[:,0] < width)\n",
    "            mask2 = (center[:,1] >0) & (center[:,1] < height)\n",
    "            mask = (mask1 & mask2).view(-1,1)\n",
    "            boxes_in = boxes[mask.expand_as(boxes)].view(-1,4)\n",
    "            if len(boxes_in) == 0:\n",
    "                return bgr,boxes,labels\n",
    "            box_shift = torch.FloatTensor([[int(shift_x),int(shift_y),int(shift_x),int(shift_y)]]).expand_as(boxes_in)\n",
    "            boxes_in = boxes_in+box_shift\n",
    "            labels_in = labels[mask.view(-1)]\n",
    "            return after_shfit_image,boxes_in,labels_in\n",
    "        return bgr,boxes,labels\n",
    "\n",
    "    def randomScale(self,bgr,boxes):\n",
    "        #固定住高度，以0.8-1.2伸缩宽度，做图像形变\n",
    "        if random.random() < 0.5:\n",
    "            scale = random.uniform(0.8,1.2)\n",
    "            height,width,c = bgr.shape\n",
    "            bgr = cv2.resize(bgr,(int(width*scale),height))\n",
    "            scale_tensor = torch.FloatTensor([[scale,1,scale,1]]).expand_as(boxes)\n",
    "            boxes = boxes * scale_tensor\n",
    "            return bgr,boxes\n",
    "        return bgr,boxes\n",
    "\n",
    "    def randomCrop(self,bgr,boxes,labels):\n",
    "        if random.random() < 0.5:\n",
    "            center = (boxes[:,2:]+boxes[:,:2])/2\n",
    "            height,width,c = bgr.shape\n",
    "            h = random.uniform(0.6*height,height)\n",
    "            w = random.uniform(0.6*width,width)\n",
    "            x = random.uniform(0,width-w)\n",
    "            y = random.uniform(0,height-h)\n",
    "            x,y,h,w = int(x),int(y),int(h),int(w)\n",
    "\n",
    "            center = center - torch.FloatTensor([[x,y]]).expand_as(center)\n",
    "            mask1 = (center[:,0]>0) & (center[:,0]<w)\n",
    "            mask2 = (center[:,1]>0) & (center[:,1]<h)\n",
    "            mask = (mask1 & mask2).view(-1,1)\n",
    "\n",
    "            boxes_in = boxes[mask.expand_as(boxes)].view(-1,4)\n",
    "            if(len(boxes_in)==0):\n",
    "                return bgr,boxes,labels\n",
    "            box_shift = torch.FloatTensor([[x,y,x,y]]).expand_as(boxes_in)\n",
    "\n",
    "            boxes_in = boxes_in - box_shift\n",
    "            boxes_in[:,0]=boxes_in[:,0].clamp_(min=0,max=w)\n",
    "            boxes_in[:,2]=boxes_in[:,2].clamp_(min=0,max=w)\n",
    "            boxes_in[:,1]=boxes_in[:,1].clamp_(min=0,max=h)\n",
    "            boxes_in[:,3]=boxes_in[:,3].clamp_(min=0,max=h)\n",
    "\n",
    "            labels_in = labels[mask.view(-1)]\n",
    "            img_croped = bgr[y:y+h,x:x+w,:]\n",
    "            return img_croped,boxes_in,labels_in\n",
    "        return bgr,boxes,labels\n",
    "\n",
    "    def random_flip(self, im, boxes):\n",
    "        if random.random() < 0.5:\n",
    "            im_lr = np.fliplr(im).copy()\n",
    "            h,w,_ = im.shape\n",
    "            xmin = w - boxes[:,2]\n",
    "            xmax = w - boxes[:,0]\n",
    "            boxes[:,0] = xmin\n",
    "            boxes[:,2] = xmax\n",
    "            return im_lr, boxes\n",
    "        return im, boxes\n",
    "\n",
    "    def random_bright(self, im, delta=16): # unused\n",
    "        alpha = random.random()\n",
    "        if alpha > 0.3:\n",
    "            im = im * alpha + random.randrange(-delta,delta)\n",
    "            im = im.clip(min=0,max=255).astype(np.uint8)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KOlUUMjoobF"
   },
   "source": [
    "## Yolov1 Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1664613864126,
     "user": {
      "displayName": "夏宇澄",
      "userId": "12299807091212530744"
     },
     "user_tz": -480
    },
    "id": "kAYSQkK5oyXz"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class yolov1Loss(nn.Module):\n",
    "    def __init__(self, S, B, C, lambda_coord, lambda_noobj):\n",
    "        # Args:\n",
    "        #    S: size of grid\n",
    "        #    B: number of box\n",
    "        #    C: number of class\n",
    "        super(yolov1Loss, self).__init__()\n",
    "        self.S = S \n",
    "        self.B = B \n",
    "        self.C = C \n",
    "        self.l_coord = lambda_coord\n",
    "        self.l_noobj = lambda_noobj\n",
    "    \n",
    "    def calculateIoU(self, box1, box2):\n",
    "        # calculate the intersection over the union of two sets of boxes, each box contains [xmin,ymin,xmax,ymax]\n",
    "        # Args:\n",
    "        #    size of box1 = [n,4]\n",
    "        #    size of box2 = [m,4]\n",
    "        # Return:\n",
    "        #    size of Iou of two sets of boxes = [n,m]\n",
    "        n = box1.size(0)\n",
    "        m = box2.size(0)\n",
    "        \n",
    "        # take the max of left-bottom point and the min of right-top point \n",
    "        # to calculate the left-top point and the right-bottom point of the intersection\n",
    "        lt = torch.max(\n",
    "            box1[:,:2].unsqueeze(1).expand(n,m,2), # take [xmin,ymin]: [n,2] -> [n,1,2] -> [n,m,2]\n",
    "            box2[:,:2].unsqueeze(0).expand(n,m,2)  # take [xmin,ymin]: [m,2] -> [1,m,2] -> [n,m,2]\n",
    "        )\n",
    "        \n",
    "        rb = torch.min(\n",
    "            box1[:,2:].unsqueeze(1).expand(n,m,2), # take [xmax,ymax]: [n,2] -> [n,1,2] -> [n,m,2]\n",
    "            box2[:,2:].unsqueeze(0).expand(n,m,2)  # take [xmax,ymax]: [m,2] -> [1,m,2] -> [n,m,2]\n",
    "        )\n",
    "        \n",
    "        # calculate weight and height of intersection areas and check if intersection area is 0\n",
    "        wh = rb - lt # [n,m,2]\n",
    "        wh[wh<0] = 0 # if max_left >= min_right or max_bottom >= min_top, then there is no intersection\n",
    "        intersection = wh[:,:,0] * wh[:,:,1] # [n,m]\n",
    "        \n",
    "        area1 = (box1[:,2]-box1[:,0])*(box1[:,3]-box1[:,1])  #[n,]     \n",
    "        area2 = (box2[:,2]-box2[:,0])*(box2[:,3]-box2[:,1])  #[m,]\n",
    "        area1 = area1.unsqueeze(1).expand(n,m) # [n,] -> [n,1] -> [n,m]\n",
    "        area2 = area2.unsqueeze(0).expand(n,m) # [m,] -> [1,m] -> [n,m]\n",
    "        \n",
    "        iou = intersection / (area1 + area2 - intersection)\n",
    "        return iou\n",
    "    def forward(self, preds, targets):\n",
    "        # Args:\n",
    "        #    size of preds = [batchsize, S, S, Bx5+20]: Bx5 means each box has [x,y,w,h,c] 5 values\n",
    "        #    size of targets = [batchsize, S, S, Bx5+20]\n",
    "        S, B, C = self.S, self.B, self.C\n",
    "        N = B * 5 + C \n",
    "        batchsize = preds.size(0)\n",
    "        coord_mask = targets[:,:,:,4] > 0        \n",
    "        noobj_mask = targets[:,:,:,4] == 0\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand(batchsize, S, S, N)        \n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand(batchsize, S, S, N)\n",
    "        \n",
    "        coord_pred = preds[coord_mask].view(-1, N)\n",
    "        box_pred = coord_pred[:,:5*B].contiguous().view(-1, 5)\n",
    "        class_pred = coord_pred[:,5*B:]\n",
    "        \n",
    "        coord_target = targets[coord_mask].view(-1, N)\n",
    "        box_target = coord_target[:,:5*B].contiguous().view(-1, 5)\n",
    "        class_target = coord_target[:,5*B:]\n",
    "        \n",
    "        # compute noobj_loss: only calculate confidence loss\n",
    "        noobj_pred = preds[noobj_mask].view(-1, N)\n",
    "        noobj_target = targets[noobj_mask].view(-1, N)\n",
    "        noobj_pred_mask = torch.cuda.BoolTensor(noobj_pred.size())\n",
    "        noobj_pred_mask.zero_()\n",
    "        for b in range(B):\n",
    "            noobj_pred_mask[:, 4+b*5] = 1\n",
    "        noobj_pred_conf = noobj_pred[noobj_pred_mask]\n",
    "        noobj_target_conf = noobj_target[noobj_pred_mask]  \n",
    "        loss_noobj = F.mse_loss(noobj_pred_conf, noobj_target_conf, reduction = 'sum')\n",
    "        \n",
    "        # compute coord_loss\n",
    "        coord_response_mask = torch.cuda.BoolTensor(box_target.size()).fill_(0) # only compute the loss of the box containing the center of object\n",
    "        box_target_iou = torch.zeros(box_target.size()).cuda()\n",
    "        \n",
    "        # Choose the pred box having the highest IoU for each target boxes\n",
    "        for i in range(0, box_target.size(0), B):\n",
    "            # take all predict boxes at i-th cell\n",
    "            pred_boxes = box_pred[i:i+B]\n",
    "            pred_xyxy = Variable(torch.FloatTensor(pred_boxes.size()))\n",
    "            pred_xyxy[:, :2] = pred_boxes[:, :2]/float(S) - 0.5*pred_boxes[:,2:4]\n",
    "            pred_xyxy[:, 2:4] = pred_boxes[:, :2]/float(S) + 0.5*pred_boxes[:,2:4]   \n",
    "            \n",
    "            # take all target boxes at i-th cell\n",
    "            # Since target boxes contained by each cell are identical in current implement,thus just take the first one\n",
    "            target_boxes = box_target[i].view(-1, 5)\n",
    "            target_xyxy = Variable(torch.FloatTensor(target_boxes.size()))\n",
    "            target_xyxy[:, :2] = target_boxes[:, :2]/float(S) - 0.5*target_boxes[:,2:4]\n",
    "            target_xyxy[:, 2:4] = target_boxes[:, :2]/float(S) + 0.5*target_boxes[:,2:4]\n",
    "                                   \n",
    "            iou = self.calculateIoU(pred_xyxy[:,:4], target_xyxy[:,:4]) # [B,1]\n",
    "            max_iou, max_index = iou.max(0)\n",
    "            max_index = max_index.data.cuda()\n",
    "            \n",
    "            coord_response_mask[i+max_index] = 1\n",
    "            box_target_iou[i+max_index, torch.LongTensor([4]).cuda()] = (max_iou).data.cuda()\n",
    "        \n",
    "        # calculate the loss of the response boxes\n",
    "        box_target_iou = Variable(box_target_iou).cuda()\n",
    "        box_pred_response = box_pred[coord_response_mask].view(-1, 5)\n",
    "        box_target_response = box_target[coord_response_mask].view(-1, 5)\n",
    "        target_iou = box_target_iou[coord_response_mask].view(-1, 5)\n",
    "        loss_xy = F.mse_loss(box_pred_response[:,:2], box_target_response[:,:2], reduction = 'sum')\n",
    "        loss_wh = F.mse_loss(torch.sqrt(box_pred_response[:,2:4]), torch.sqrt(box_target_response[:,2:4]), reduction = 'sum')                \n",
    "        loss_obj = F. mse_loss(box_pred_response[:,4], target_iou[:,4], reduction = 'sum')\n",
    "        \n",
    "        # calculate the class probability loss of cells containing objects\n",
    "        loss_class = F.mse_loss(class_pred, class_target, reduction = 'sum')\n",
    "        \n",
    "        # total loss\n",
    "        loss = self.l_coord * (loss_xy + loss_wh) + loss_obj + self.l_noobj*loss_noobj + loss_class\n",
    "        loss = loss/float(batchsize)\n",
    "                                   \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCt76m6Uot_P"
   },
   "source": [
    "## Training Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "executionInfo": {
     "elapsed": 38441,
     "status": "error",
     "timestamp": 1664614708565,
     "user": {
      "displayName": "夏宇澄",
      "userId": "12299807091212530744"
     },
     "user_tz": -480
    },
    "id": "ojEJprqbx9QU",
    "outputId": "842f165a-4287-4f3f-eb99-874d5918b349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset has 3508 images\n",
      "the batch_size is 8\n",
      "Epoch [1/50], Iter [5/439] Loss: 21.6132, average_loss: 26.0365\n",
      "Epoch [1/50], Iter [10/439] Loss: 25.4903, average_loss: 23.7071\n",
      "Epoch [1/50], Iter [15/439] Loss: 17.3300, average_loss: 22.4634\n",
      "Epoch [1/50], Iter [20/439] Loss: 19.8315, average_loss: 21.8494\n",
      "Epoch [1/50], Iter [25/439] Loss: 11.3041, average_loss: 20.5039\n",
      "Epoch [1/50], Iter [30/439] Loss: 13.0496, average_loss: 19.2587\n",
      "Epoch [1/50], Iter [35/439] Loss: 11.6138, average_loss: 18.3846\n",
      "Epoch [1/50], Iter [40/439] Loss: 11.8761, average_loss: 17.5948\n",
      "Epoch [1/50], Iter [45/439] Loss: 12.5501, average_loss: 17.0116\n",
      "Epoch [1/50], Iter [50/439] Loss: 10.0672, average_loss: 16.3324\n",
      "Epoch [1/50], Iter [55/439] Loss: 8.5167, average_loss: 15.6333\n",
      "Epoch [1/50], Iter [60/439] Loss: 9.8137, average_loss: 15.0121\n",
      "Epoch [1/50], Iter [65/439] Loss: 14.0218, average_loss: 14.7331\n",
      "Epoch [1/50], Iter [70/439] Loss: 8.3046, average_loss: 14.2536\n",
      "Epoch [1/50], Iter [75/439] Loss: 7.2583, average_loss: 13.9522\n",
      "Epoch [1/50], Iter [80/439] Loss: 10.6825, average_loss: 13.7138\n",
      "Epoch [1/50], Iter [85/439] Loss: 5.0218, average_loss: 13.3090\n",
      "Epoch [1/50], Iter [90/439] Loss: 6.3879, average_loss: 13.1374\n",
      "Epoch [1/50], Iter [95/439] Loss: 7.3508, average_loss: 12.8524\n",
      "Epoch [1/50], Iter [100/439] Loss: 8.9457, average_loss: 12.6189\n",
      "Epoch [1/50], Iter [105/439] Loss: 10.2409, average_loss: 12.3700\n",
      "Epoch [1/50], Iter [110/439] Loss: 4.9926, average_loss: 12.1463\n",
      "Epoch [1/50], Iter [115/439] Loss: 11.0101, average_loss: 12.0094\n",
      "Epoch [1/50], Iter [120/439] Loss: 6.6074, average_loss: 11.7688\n",
      "Epoch [1/50], Iter [125/439] Loss: 8.6724, average_loss: 11.6435\n",
      "Epoch [1/50], Iter [130/439] Loss: 9.1648, average_loss: 11.5151\n",
      "Epoch [1/50], Iter [135/439] Loss: 7.6575, average_loss: 11.3221\n",
      "Epoch [1/50], Iter [140/439] Loss: 7.3674, average_loss: 11.2148\n",
      "Epoch [1/50], Iter [145/439] Loss: 8.4598, average_loss: 11.0820\n",
      "Epoch [1/50], Iter [150/439] Loss: 8.5023, average_loss: 10.9629\n",
      "Epoch [1/50], Iter [155/439] Loss: 5.5552, average_loss: 10.7974\n",
      "Epoch [1/50], Iter [160/439] Loss: 8.4960, average_loss: 10.6970\n",
      "Epoch [1/50], Iter [165/439] Loss: 14.3329, average_loss: 10.5955\n",
      "Epoch [1/50], Iter [170/439] Loss: 6.5490, average_loss: 10.4714\n",
      "Epoch [1/50], Iter [175/439] Loss: 6.3180, average_loss: 10.3476\n",
      "Epoch [1/50], Iter [180/439] Loss: 5.8348, average_loss: 10.2311\n",
      "Epoch [1/50], Iter [185/439] Loss: 6.5350, average_loss: 10.1698\n",
      "Epoch [1/50], Iter [190/439] Loss: 5.4493, average_loss: 10.1006\n",
      "Epoch [1/50], Iter [195/439] Loss: 6.4840, average_loss: 9.9953\n",
      "Epoch [1/50], Iter [200/439] Loss: 3.6804, average_loss: 9.8729\n",
      "Epoch [1/50], Iter [205/439] Loss: 11.5795, average_loss: 9.8192\n",
      "Epoch [1/50], Iter [210/439] Loss: 9.4726, average_loss: 9.7414\n",
      "Epoch [1/50], Iter [215/439] Loss: 4.6803, average_loss: 9.6414\n",
      "Epoch [1/50], Iter [220/439] Loss: 5.1685, average_loss: 9.5813\n",
      "Epoch [1/50], Iter [225/439] Loss: 6.1210, average_loss: 9.5167\n",
      "Epoch [1/50], Iter [230/439] Loss: 6.4814, average_loss: 9.4310\n",
      "Epoch [1/50], Iter [235/439] Loss: 4.3018, average_loss: 9.3647\n",
      "Epoch [1/50], Iter [240/439] Loss: 9.9022, average_loss: 9.3020\n",
      "Epoch [1/50], Iter [245/439] Loss: 7.1155, average_loss: 9.2492\n",
      "Epoch [1/50], Iter [250/439] Loss: 4.4819, average_loss: 9.1925\n",
      "Epoch [1/50], Iter [255/439] Loss: 7.5768, average_loss: 9.1428\n",
      "Epoch [1/50], Iter [260/439] Loss: 6.3594, average_loss: 9.0881\n",
      "Epoch [1/50], Iter [265/439] Loss: 5.5654, average_loss: 9.0228\n",
      "Epoch [1/50], Iter [270/439] Loss: 3.6539, average_loss: 8.9433\n",
      "Epoch [1/50], Iter [275/439] Loss: 4.6893, average_loss: 8.8828\n",
      "Epoch [1/50], Iter [280/439] Loss: 5.7231, average_loss: 8.8319\n",
      "Epoch [1/50], Iter [285/439] Loss: 5.3911, average_loss: 8.7902\n",
      "Epoch [1/50], Iter [290/439] Loss: 4.9887, average_loss: 8.7125\n",
      "Epoch [1/50], Iter [295/439] Loss: 6.3800, average_loss: 8.6705\n",
      "Epoch [1/50], Iter [300/439] Loss: 6.4297, average_loss: 8.6199\n",
      "Epoch [1/50], Iter [305/439] Loss: 4.8465, average_loss: 8.5735\n",
      "Epoch [1/50], Iter [310/439] Loss: 4.2655, average_loss: 8.5188\n",
      "Epoch [1/50], Iter [315/439] Loss: 7.8614, average_loss: 8.4769\n",
      "Epoch [1/50], Iter [320/439] Loss: 6.2081, average_loss: 8.4242\n",
      "Epoch [1/50], Iter [325/439] Loss: 4.1234, average_loss: 8.3812\n",
      "Epoch [1/50], Iter [330/439] Loss: 3.3482, average_loss: 8.3321\n",
      "Epoch [1/50], Iter [335/439] Loss: 4.0679, average_loss: 8.3151\n",
      "Epoch [1/50], Iter [340/439] Loss: 3.5308, average_loss: 8.2605\n",
      "Epoch [1/50], Iter [345/439] Loss: 4.7594, average_loss: 8.2022\n",
      "Epoch [1/50], Iter [350/439] Loss: 5.0897, average_loss: 8.1792\n",
      "Epoch [1/50], Iter [355/439] Loss: 8.0421, average_loss: 8.1460\n",
      "Epoch [1/50], Iter [360/439] Loss: 2.2911, average_loss: 8.0954\n",
      "Epoch [1/50], Iter [365/439] Loss: 5.8966, average_loss: 8.0340\n",
      "Epoch [1/50], Iter [370/439] Loss: 4.8550, average_loss: 7.9890\n",
      "Epoch [1/50], Iter [375/439] Loss: 6.6708, average_loss: 7.9727\n",
      "Epoch [1/50], Iter [380/439] Loss: 5.4752, average_loss: 7.9478\n",
      "Epoch [1/50], Iter [385/439] Loss: 3.3785, average_loss: 7.9133\n",
      "Epoch [1/50], Iter [390/439] Loss: 5.2530, average_loss: 7.8803\n",
      "Epoch [1/50], Iter [395/439] Loss: 5.0441, average_loss: 7.8457\n",
      "Epoch [1/50], Iter [400/439] Loss: 6.1573, average_loss: 7.8171\n",
      "Epoch [1/50], Iter [405/439] Loss: 5.7711, average_loss: 7.7849\n",
      "Epoch [1/50], Iter [410/439] Loss: 5.4024, average_loss: 7.7485\n",
      "Epoch [1/50], Iter [415/439] Loss: 3.0845, average_loss: 7.7161\n",
      "Epoch [1/50], Iter [420/439] Loss: 2.9800, average_loss: 7.6791\n",
      "Epoch [1/50], Iter [425/439] Loss: 4.1709, average_loss: 7.6451\n",
      "Epoch [1/50], Iter [430/439] Loss: 3.8675, average_loss: 7.6040\n",
      "Epoch [1/50], Iter [435/439] Loss: 3.0562, average_loss: 7.5627\n",
      "Test epoch [1/50], average_loss: 4.9576\n",
      "Epoch [2/50], Iter [5/439] Loss: 2.9111, average_loss: 4.4091\n",
      "Epoch [2/50], Iter [10/439] Loss: 7.1409, average_loss: 5.4392\n",
      "Epoch [2/50], Iter [15/439] Loss: 3.2891, average_loss: 4.9295\n",
      "Epoch [2/50], Iter [20/439] Loss: 7.1347, average_loss: 5.1553\n",
      "Epoch [2/50], Iter [25/439] Loss: 4.3387, average_loss: 5.0097\n",
      "Epoch [2/50], Iter [30/439] Loss: 4.5699, average_loss: 5.0908\n",
      "Epoch [2/50], Iter [35/439] Loss: 2.9773, average_loss: 5.0627\n",
      "Epoch [2/50], Iter [40/439] Loss: 8.4213, average_loss: 5.1439\n",
      "Epoch [2/50], Iter [45/439] Loss: 3.5072, average_loss: 5.1844\n",
      "Epoch [2/50], Iter [50/439] Loss: 4.0482, average_loss: 5.1368\n",
      "Epoch [2/50], Iter [55/439] Loss: 11.0358, average_loss: 5.3010\n",
      "Epoch [2/50], Iter [60/439] Loss: 5.3617, average_loss: 5.2245\n",
      "Epoch [2/50], Iter [65/439] Loss: 5.6026, average_loss: 5.1293\n",
      "Epoch [2/50], Iter [70/439] Loss: 8.6083, average_loss: 5.0904\n",
      "Epoch [2/50], Iter [75/439] Loss: 5.6454, average_loss: 5.1167\n",
      "Epoch [2/50], Iter [80/439] Loss: 4.7388, average_loss: 5.0828\n",
      "Epoch [2/50], Iter [85/439] Loss: 4.9807, average_loss: 5.1620\n",
      "Epoch [2/50], Iter [90/439] Loss: 4.1805, average_loss: 5.1753\n",
      "Epoch [2/50], Iter [95/439] Loss: 5.7265, average_loss: 5.2314\n",
      "Epoch [2/50], Iter [100/439] Loss: 3.1692, average_loss: 5.2136\n",
      "Epoch [2/50], Iter [105/439] Loss: 5.6091, average_loss: 5.1816\n",
      "Epoch [2/50], Iter [110/439] Loss: 5.0334, average_loss: 5.1310\n",
      "Epoch [2/50], Iter [115/439] Loss: 4.5238, average_loss: 5.1413\n",
      "Epoch [2/50], Iter [120/439] Loss: 6.5546, average_loss: 5.1575\n",
      "Epoch [2/50], Iter [125/439] Loss: 3.9777, average_loss: 5.1094\n",
      "Epoch [2/50], Iter [130/439] Loss: 3.3963, average_loss: 5.0689\n",
      "Epoch [2/50], Iter [135/439] Loss: 5.0806, average_loss: 5.0671\n",
      "Epoch [2/50], Iter [140/439] Loss: 7.0775, average_loss: 5.0877\n",
      "Epoch [2/50], Iter [145/439] Loss: 4.2281, average_loss: 5.0819\n",
      "Epoch [2/50], Iter [150/439] Loss: 5.7223, average_loss: 5.0708\n",
      "Epoch [2/50], Iter [155/439] Loss: 6.4539, average_loss: 5.0861\n",
      "Epoch [2/50], Iter [160/439] Loss: 3.9970, average_loss: 5.0535\n",
      "Epoch [2/50], Iter [165/439] Loss: 3.7839, average_loss: 5.0290\n",
      "Epoch [2/50], Iter [170/439] Loss: 2.4572, average_loss: 4.9933\n",
      "Epoch [2/50], Iter [175/439] Loss: 4.9358, average_loss: 4.9660\n",
      "Epoch [2/50], Iter [180/439] Loss: 5.5059, average_loss: 4.9453\n",
      "Epoch [2/50], Iter [185/439] Loss: 4.3302, average_loss: 4.9394\n",
      "Epoch [2/50], Iter [190/439] Loss: 5.0454, average_loss: 4.9192\n",
      "Epoch [2/50], Iter [195/439] Loss: 5.4462, average_loss: 4.9072\n",
      "Epoch [2/50], Iter [200/439] Loss: 6.1026, average_loss: 4.8919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Iter [205/439] Loss: 5.8776, average_loss: 4.8722\n",
      "Epoch [2/50], Iter [210/439] Loss: 13.9833, average_loss: 4.9117\n",
      "Epoch [2/50], Iter [215/439] Loss: 6.1498, average_loss: 4.9072\n",
      "Epoch [2/50], Iter [220/439] Loss: 4.7493, average_loss: 4.8908\n",
      "Epoch [2/50], Iter [225/439] Loss: 3.7672, average_loss: 4.8687\n",
      "Epoch [2/50], Iter [230/439] Loss: 3.5624, average_loss: 4.9070\n",
      "Epoch [2/50], Iter [235/439] Loss: 5.6912, average_loss: 4.9075\n",
      "Epoch [2/50], Iter [240/439] Loss: 2.6355, average_loss: 4.8783\n",
      "Epoch [2/50], Iter [245/439] Loss: 5.5745, average_loss: 4.8644\n",
      "Epoch [2/50], Iter [250/439] Loss: 5.7291, average_loss: 4.8574\n",
      "Epoch [2/50], Iter [255/439] Loss: 5.3537, average_loss: 4.8506\n",
      "Epoch [2/50], Iter [260/439] Loss: 4.4142, average_loss: 4.8345\n",
      "Epoch [2/50], Iter [265/439] Loss: 3.9051, average_loss: 4.8227\n",
      "Epoch [2/50], Iter [270/439] Loss: 4.5461, average_loss: 4.8122\n",
      "Epoch [2/50], Iter [275/439] Loss: 4.0995, average_loss: 4.8155\n",
      "Epoch [2/50], Iter [280/439] Loss: 3.4325, average_loss: 4.8092\n",
      "Epoch [2/50], Iter [285/439] Loss: 5.4331, average_loss: 4.8036\n",
      "Epoch [2/50], Iter [290/439] Loss: 4.4909, average_loss: 4.7895\n",
      "Epoch [2/50], Iter [295/439] Loss: 4.3451, average_loss: 4.7790\n",
      "Epoch [2/50], Iter [300/439] Loss: 5.0175, average_loss: 4.7909\n",
      "Epoch [2/50], Iter [305/439] Loss: 7.4412, average_loss: 4.7855\n",
      "Epoch [2/50], Iter [310/439] Loss: 3.3029, average_loss: 4.7757\n",
      "Epoch [2/50], Iter [315/439] Loss: 5.0060, average_loss: 4.7693\n",
      "Epoch [2/50], Iter [320/439] Loss: 3.6769, average_loss: 4.7698\n",
      "Epoch [2/50], Iter [325/439] Loss: 4.0795, average_loss: 4.7655\n",
      "Epoch [2/50], Iter [330/439] Loss: 4.3292, average_loss: 4.7495\n",
      "Epoch [2/50], Iter [335/439] Loss: 5.1160, average_loss: 4.7389\n",
      "Epoch [2/50], Iter [340/439] Loss: 5.5726, average_loss: 4.7516\n",
      "Epoch [2/50], Iter [345/439] Loss: 2.3671, average_loss: 4.7409\n",
      "Epoch [2/50], Iter [350/439] Loss: 5.1622, average_loss: 4.7385\n",
      "Epoch [2/50], Iter [355/439] Loss: 3.5977, average_loss: 4.7314\n",
      "Epoch [2/50], Iter [360/439] Loss: 5.4683, average_loss: 4.7161\n",
      "Epoch [2/50], Iter [365/439] Loss: 4.0548, average_loss: 4.7174\n",
      "Epoch [2/50], Iter [370/439] Loss: 5.2659, average_loss: 4.7078\n",
      "Epoch [2/50], Iter [375/439] Loss: 2.9254, average_loss: 4.6986\n",
      "Epoch [2/50], Iter [380/439] Loss: 3.5073, average_loss: 4.6817\n",
      "Epoch [2/50], Iter [385/439] Loss: 4.5106, average_loss: 4.6734\n",
      "Epoch [2/50], Iter [390/439] Loss: 3.7786, average_loss: 4.6671\n",
      "Epoch [2/50], Iter [395/439] Loss: 4.8325, average_loss: 4.6629\n",
      "Epoch [2/50], Iter [400/439] Loss: 4.2311, average_loss: 4.6508\n",
      "Epoch [2/50], Iter [405/439] Loss: 4.0841, average_loss: 4.6423\n",
      "Epoch [2/50], Iter [410/439] Loss: 3.4928, average_loss: 4.6335\n",
      "Epoch [2/50], Iter [415/439] Loss: 4.3167, average_loss: 4.6320\n",
      "Epoch [2/50], Iter [420/439] Loss: 5.4547, average_loss: 4.6215\n",
      "Epoch [2/50], Iter [425/439] Loss: 5.1391, average_loss: 4.6151\n",
      "Epoch [2/50], Iter [430/439] Loss: 4.2734, average_loss: 4.6109\n",
      "Epoch [2/50], Iter [435/439] Loss: 2.8540, average_loss: 4.5931\n",
      "Test epoch [2/50], average_loss: 4.0401\n",
      "Epoch [3/50], Iter [5/439] Loss: 5.9680, average_loss: 4.8804\n",
      "Epoch [3/50], Iter [10/439] Loss: 4.4471, average_loss: 5.0049\n",
      "Epoch [3/50], Iter [15/439] Loss: 4.8930, average_loss: 4.9896\n",
      "Epoch [3/50], Iter [20/439] Loss: 6.1843, average_loss: 5.5461\n",
      "Epoch [3/50], Iter [25/439] Loss: 5.3590, average_loss: 5.3847\n",
      "Epoch [3/50], Iter [30/439] Loss: 8.9912, average_loss: 5.3773\n",
      "Epoch [3/50], Iter [35/439] Loss: 4.8708, average_loss: 5.3653\n",
      "Epoch [3/50], Iter [40/439] Loss: 4.1035, average_loss: 5.3121\n",
      "Epoch [3/50], Iter [45/439] Loss: 5.3465, average_loss: 5.3559\n",
      "Epoch [3/50], Iter [50/439] Loss: 5.3080, average_loss: 5.3962\n",
      "Epoch [3/50], Iter [55/439] Loss: 2.7883, average_loss: 5.3456\n",
      "Epoch [3/50], Iter [60/439] Loss: 8.1010, average_loss: 5.5300\n",
      "Epoch [3/50], Iter [65/439] Loss: 4.1242, average_loss: 5.5504\n",
      "Epoch [3/50], Iter [70/439] Loss: 5.3685, average_loss: 5.6221\n",
      "Epoch [3/50], Iter [75/439] Loss: 4.7094, average_loss: 5.6300\n",
      "Epoch [3/50], Iter [80/439] Loss: 5.3374, average_loss: 5.6328\n",
      "Epoch [3/50], Iter [85/439] Loss: 7.2333, average_loss: 5.7211\n",
      "Epoch [3/50], Iter [90/439] Loss: 9.2113, average_loss: 5.7854\n",
      "Epoch [3/50], Iter [95/439] Loss: 3.8696, average_loss: 5.8140\n",
      "Epoch [3/50], Iter [100/439] Loss: 3.6146, average_loss: 5.7883\n",
      "Epoch [3/50], Iter [105/439] Loss: 10.1014, average_loss: 5.7743\n",
      "Epoch [3/50], Iter [110/439] Loss: 5.1274, average_loss: 5.7558\n",
      "Epoch [3/50], Iter [115/439] Loss: 5.5318, average_loss: 5.7036\n",
      "Epoch [3/50], Iter [120/439] Loss: 3.0258, average_loss: 5.6457\n",
      "Epoch [3/50], Iter [125/439] Loss: 3.8599, average_loss: 5.6232\n",
      "Epoch [3/50], Iter [130/439] Loss: 4.0840, average_loss: 5.6198\n",
      "Epoch [3/50], Iter [135/439] Loss: 2.8987, average_loss: 5.5607\n",
      "Epoch [3/50], Iter [140/439] Loss: 9.6903, average_loss: 5.6082\n",
      "Epoch [3/50], Iter [145/439] Loss: 5.1594, average_loss: 5.5765\n",
      "Epoch [3/50], Iter [150/439] Loss: 4.7855, average_loss: 5.5459\n",
      "Epoch [3/50], Iter [155/439] Loss: 5.4447, average_loss: 5.5163\n",
      "Epoch [3/50], Iter [160/439] Loss: 6.9533, average_loss: 5.5078\n",
      "Epoch [3/50], Iter [165/439] Loss: 7.1420, average_loss: 5.5058\n",
      "Epoch [3/50], Iter [170/439] Loss: 5.7342, average_loss: 5.4858\n",
      "Epoch [3/50], Iter [175/439] Loss: 4.6226, average_loss: 5.4691\n",
      "Epoch [3/50], Iter [180/439] Loss: 5.7200, average_loss: 5.4877\n",
      "Epoch [3/50], Iter [185/439] Loss: 3.7724, average_loss: 5.4377\n",
      "Epoch [3/50], Iter [190/439] Loss: 3.5224, average_loss: 5.4135\n",
      "Epoch [3/50], Iter [195/439] Loss: 3.3787, average_loss: 5.3967\n",
      "Epoch [3/50], Iter [200/439] Loss: 4.8451, average_loss: 5.3796\n",
      "Epoch [3/50], Iter [205/439] Loss: 4.3772, average_loss: 5.3637\n",
      "Epoch [3/50], Iter [210/439] Loss: 2.7895, average_loss: 5.3235\n",
      "Epoch [3/50], Iter [215/439] Loss: 4.8401, average_loss: 5.3045\n",
      "Epoch [3/50], Iter [220/439] Loss: 4.1891, average_loss: 5.3048\n",
      "Epoch [3/50], Iter [225/439] Loss: 3.8788, average_loss: 5.2775\n",
      "Epoch [3/50], Iter [230/439] Loss: 4.5603, average_loss: 5.2470\n",
      "Epoch [3/50], Iter [235/439] Loss: 4.4107, average_loss: 5.2116\n",
      "Epoch [3/50], Iter [240/439] Loss: 5.2529, average_loss: 5.2086\n",
      "Epoch [3/50], Iter [245/439] Loss: 3.8892, average_loss: 5.1821\n",
      "Epoch [3/50], Iter [250/439] Loss: 5.9604, average_loss: 5.1841\n",
      "Epoch [3/50], Iter [255/439] Loss: 3.2061, average_loss: 5.1849\n",
      "Epoch [3/50], Iter [260/439] Loss: 2.7900, average_loss: 5.1531\n",
      "Epoch [3/50], Iter [265/439] Loss: 4.6398, average_loss: 5.1331\n",
      "Epoch [3/50], Iter [270/439] Loss: 5.1524, average_loss: 5.1252\n",
      "Epoch [3/50], Iter [275/439] Loss: 3.8180, average_loss: 5.1077\n",
      "Epoch [3/50], Iter [280/439] Loss: 3.3408, average_loss: 5.0919\n",
      "Epoch [3/50], Iter [285/439] Loss: 3.6819, average_loss: 5.0721\n",
      "Epoch [3/50], Iter [290/439] Loss: 3.8744, average_loss: 5.0567\n",
      "Epoch [3/50], Iter [295/439] Loss: 4.3631, average_loss: 5.0438\n",
      "Epoch [3/50], Iter [300/439] Loss: 6.0680, average_loss: 5.0390\n",
      "Epoch [3/50], Iter [305/439] Loss: 3.3939, average_loss: 5.0267\n",
      "Epoch [3/50], Iter [310/439] Loss: 4.8041, average_loss: 5.0502\n",
      "Epoch [3/50], Iter [315/439] Loss: 4.7153, average_loss: 5.0533\n",
      "Epoch [3/50], Iter [320/439] Loss: 3.1348, average_loss: 5.0509\n",
      "Epoch [3/50], Iter [325/439] Loss: 4.1747, average_loss: 5.0347\n",
      "Epoch [3/50], Iter [330/439] Loss: 6.7073, average_loss: 5.0358\n",
      "Epoch [3/50], Iter [335/439] Loss: 4.7057, average_loss: 5.0313\n",
      "Epoch [3/50], Iter [340/439] Loss: 5.4658, average_loss: 5.0188\n",
      "Epoch [3/50], Iter [345/439] Loss: 2.8567, average_loss: 5.0057\n",
      "Epoch [3/50], Iter [350/439] Loss: 2.9789, average_loss: 4.9894\n",
      "Epoch [3/50], Iter [355/439] Loss: 3.7013, average_loss: 4.9760\n",
      "Epoch [3/50], Iter [360/439] Loss: 5.1412, average_loss: 4.9770\n",
      "Epoch [3/50], Iter [365/439] Loss: 4.2887, average_loss: 4.9634\n",
      "Epoch [3/50], Iter [370/439] Loss: 5.5917, average_loss: 4.9518\n",
      "Epoch [3/50], Iter [375/439] Loss: 2.9138, average_loss: 4.9382\n",
      "Epoch [3/50], Iter [380/439] Loss: 6.8408, average_loss: 4.9539\n",
      "Epoch [3/50], Iter [385/439] Loss: 4.4520, average_loss: 4.9502\n",
      "Epoch [3/50], Iter [390/439] Loss: 2.5639, average_loss: 4.9368\n",
      "Epoch [3/50], Iter [395/439] Loss: 6.2521, average_loss: 4.9412\n",
      "Epoch [3/50], Iter [400/439] Loss: 4.9462, average_loss: 4.9453\n",
      "Epoch [3/50], Iter [405/439] Loss: 3.0296, average_loss: 4.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Iter [410/439] Loss: 4.3775, average_loss: 4.9339\n",
      "Epoch [3/50], Iter [415/439] Loss: 5.4001, average_loss: 4.9197\n",
      "Epoch [3/50], Iter [420/439] Loss: 4.4895, average_loss: 4.9094\n",
      "Epoch [3/50], Iter [425/439] Loss: 3.1876, average_loss: 4.8934\n",
      "Epoch [3/50], Iter [430/439] Loss: 4.8344, average_loss: 4.8891\n",
      "Epoch [3/50], Iter [435/439] Loss: 4.3955, average_loss: 4.8899\n",
      "Test epoch [3/50], average_loss: 4.5011\n",
      "Epoch [4/50], Iter [5/439] Loss: 4.7474, average_loss: 4.1867\n",
      "Epoch [4/50], Iter [10/439] Loss: 5.8325, average_loss: 4.1918\n",
      "Epoch [4/50], Iter [15/439] Loss: 3.8970, average_loss: 3.9804\n",
      "Epoch [4/50], Iter [20/439] Loss: 5.4471, average_loss: 4.0658\n",
      "Epoch [4/50], Iter [25/439] Loss: 2.6288, average_loss: 4.1354\n",
      "Epoch [4/50], Iter [30/439] Loss: 5.9815, average_loss: 4.2682\n",
      "Epoch [4/50], Iter [35/439] Loss: 4.1415, average_loss: 4.4867\n",
      "Epoch [4/50], Iter [40/439] Loss: 3.4242, average_loss: 4.3572\n",
      "Epoch [4/50], Iter [45/439] Loss: 3.4776, average_loss: 4.3068\n",
      "Epoch [4/50], Iter [50/439] Loss: 5.5804, average_loss: 4.3877\n",
      "Epoch [4/50], Iter [55/439] Loss: 4.0611, average_loss: 4.3547\n",
      "Epoch [4/50], Iter [60/439] Loss: 3.6970, average_loss: 4.3994\n",
      "Epoch [4/50], Iter [65/439] Loss: 2.3334, average_loss: 4.3720\n",
      "Epoch [4/50], Iter [70/439] Loss: 2.1941, average_loss: 4.3789\n",
      "Epoch [4/50], Iter [75/439] Loss: 3.6587, average_loss: 4.3283\n",
      "Epoch [4/50], Iter [80/439] Loss: 4.4496, average_loss: 4.2969\n",
      "Epoch [4/50], Iter [85/439] Loss: 5.4595, average_loss: 4.2838\n",
      "Epoch [4/50], Iter [90/439] Loss: 3.6019, average_loss: 4.2707\n",
      "Epoch [4/50], Iter [95/439] Loss: 3.5903, average_loss: 4.2825\n",
      "Epoch [4/50], Iter [100/439] Loss: 4.4978, average_loss: 4.2745\n",
      "Epoch [4/50], Iter [105/439] Loss: 3.9736, average_loss: 4.2926\n",
      "Epoch [4/50], Iter [110/439] Loss: 5.2192, average_loss: 4.2915\n",
      "Epoch [4/50], Iter [115/439] Loss: 5.4624, average_loss: 4.3207\n",
      "Epoch [4/50], Iter [120/439] Loss: 2.8793, average_loss: 4.3247\n",
      "Epoch [4/50], Iter [125/439] Loss: 3.4641, average_loss: 4.3015\n",
      "Epoch [4/50], Iter [130/439] Loss: 5.0937, average_loss: 4.2931\n",
      "Epoch [4/50], Iter [135/439] Loss: 2.9500, average_loss: 4.2814\n",
      "Epoch [4/50], Iter [140/439] Loss: 5.2083, average_loss: 4.2887\n",
      "Epoch [4/50], Iter [145/439] Loss: 4.5434, average_loss: 4.2838\n",
      "Epoch [4/50], Iter [150/439] Loss: 2.6741, average_loss: 4.2834\n",
      "Epoch [4/50], Iter [155/439] Loss: 6.3041, average_loss: 4.2998\n",
      "Epoch [4/50], Iter [160/439] Loss: 5.1368, average_loss: 4.3331\n",
      "Epoch [4/50], Iter [165/439] Loss: 3.5971, average_loss: 4.3159\n",
      "Epoch [4/50], Iter [170/439] Loss: 3.6117, average_loss: 4.3147\n",
      "Epoch [4/50], Iter [175/439] Loss: 3.3325, average_loss: 4.3038\n",
      "Epoch [4/50], Iter [180/439] Loss: 5.4196, average_loss: 4.3076\n",
      "Epoch [4/50], Iter [185/439] Loss: 4.6695, average_loss: 4.2941\n",
      "Epoch [4/50], Iter [190/439] Loss: 5.0591, average_loss: 4.3221\n",
      "Epoch [4/50], Iter [195/439] Loss: 3.8594, average_loss: 4.3255\n",
      "Epoch [4/50], Iter [200/439] Loss: 5.0818, average_loss: 4.3321\n",
      "Epoch [4/50], Iter [205/439] Loss: 5.8340, average_loss: 4.3284\n",
      "Epoch [4/50], Iter [210/439] Loss: 3.0159, average_loss: 4.3245\n",
      "Epoch [4/50], Iter [215/439] Loss: 4.3874, average_loss: 4.3102\n",
      "Epoch [4/50], Iter [220/439] Loss: 3.2730, average_loss: 4.3236\n",
      "Epoch [4/50], Iter [225/439] Loss: 5.9292, average_loss: 4.3439\n",
      "Epoch [4/50], Iter [230/439] Loss: 3.7603, average_loss: 4.3286\n",
      "Epoch [4/50], Iter [235/439] Loss: 3.8687, average_loss: 4.3408\n",
      "Epoch [4/50], Iter [240/439] Loss: 3.2242, average_loss: 4.3352\n",
      "Epoch [4/50], Iter [245/439] Loss: 2.9957, average_loss: 4.3259\n",
      "Epoch [4/50], Iter [250/439] Loss: 2.0153, average_loss: 4.3392\n",
      "Epoch [4/50], Iter [255/439] Loss: 3.8623, average_loss: 4.3271\n",
      "Epoch [4/50], Iter [260/439] Loss: 3.4959, average_loss: 4.3309\n",
      "Epoch [4/50], Iter [265/439] Loss: 3.5130, average_loss: 4.3292\n",
      "Epoch [4/50], Iter [270/439] Loss: 5.4407, average_loss: 4.3186\n",
      "Epoch [4/50], Iter [275/439] Loss: 5.4608, average_loss: 4.3299\n",
      "Epoch [4/50], Iter [280/439] Loss: 4.9833, average_loss: 4.3320\n",
      "Epoch [4/50], Iter [285/439] Loss: 2.8146, average_loss: 4.3299\n",
      "Epoch [4/50], Iter [290/439] Loss: 5.1232, average_loss: 4.3321\n",
      "Epoch [4/50], Iter [295/439] Loss: 4.0978, average_loss: 4.3494\n",
      "Epoch [4/50], Iter [300/439] Loss: 3.2098, average_loss: 4.3476\n",
      "Epoch [4/50], Iter [305/439] Loss: 3.7191, average_loss: 4.3462\n",
      "Epoch [4/50], Iter [310/439] Loss: 3.7159, average_loss: 4.3449\n",
      "Epoch [4/50], Iter [315/439] Loss: 3.3530, average_loss: 4.3473\n",
      "Epoch [4/50], Iter [320/439] Loss: 5.6675, average_loss: 4.3437\n",
      "Epoch [4/50], Iter [325/439] Loss: 4.3763, average_loss: 4.3333\n",
      "Epoch [4/50], Iter [330/439] Loss: 2.5450, average_loss: 4.3265\n",
      "Epoch [4/50], Iter [335/439] Loss: 3.7303, average_loss: 4.3154\n",
      "Epoch [4/50], Iter [340/439] Loss: 4.4337, average_loss: 4.3080\n",
      "Epoch [4/50], Iter [345/439] Loss: 4.2918, average_loss: 4.3182\n",
      "Epoch [4/50], Iter [350/439] Loss: 4.1910, average_loss: 4.3297\n",
      "Epoch [4/50], Iter [355/439] Loss: 5.2048, average_loss: 4.3266\n",
      "Epoch [4/50], Iter [360/439] Loss: 8.5551, average_loss: 4.3395\n",
      "Epoch [4/50], Iter [365/439] Loss: 4.4024, average_loss: 4.3418\n",
      "Epoch [4/50], Iter [370/439] Loss: 2.9737, average_loss: 4.3268\n",
      "Epoch [4/50], Iter [375/439] Loss: 2.9019, average_loss: 4.3240\n",
      "Epoch [4/50], Iter [380/439] Loss: 5.1654, average_loss: 4.3298\n",
      "Epoch [4/50], Iter [385/439] Loss: 4.7363, average_loss: 4.3295\n",
      "Epoch [4/50], Iter [390/439] Loss: 4.5618, average_loss: 4.3304\n",
      "Epoch [4/50], Iter [395/439] Loss: 4.4112, average_loss: 4.3344\n",
      "Epoch [4/50], Iter [400/439] Loss: 5.4518, average_loss: 4.3325\n",
      "Epoch [4/50], Iter [405/439] Loss: 4.4842, average_loss: 4.3341\n",
      "Epoch [4/50], Iter [410/439] Loss: 5.1586, average_loss: 4.3365\n",
      "Epoch [4/50], Iter [415/439] Loss: 4.0686, average_loss: 4.3343\n",
      "Epoch [4/50], Iter [420/439] Loss: 2.3358, average_loss: 4.3321\n",
      "Epoch [4/50], Iter [425/439] Loss: 3.7465, average_loss: 4.3363\n",
      "Epoch [4/50], Iter [430/439] Loss: 4.3039, average_loss: 4.3411\n",
      "Epoch [4/50], Iter [435/439] Loss: 4.9439, average_loss: 4.3525\n",
      "Test epoch [4/50], average_loss: 4.3757\n",
      "Epoch [5/50], Iter [5/439] Loss: 2.8835, average_loss: 4.1612\n",
      "Epoch [5/50], Iter [10/439] Loss: 2.9583, average_loss: 4.1329\n",
      "Epoch [5/50], Iter [15/439] Loss: 3.1133, average_loss: 4.3207\n",
      "Epoch [5/50], Iter [20/439] Loss: 3.4626, average_loss: 4.3363\n",
      "Epoch [5/50], Iter [25/439] Loss: 5.0574, average_loss: 4.4787\n",
      "Epoch [5/50], Iter [30/439] Loss: 4.3432, average_loss: 4.4501\n",
      "Epoch [5/50], Iter [35/439] Loss: 3.5486, average_loss: 4.4290\n",
      "Epoch [5/50], Iter [40/439] Loss: 4.6976, average_loss: 4.4539\n",
      "Epoch [5/50], Iter [45/439] Loss: 3.4239, average_loss: 4.3662\n",
      "Epoch [5/50], Iter [50/439] Loss: 3.2015, average_loss: 4.3399\n",
      "Epoch [5/50], Iter [55/439] Loss: 4.2664, average_loss: 4.3455\n",
      "Epoch [5/50], Iter [60/439] Loss: 4.2256, average_loss: 4.3088\n",
      "Epoch [5/50], Iter [65/439] Loss: 5.2002, average_loss: 4.2507\n",
      "Epoch [5/50], Iter [70/439] Loss: 4.6141, average_loss: 4.2486\n",
      "Epoch [5/50], Iter [75/439] Loss: 4.1888, average_loss: 4.2356\n",
      "Epoch [5/50], Iter [80/439] Loss: 2.9775, average_loss: 4.1882\n",
      "Epoch [5/50], Iter [85/439] Loss: 3.5306, average_loss: 4.1574\n",
      "Epoch [5/50], Iter [90/439] Loss: 3.5097, average_loss: 4.2023\n",
      "Epoch [5/50], Iter [95/439] Loss: 3.8938, average_loss: 4.2224\n",
      "Epoch [5/50], Iter [100/439] Loss: 2.3514, average_loss: 4.1927\n",
      "Epoch [5/50], Iter [105/439] Loss: 7.3961, average_loss: 4.1927\n",
      "Epoch [5/50], Iter [110/439] Loss: 3.2895, average_loss: 4.2561\n",
      "Epoch [5/50], Iter [115/439] Loss: 2.5867, average_loss: 4.2355\n",
      "Epoch [5/50], Iter [120/439] Loss: 3.3877, average_loss: 4.2040\n",
      "Epoch [5/50], Iter [125/439] Loss: 4.0545, average_loss: 4.2142\n",
      "Epoch [5/50], Iter [130/439] Loss: 2.4743, average_loss: 4.1824\n",
      "Epoch [5/50], Iter [135/439] Loss: 5.4723, average_loss: 4.1814\n",
      "Epoch [5/50], Iter [140/439] Loss: 6.0103, average_loss: 4.2086\n",
      "Epoch [5/50], Iter [145/439] Loss: 7.1914, average_loss: 4.2214\n",
      "Epoch [5/50], Iter [150/439] Loss: 3.3310, average_loss: 4.2549\n",
      "Epoch [5/50], Iter [155/439] Loss: 4.4389, average_loss: 4.2363\n",
      "Epoch [5/50], Iter [160/439] Loss: 3.1964, average_loss: 4.2237\n",
      "Epoch [5/50], Iter [165/439] Loss: 8.2110, average_loss: 4.2542\n",
      "Epoch [5/50], Iter [170/439] Loss: 3.8852, average_loss: 4.2537\n",
      "Epoch [5/50], Iter [175/439] Loss: 5.2676, average_loss: 4.2478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Iter [180/439] Loss: 2.8728, average_loss: 4.2401\n",
      "Epoch [5/50], Iter [185/439] Loss: 2.8416, average_loss: 4.2318\n",
      "Epoch [5/50], Iter [190/439] Loss: 6.5832, average_loss: 4.2601\n",
      "Epoch [5/50], Iter [195/439] Loss: 2.9522, average_loss: 4.2525\n",
      "Epoch [5/50], Iter [200/439] Loss: 3.1674, average_loss: 4.2480\n",
      "Epoch [5/50], Iter [205/439] Loss: 4.1563, average_loss: 4.2448\n",
      "Epoch [5/50], Iter [210/439] Loss: 4.0507, average_loss: 4.2434\n",
      "Epoch [5/50], Iter [215/439] Loss: 6.9828, average_loss: 4.2662\n",
      "Epoch [5/50], Iter [220/439] Loss: 2.9586, average_loss: 4.2577\n",
      "Epoch [5/50], Iter [225/439] Loss: 4.1333, average_loss: 4.2639\n",
      "Epoch [5/50], Iter [230/439] Loss: 4.4361, average_loss: 4.2570\n",
      "Epoch [5/50], Iter [235/439] Loss: 3.5247, average_loss: 4.2532\n",
      "Epoch [5/50], Iter [240/439] Loss: 3.9348, average_loss: 4.2518\n",
      "Epoch [5/50], Iter [245/439] Loss: 4.7964, average_loss: 4.2454\n",
      "Epoch [5/50], Iter [250/439] Loss: 5.2504, average_loss: 4.2309\n",
      "Epoch [5/50], Iter [255/439] Loss: 2.7350, average_loss: 4.2210\n",
      "Epoch [5/50], Iter [260/439] Loss: 4.5041, average_loss: 4.2295\n",
      "Epoch [5/50], Iter [265/439] Loss: 5.5370, average_loss: 4.2333\n",
      "Epoch [5/50], Iter [270/439] Loss: 3.6890, average_loss: 4.2257\n",
      "Epoch [5/50], Iter [275/439] Loss: 4.4919, average_loss: 4.2228\n",
      "Epoch [5/50], Iter [280/439] Loss: 5.4094, average_loss: 4.2222\n",
      "Epoch [5/50], Iter [285/439] Loss: 5.2764, average_loss: 4.2323\n",
      "Epoch [5/50], Iter [290/439] Loss: 2.7573, average_loss: 4.2309\n",
      "Epoch [5/50], Iter [295/439] Loss: 3.0545, average_loss: 4.2270\n",
      "Epoch [5/50], Iter [300/439] Loss: 3.8980, average_loss: 4.2328\n",
      "Epoch [5/50], Iter [305/439] Loss: 3.3778, average_loss: 4.2272\n",
      "Epoch [5/50], Iter [310/439] Loss: 3.2938, average_loss: 4.2349\n",
      "Epoch [5/50], Iter [315/439] Loss: 7.4549, average_loss: 4.2388\n",
      "Epoch [5/50], Iter [320/439] Loss: 4.2696, average_loss: 4.2396\n",
      "Epoch [5/50], Iter [325/439] Loss: 4.2280, average_loss: 4.2473\n",
      "Epoch [5/50], Iter [330/439] Loss: 4.8445, average_loss: 4.2479\n",
      "Epoch [5/50], Iter [335/439] Loss: 5.7492, average_loss: 4.2514\n",
      "Epoch [5/50], Iter [340/439] Loss: 3.6047, average_loss: 4.2477\n",
      "Epoch [5/50], Iter [345/439] Loss: 5.5675, average_loss: 4.2623\n",
      "Epoch [5/50], Iter [350/439] Loss: 4.9593, average_loss: 4.2580\n",
      "Epoch [5/50], Iter [355/439] Loss: 4.0010, average_loss: 4.2556\n",
      "Epoch [5/50], Iter [360/439] Loss: 3.5381, average_loss: 4.2493\n",
      "Epoch [5/50], Iter [365/439] Loss: 3.2444, average_loss: 4.2445\n",
      "Epoch [5/50], Iter [370/439] Loss: 2.1308, average_loss: 4.2366\n",
      "Epoch [5/50], Iter [375/439] Loss: 3.3506, average_loss: 4.2446\n",
      "Epoch [5/50], Iter [380/439] Loss: 3.6710, average_loss: 4.2361\n",
      "Epoch [5/50], Iter [385/439] Loss: 5.6149, average_loss: 4.2376\n",
      "Epoch [5/50], Iter [390/439] Loss: 3.7683, average_loss: 4.2326\n",
      "Epoch [5/50], Iter [395/439] Loss: 4.6481, average_loss: 4.2351\n",
      "Epoch [5/50], Iter [400/439] Loss: 4.0864, average_loss: 4.2292\n",
      "Epoch [5/50], Iter [405/439] Loss: 5.7903, average_loss: 4.2391\n",
      "Epoch [5/50], Iter [410/439] Loss: 2.8333, average_loss: 4.2398\n",
      "Epoch [5/50], Iter [415/439] Loss: 5.9590, average_loss: 4.2407\n",
      "Epoch [5/50], Iter [420/439] Loss: 5.6532, average_loss: 4.2433\n",
      "Epoch [5/50], Iter [425/439] Loss: 2.7169, average_loss: 4.2436\n",
      "Epoch [5/50], Iter [430/439] Loss: 3.9824, average_loss: 4.2402\n",
      "Epoch [5/50], Iter [435/439] Loss: 3.5399, average_loss: 4.2363\n",
      "Test epoch [5/50], average_loss: 4.2887\n",
      "Epoch [6/50], Iter [5/439] Loss: 2.9266, average_loss: 3.5274\n",
      "Epoch [6/50], Iter [10/439] Loss: 2.6594, average_loss: 3.3760\n",
      "Epoch [6/50], Iter [15/439] Loss: 4.8653, average_loss: 3.5197\n",
      "Epoch [6/50], Iter [20/439] Loss: 5.1899, average_loss: 3.7380\n",
      "Epoch [6/50], Iter [25/439] Loss: 2.8891, average_loss: 3.7401\n",
      "Epoch [6/50], Iter [30/439] Loss: 3.9313, average_loss: 3.9544\n",
      "Epoch [6/50], Iter [35/439] Loss: 5.4172, average_loss: 4.0047\n",
      "Epoch [6/50], Iter [40/439] Loss: 3.9836, average_loss: 3.9993\n",
      "Epoch [6/50], Iter [45/439] Loss: 3.3385, average_loss: 3.9609\n",
      "Epoch [6/50], Iter [50/439] Loss: 3.0471, average_loss: 3.9595\n",
      "Epoch [6/50], Iter [55/439] Loss: 6.7318, average_loss: 3.9959\n",
      "Epoch [6/50], Iter [60/439] Loss: 3.4895, average_loss: 3.9922\n",
      "Epoch [6/50], Iter [65/439] Loss: 4.3888, average_loss: 4.0135\n",
      "Epoch [6/50], Iter [70/439] Loss: 3.7081, average_loss: 4.0525\n",
      "Epoch [6/50], Iter [75/439] Loss: 4.6021, average_loss: 4.0566\n",
      "Epoch [6/50], Iter [80/439] Loss: 3.3881, average_loss: 4.0598\n",
      "Epoch [6/50], Iter [85/439] Loss: 3.8110, average_loss: 4.1105\n",
      "Epoch [6/50], Iter [90/439] Loss: 3.7187, average_loss: 4.1248\n",
      "Epoch [6/50], Iter [95/439] Loss: 3.5790, average_loss: 4.1113\n",
      "Epoch [6/50], Iter [100/439] Loss: 4.2648, average_loss: 4.0963\n",
      "Epoch [6/50], Iter [105/439] Loss: 4.5663, average_loss: 4.0831\n",
      "Epoch [6/50], Iter [110/439] Loss: 3.3972, average_loss: 4.0886\n",
      "Epoch [6/50], Iter [115/439] Loss: 2.5783, average_loss: 4.0711\n",
      "Epoch [6/50], Iter [120/439] Loss: 5.2312, average_loss: 4.0965\n",
      "Epoch [6/50], Iter [125/439] Loss: 5.7956, average_loss: 4.1064\n",
      "Epoch [6/50], Iter [130/439] Loss: 3.9776, average_loss: 4.0704\n",
      "Epoch [6/50], Iter [135/439] Loss: 3.2518, average_loss: 4.0593\n",
      "Epoch [6/50], Iter [140/439] Loss: 7.1958, average_loss: 4.0723\n",
      "Epoch [6/50], Iter [145/439] Loss: 5.0415, average_loss: 4.0604\n",
      "Epoch [6/50], Iter [150/439] Loss: 3.5439, average_loss: 4.0407\n",
      "Epoch [6/50], Iter [155/439] Loss: 4.8431, average_loss: 4.0425\n",
      "Epoch [6/50], Iter [160/439] Loss: 4.4011, average_loss: 4.0600\n",
      "Epoch [6/50], Iter [165/439] Loss: 5.4837, average_loss: 4.0672\n",
      "Epoch [6/50], Iter [170/439] Loss: 2.8871, average_loss: 4.0587\n",
      "Epoch [6/50], Iter [175/439] Loss: 3.3877, average_loss: 4.0586\n",
      "Epoch [6/50], Iter [180/439] Loss: 7.6142, average_loss: 4.1028\n",
      "Epoch [6/50], Iter [185/439] Loss: 3.3042, average_loss: 4.0898\n",
      "Epoch [6/50], Iter [190/439] Loss: 6.1677, average_loss: 4.1156\n",
      "Epoch [6/50], Iter [195/439] Loss: 4.2850, average_loss: 4.1260\n",
      "Epoch [6/50], Iter [200/439] Loss: 3.8996, average_loss: 4.1313\n",
      "Epoch [6/50], Iter [205/439] Loss: 4.2791, average_loss: 4.1339\n",
      "Epoch [6/50], Iter [210/439] Loss: 5.6955, average_loss: 4.1370\n",
      "Epoch [6/50], Iter [215/439] Loss: 3.0806, average_loss: 4.1482\n",
      "Epoch [6/50], Iter [220/439] Loss: 2.6303, average_loss: 4.1365\n",
      "Epoch [6/50], Iter [225/439] Loss: 4.1674, average_loss: 4.1514\n",
      "Epoch [6/50], Iter [230/439] Loss: 3.8868, average_loss: 4.1490\n",
      "Epoch [6/50], Iter [235/439] Loss: 3.5468, average_loss: 4.1585\n",
      "Epoch [6/50], Iter [240/439] Loss: 3.9207, average_loss: 4.1514\n",
      "Epoch [6/50], Iter [245/439] Loss: 3.9203, average_loss: 4.1494\n",
      "Epoch [6/50], Iter [250/439] Loss: 6.2458, average_loss: 4.1470\n",
      "Epoch [6/50], Iter [255/439] Loss: 3.2604, average_loss: 4.1429\n",
      "Epoch [6/50], Iter [260/439] Loss: 3.5473, average_loss: 4.1459\n",
      "Epoch [6/50], Iter [265/439] Loss: 3.9383, average_loss: 4.1589\n",
      "Epoch [6/50], Iter [270/439] Loss: 4.7685, average_loss: 4.1596\n",
      "Epoch [6/50], Iter [275/439] Loss: 3.9638, average_loss: 4.1746\n",
      "Epoch [6/50], Iter [280/439] Loss: 3.6444, average_loss: 4.1669\n",
      "Epoch [6/50], Iter [285/439] Loss: 3.9661, average_loss: 4.1660\n",
      "Epoch [6/50], Iter [290/439] Loss: 3.8158, average_loss: 4.1702\n",
      "Epoch [6/50], Iter [295/439] Loss: 5.6386, average_loss: 4.1793\n",
      "Epoch [6/50], Iter [300/439] Loss: 3.7802, average_loss: 4.1867\n",
      "Epoch [6/50], Iter [305/439] Loss: 4.0058, average_loss: 4.1805\n",
      "Epoch [6/50], Iter [310/439] Loss: 3.1873, average_loss: 4.1893\n",
      "Epoch [6/50], Iter [315/439] Loss: 3.4062, average_loss: 4.1801\n",
      "Epoch [6/50], Iter [320/439] Loss: 3.0909, average_loss: 4.1753\n",
      "Epoch [6/50], Iter [325/439] Loss: 3.7165, average_loss: 4.1689\n",
      "Epoch [6/50], Iter [330/439] Loss: 3.8555, average_loss: 4.1582\n",
      "Epoch [6/50], Iter [335/439] Loss: 4.2094, average_loss: 4.1651\n",
      "Epoch [6/50], Iter [340/439] Loss: 4.0263, average_loss: 4.1704\n",
      "Epoch [6/50], Iter [345/439] Loss: 6.1935, average_loss: 4.1720\n",
      "Epoch [6/50], Iter [350/439] Loss: 5.8206, average_loss: 4.1728\n",
      "Epoch [6/50], Iter [355/439] Loss: 6.9580, average_loss: 4.1738\n",
      "Epoch [6/50], Iter [360/439] Loss: 2.4914, average_loss: 4.1674\n",
      "Epoch [6/50], Iter [365/439] Loss: 3.6777, average_loss: 4.1656\n",
      "Epoch [6/50], Iter [370/439] Loss: 3.2739, average_loss: 4.1731\n",
      "Epoch [6/50], Iter [375/439] Loss: 4.3490, average_loss: 4.1862\n",
      "Epoch [6/50], Iter [380/439] Loss: 3.9022, average_loss: 4.1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Iter [385/439] Loss: 3.2497, average_loss: 4.1839\n",
      "Epoch [6/50], Iter [390/439] Loss: 3.1011, average_loss: 4.1802\n",
      "Epoch [6/50], Iter [395/439] Loss: 3.1846, average_loss: 4.1810\n",
      "Epoch [6/50], Iter [400/439] Loss: 4.2979, average_loss: 4.1990\n",
      "Epoch [6/50], Iter [405/439] Loss: 3.6434, average_loss: 4.1917\n",
      "Epoch [6/50], Iter [410/439] Loss: 4.1010, average_loss: 4.1921\n",
      "Epoch [6/50], Iter [415/439] Loss: 6.1889, average_loss: 4.2006\n",
      "Epoch [6/50], Iter [420/439] Loss: 5.2354, average_loss: 4.1969\n",
      "Epoch [6/50], Iter [425/439] Loss: 4.0942, average_loss: 4.1944\n",
      "Epoch [6/50], Iter [430/439] Loss: 3.7007, average_loss: 4.1917\n",
      "Epoch [6/50], Iter [435/439] Loss: 3.2627, average_loss: 4.1885\n",
      "Test epoch [6/50], average_loss: 4.1927\n",
      "Epoch [7/50], Iter [5/439] Loss: 3.1097, average_loss: 4.1212\n",
      "Epoch [7/50], Iter [10/439] Loss: 4.6404, average_loss: 3.9169\n",
      "Epoch [7/50], Iter [15/439] Loss: 3.2019, average_loss: 3.7360\n",
      "Epoch [7/50], Iter [20/439] Loss: 5.0765, average_loss: 3.9166\n",
      "Epoch [7/50], Iter [25/439] Loss: 4.1874, average_loss: 3.9405\n",
      "Epoch [7/50], Iter [30/439] Loss: 4.1382, average_loss: 3.8295\n",
      "Epoch [7/50], Iter [35/439] Loss: 4.7147, average_loss: 4.0709\n",
      "Epoch [7/50], Iter [40/439] Loss: 2.9055, average_loss: 4.1226\n",
      "Epoch [7/50], Iter [45/439] Loss: 5.5221, average_loss: 4.1923\n",
      "Epoch [7/50], Iter [50/439] Loss: 2.5786, average_loss: 4.0963\n",
      "Epoch [7/50], Iter [55/439] Loss: 3.2192, average_loss: 4.1058\n",
      "Epoch [7/50], Iter [60/439] Loss: 3.6121, average_loss: 4.0815\n",
      "Epoch [7/50], Iter [65/439] Loss: 2.8199, average_loss: 4.1051\n",
      "Epoch [7/50], Iter [70/439] Loss: 3.6423, average_loss: 4.1034\n",
      "Epoch [7/50], Iter [75/439] Loss: 7.0354, average_loss: 4.2352\n",
      "Epoch [7/50], Iter [80/439] Loss: 4.5579, average_loss: 4.2643\n",
      "Epoch [7/50], Iter [85/439] Loss: 2.5697, average_loss: 4.2338\n",
      "Epoch [7/50], Iter [90/439] Loss: 7.7406, average_loss: 4.2717\n",
      "Epoch [7/50], Iter [95/439] Loss: 4.1971, average_loss: 4.3168\n",
      "Epoch [7/50], Iter [100/439] Loss: 3.8585, average_loss: 4.3142\n",
      "Epoch [7/50], Iter [105/439] Loss: 4.2416, average_loss: 4.2855\n",
      "Epoch [7/50], Iter [110/439] Loss: 5.2501, average_loss: 4.2550\n",
      "Epoch [7/50], Iter [115/439] Loss: 3.2208, average_loss: 4.2533\n",
      "Epoch [7/50], Iter [120/439] Loss: 5.1867, average_loss: 4.2332\n",
      "Epoch [7/50], Iter [125/439] Loss: 6.5932, average_loss: 4.2338\n",
      "Epoch [7/50], Iter [130/439] Loss: 3.8122, average_loss: 4.2172\n",
      "Epoch [7/50], Iter [135/439] Loss: 3.3541, average_loss: 4.2074\n",
      "Epoch [7/50], Iter [140/439] Loss: 3.0796, average_loss: 4.2230\n",
      "Epoch [7/50], Iter [145/439] Loss: 6.0006, average_loss: 4.2123\n",
      "Epoch [7/50], Iter [150/439] Loss: 3.9231, average_loss: 4.2187\n",
      "Epoch [7/50], Iter [155/439] Loss: 5.1203, average_loss: 4.2168\n",
      "Epoch [7/50], Iter [160/439] Loss: 5.5450, average_loss: 4.2277\n",
      "Epoch [7/50], Iter [165/439] Loss: 5.0924, average_loss: 4.2173\n",
      "Epoch [7/50], Iter [170/439] Loss: 2.3700, average_loss: 4.2130\n",
      "Epoch [7/50], Iter [175/439] Loss: 4.0823, average_loss: 4.1904\n",
      "Epoch [7/50], Iter [180/439] Loss: 4.2924, average_loss: 4.1920\n",
      "Epoch [7/50], Iter [185/439] Loss: 4.6215, average_loss: 4.1886\n",
      "Epoch [7/50], Iter [190/439] Loss: 3.2405, average_loss: 4.1681\n",
      "Epoch [7/50], Iter [195/439] Loss: 6.9164, average_loss: 4.1873\n",
      "Epoch [7/50], Iter [200/439] Loss: 5.8693, average_loss: 4.1870\n",
      "Epoch [7/50], Iter [205/439] Loss: 2.9486, average_loss: 4.1780\n",
      "Epoch [7/50], Iter [210/439] Loss: 3.1807, average_loss: 4.1684\n",
      "Epoch [7/50], Iter [215/439] Loss: 4.4296, average_loss: 4.1730\n",
      "Epoch [7/50], Iter [220/439] Loss: 5.6579, average_loss: 4.1814\n",
      "Epoch [7/50], Iter [225/439] Loss: 5.3427, average_loss: 4.2161\n",
      "Epoch [7/50], Iter [230/439] Loss: 5.3911, average_loss: 4.2032\n",
      "Epoch [7/50], Iter [235/439] Loss: 5.2328, average_loss: 4.2027\n",
      "Epoch [7/50], Iter [240/439] Loss: 4.3974, average_loss: 4.2244\n",
      "Epoch [7/50], Iter [245/439] Loss: 4.0445, average_loss: 4.2193\n",
      "Epoch [7/50], Iter [250/439] Loss: 3.1285, average_loss: 4.2066\n",
      "Epoch [7/50], Iter [255/439] Loss: 3.7088, average_loss: 4.2033\n",
      "Epoch [7/50], Iter [260/439] Loss: 4.6144, average_loss: 4.1846\n",
      "Epoch [7/50], Iter [265/439] Loss: 4.7401, average_loss: 4.1896\n",
      "Epoch [7/50], Iter [270/439] Loss: 3.9326, average_loss: 4.1828\n",
      "Epoch [7/50], Iter [275/439] Loss: 5.0778, average_loss: 4.1786\n",
      "Epoch [7/50], Iter [280/439] Loss: 3.5014, average_loss: 4.1725\n",
      "Epoch [7/50], Iter [285/439] Loss: 2.9411, average_loss: 4.1700\n",
      "Epoch [7/50], Iter [290/439] Loss: 3.8408, average_loss: 4.1620\n",
      "Epoch [7/50], Iter [295/439] Loss: 4.4134, average_loss: 4.1549\n",
      "Epoch [7/50], Iter [300/439] Loss: 4.1333, average_loss: 4.1514\n",
      "Epoch [7/50], Iter [305/439] Loss: 3.8715, average_loss: 4.1487\n",
      "Epoch [7/50], Iter [310/439] Loss: 2.6213, average_loss: 4.1389\n",
      "Epoch [7/50], Iter [315/439] Loss: 4.4467, average_loss: 4.1339\n",
      "Epoch [7/50], Iter [320/439] Loss: 5.3955, average_loss: 4.1305\n",
      "Epoch [7/50], Iter [325/439] Loss: 4.1985, average_loss: 4.1347\n",
      "Epoch [7/50], Iter [330/439] Loss: 5.5263, average_loss: 4.1404\n",
      "Epoch [7/50], Iter [335/439] Loss: 5.9787, average_loss: 4.1398\n",
      "Epoch [7/50], Iter [340/439] Loss: 2.7418, average_loss: 4.1308\n",
      "Epoch [7/50], Iter [345/439] Loss: 6.0166, average_loss: 4.1353\n",
      "Epoch [7/50], Iter [350/439] Loss: 3.4979, average_loss: 4.1292\n",
      "Epoch [7/50], Iter [355/439] Loss: 3.4393, average_loss: 4.1195\n",
      "Epoch [7/50], Iter [360/439] Loss: 4.5466, average_loss: 4.1251\n",
      "Epoch [7/50], Iter [365/439] Loss: 3.1218, average_loss: 4.1234\n",
      "Epoch [7/50], Iter [370/439] Loss: 3.4272, average_loss: 4.1204\n",
      "Epoch [7/50], Iter [375/439] Loss: 2.9593, average_loss: 4.1112\n",
      "Epoch [7/50], Iter [380/439] Loss: 3.7928, average_loss: 4.1112\n",
      "Epoch [7/50], Iter [385/439] Loss: 4.2468, average_loss: 4.1095\n",
      "Epoch [7/50], Iter [390/439] Loss: 7.2311, average_loss: 4.1170\n",
      "Epoch [7/50], Iter [395/439] Loss: 3.7451, average_loss: 4.1094\n",
      "Epoch [7/50], Iter [400/439] Loss: 4.1956, average_loss: 4.1103\n",
      "Epoch [7/50], Iter [405/439] Loss: 5.2334, average_loss: 4.1218\n",
      "Epoch [7/50], Iter [410/439] Loss: 3.0667, average_loss: 4.1219\n",
      "Epoch [7/50], Iter [415/439] Loss: 3.6941, average_loss: 4.1123\n",
      "Epoch [7/50], Iter [420/439] Loss: 4.4405, average_loss: 4.1044\n",
      "Epoch [7/50], Iter [425/439] Loss: 2.4075, average_loss: 4.1086\n",
      "Epoch [7/50], Iter [430/439] Loss: 4.6366, average_loss: 4.1065\n",
      "Epoch [7/50], Iter [435/439] Loss: 5.1112, average_loss: 4.1077\n",
      "Test epoch [7/50], average_loss: 4.1397\n",
      "Epoch [8/50], Iter [5/439] Loss: 3.9392, average_loss: 4.7980\n",
      "Epoch [8/50], Iter [10/439] Loss: 3.8705, average_loss: 4.3609\n",
      "Epoch [8/50], Iter [15/439] Loss: 4.0002, average_loss: 4.6966\n",
      "Epoch [8/50], Iter [20/439] Loss: 4.9659, average_loss: 4.3971\n",
      "Epoch [8/50], Iter [25/439] Loss: 7.0480, average_loss: 4.5233\n",
      "Epoch [8/50], Iter [30/439] Loss: 3.3802, average_loss: 4.6264\n",
      "Epoch [8/50], Iter [35/439] Loss: 6.9496, average_loss: 4.6355\n",
      "Epoch [8/50], Iter [40/439] Loss: 3.4533, average_loss: 4.4866\n",
      "Epoch [8/50], Iter [45/439] Loss: 3.9355, average_loss: 4.4168\n",
      "Epoch [8/50], Iter [50/439] Loss: 7.3803, average_loss: 4.5062\n",
      "Epoch [8/50], Iter [55/439] Loss: 3.7560, average_loss: 4.4755\n",
      "Epoch [8/50], Iter [60/439] Loss: 2.2984, average_loss: 4.4107\n",
      "Epoch [8/50], Iter [65/439] Loss: 3.9741, average_loss: 4.3604\n",
      "Epoch [8/50], Iter [70/439] Loss: 3.7476, average_loss: 4.3344\n",
      "Epoch [8/50], Iter [75/439] Loss: 3.2066, average_loss: 4.3187\n",
      "Epoch [8/50], Iter [80/439] Loss: 4.2771, average_loss: 4.3382\n",
      "Epoch [8/50], Iter [85/439] Loss: 4.3501, average_loss: 4.3064\n",
      "Epoch [8/50], Iter [90/439] Loss: 3.4714, average_loss: 4.2855\n",
      "Epoch [8/50], Iter [95/439] Loss: 2.9353, average_loss: 4.2521\n",
      "Epoch [8/50], Iter [100/439] Loss: 4.0739, average_loss: 4.2283\n",
      "Epoch [8/50], Iter [105/439] Loss: 3.4431, average_loss: 4.2155\n",
      "Epoch [8/50], Iter [110/439] Loss: 3.7458, average_loss: 4.2143\n",
      "Epoch [8/50], Iter [115/439] Loss: 6.3568, average_loss: 4.2256\n",
      "Epoch [8/50], Iter [120/439] Loss: 2.7968, average_loss: 4.1842\n",
      "Epoch [8/50], Iter [125/439] Loss: 4.6010, average_loss: 4.1674\n",
      "Epoch [8/50], Iter [130/439] Loss: 4.6883, average_loss: 4.2083\n",
      "Epoch [8/50], Iter [135/439] Loss: 4.7118, average_loss: 4.2146\n",
      "Epoch [8/50], Iter [140/439] Loss: 4.8435, average_loss: 4.2011\n",
      "Epoch [8/50], Iter [145/439] Loss: 3.7777, average_loss: 4.1958\n",
      "Epoch [8/50], Iter [150/439] Loss: 3.6170, average_loss: 4.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Iter [155/439] Loss: 4.3234, average_loss: 4.1810\n",
      "Epoch [8/50], Iter [160/439] Loss: 3.4602, average_loss: 4.1722\n",
      "Epoch [8/50], Iter [165/439] Loss: 4.8248, average_loss: 4.1517\n",
      "Epoch [8/50], Iter [170/439] Loss: 3.7592, average_loss: 4.1538\n",
      "Epoch [8/50], Iter [175/439] Loss: 2.1183, average_loss: 4.1736\n",
      "Epoch [8/50], Iter [180/439] Loss: 4.4522, average_loss: 4.1899\n",
      "Epoch [8/50], Iter [185/439] Loss: 5.2663, average_loss: 4.1912\n",
      "Epoch [8/50], Iter [190/439] Loss: 4.1203, average_loss: 4.1685\n",
      "Epoch [8/50], Iter [195/439] Loss: 3.8459, average_loss: 4.1843\n",
      "Epoch [8/50], Iter [200/439] Loss: 4.3848, average_loss: 4.1688\n",
      "Epoch [8/50], Iter [205/439] Loss: 4.8423, average_loss: 4.1699\n",
      "Epoch [8/50], Iter [210/439] Loss: 2.2710, average_loss: 4.1468\n",
      "Epoch [8/50], Iter [215/439] Loss: 5.0203, average_loss: 4.1591\n",
      "Epoch [8/50], Iter [220/439] Loss: 3.5428, average_loss: 4.1464\n",
      "Epoch [8/50], Iter [225/439] Loss: 6.6182, average_loss: 4.1643\n",
      "Epoch [8/50], Iter [230/439] Loss: 4.0658, average_loss: 4.1665\n",
      "Epoch [8/50], Iter [235/439] Loss: 4.9763, average_loss: 4.1582\n",
      "Epoch [8/50], Iter [240/439] Loss: 7.2411, average_loss: 4.1783\n",
      "Epoch [8/50], Iter [245/439] Loss: 4.7117, average_loss: 4.1670\n",
      "Epoch [8/50], Iter [250/439] Loss: 5.6859, average_loss: 4.1689\n",
      "Epoch [8/50], Iter [255/439] Loss: 3.5926, average_loss: 4.1788\n",
      "Epoch [8/50], Iter [260/439] Loss: 4.4187, average_loss: 4.1708\n",
      "Epoch [8/50], Iter [265/439] Loss: 4.4826, average_loss: 4.1634\n",
      "Epoch [8/50], Iter [270/439] Loss: 3.2714, average_loss: 4.1562\n",
      "Epoch [8/50], Iter [275/439] Loss: 4.0563, average_loss: 4.1539\n",
      "Epoch [8/50], Iter [280/439] Loss: 4.0659, average_loss: 4.1452\n",
      "Epoch [8/50], Iter [285/439] Loss: 5.5626, average_loss: 4.1469\n",
      "Epoch [8/50], Iter [290/439] Loss: 2.2803, average_loss: 4.1410\n",
      "Epoch [8/50], Iter [295/439] Loss: 3.4944, average_loss: 4.1272\n",
      "Epoch [8/50], Iter [300/439] Loss: 4.3902, average_loss: 4.1247\n",
      "Epoch [8/50], Iter [305/439] Loss: 3.6784, average_loss: 4.1230\n",
      "Epoch [8/50], Iter [310/439] Loss: 2.5659, average_loss: 4.1183\n",
      "Epoch [8/50], Iter [315/439] Loss: 6.6501, average_loss: 4.1291\n",
      "Epoch [8/50], Iter [320/439] Loss: 4.0121, average_loss: 4.1297\n",
      "Epoch [8/50], Iter [325/439] Loss: 5.4712, average_loss: 4.1329\n",
      "Epoch [8/50], Iter [330/439] Loss: 4.1296, average_loss: 4.1284\n",
      "Epoch [8/50], Iter [335/439] Loss: 3.2642, average_loss: 4.1202\n",
      "Epoch [8/50], Iter [340/439] Loss: 2.1758, average_loss: 4.1037\n",
      "Epoch [8/50], Iter [345/439] Loss: 2.0422, average_loss: 4.0981\n",
      "Epoch [8/50], Iter [350/439] Loss: 3.1831, average_loss: 4.0941\n",
      "Epoch [8/50], Iter [355/439] Loss: 3.4570, average_loss: 4.0935\n",
      "Epoch [8/50], Iter [360/439] Loss: 4.2515, average_loss: 4.0998\n",
      "Epoch [8/50], Iter [365/439] Loss: 2.6421, average_loss: 4.0928\n",
      "Epoch [8/50], Iter [370/439] Loss: 4.1436, average_loss: 4.0893\n",
      "Epoch [8/50], Iter [375/439] Loss: 4.9529, average_loss: 4.0960\n",
      "Epoch [8/50], Iter [380/439] Loss: 4.1257, average_loss: 4.0998\n",
      "Epoch [8/50], Iter [385/439] Loss: 3.6507, average_loss: 4.1012\n",
      "Epoch [8/50], Iter [390/439] Loss: 3.3790, average_loss: 4.0974\n",
      "Epoch [8/50], Iter [395/439] Loss: 2.0934, average_loss: 4.0865\n",
      "Epoch [8/50], Iter [400/439] Loss: 4.2817, average_loss: 4.0974\n",
      "Epoch [8/50], Iter [405/439] Loss: 5.6072, average_loss: 4.0953\n",
      "Epoch [8/50], Iter [410/439] Loss: 3.9414, average_loss: 4.0915\n",
      "Epoch [8/50], Iter [415/439] Loss: 4.1216, average_loss: 4.0861\n",
      "Epoch [8/50], Iter [420/439] Loss: 4.9766, average_loss: 4.0938\n",
      "Epoch [8/50], Iter [425/439] Loss: 6.3335, average_loss: 4.0856\n",
      "Epoch [8/50], Iter [430/439] Loss: 6.1613, average_loss: 4.0798\n",
      "Epoch [8/50], Iter [435/439] Loss: 5.8052, average_loss: 4.0804\n",
      "Test epoch [8/50], average_loss: 4.0599\n",
      "Epoch [9/50], Iter [5/439] Loss: 6.3061, average_loss: 5.2665\n",
      "Epoch [9/50], Iter [10/439] Loss: 3.6298, average_loss: 4.7758\n",
      "Epoch [9/50], Iter [15/439] Loss: 8.1113, average_loss: 4.8415\n",
      "Epoch [9/50], Iter [20/439] Loss: 4.5570, average_loss: 4.5711\n",
      "Epoch [9/50], Iter [25/439] Loss: 4.8370, average_loss: 4.4431\n",
      "Epoch [9/50], Iter [30/439] Loss: 3.4025, average_loss: 4.3463\n",
      "Epoch [9/50], Iter [35/439] Loss: 2.9991, average_loss: 4.3256\n",
      "Epoch [9/50], Iter [40/439] Loss: 2.9564, average_loss: 4.1928\n",
      "Epoch [9/50], Iter [45/439] Loss: 3.8527, average_loss: 4.1847\n",
      "Epoch [9/50], Iter [50/439] Loss: 5.0614, average_loss: 4.2163\n",
      "Epoch [9/50], Iter [55/439] Loss: 5.6423, average_loss: 4.1870\n",
      "Epoch [9/50], Iter [60/439] Loss: 3.0476, average_loss: 4.1212\n",
      "Epoch [9/50], Iter [65/439] Loss: 3.4209, average_loss: 4.0937\n",
      "Epoch [9/50], Iter [70/439] Loss: 4.4118, average_loss: 4.0562\n",
      "Epoch [9/50], Iter [75/439] Loss: 4.8379, average_loss: 4.0728\n",
      "Epoch [9/50], Iter [80/439] Loss: 4.1333, average_loss: 4.0726\n",
      "Epoch [9/50], Iter [85/439] Loss: 3.5438, average_loss: 4.0410\n",
      "Epoch [9/50], Iter [90/439] Loss: 7.5331, average_loss: 4.0278\n",
      "Epoch [9/50], Iter [95/439] Loss: 4.4167, average_loss: 3.9923\n",
      "Epoch [9/50], Iter [100/439] Loss: 2.5485, average_loss: 3.9673\n",
      "Epoch [9/50], Iter [105/439] Loss: 4.7961, average_loss: 3.9293\n",
      "Epoch [9/50], Iter [110/439] Loss: 2.8708, average_loss: 3.8906\n",
      "Epoch [9/50], Iter [115/439] Loss: 3.8863, average_loss: 3.8979\n",
      "Epoch [9/50], Iter [120/439] Loss: 5.9358, average_loss: 3.9687\n",
      "Epoch [9/50], Iter [125/439] Loss: 3.4966, average_loss: 3.9477\n",
      "Epoch [9/50], Iter [130/439] Loss: 4.9668, average_loss: 3.9347\n",
      "Epoch [9/50], Iter [135/439] Loss: 4.8209, average_loss: 3.9651\n",
      "Epoch [9/50], Iter [140/439] Loss: 5.6281, average_loss: 3.9702\n",
      "Epoch [9/50], Iter [145/439] Loss: 6.4683, average_loss: 4.0044\n",
      "Epoch [9/50], Iter [150/439] Loss: 3.8163, average_loss: 4.0245\n",
      "Epoch [9/50], Iter [155/439] Loss: 3.1737, average_loss: 4.0029\n",
      "Epoch [9/50], Iter [160/439] Loss: 4.0260, average_loss: 3.9993\n",
      "Epoch [9/50], Iter [165/439] Loss: 5.5126, average_loss: 4.0042\n",
      "Epoch [9/50], Iter [170/439] Loss: 5.3481, average_loss: 4.0046\n",
      "Epoch [9/50], Iter [175/439] Loss: 2.6823, average_loss: 3.9916\n",
      "Epoch [9/50], Iter [180/439] Loss: 3.1951, average_loss: 3.9713\n",
      "Epoch [9/50], Iter [185/439] Loss: 3.0582, average_loss: 3.9600\n",
      "Epoch [9/50], Iter [190/439] Loss: 4.7650, average_loss: 3.9527\n",
      "Epoch [9/50], Iter [195/439] Loss: 3.2789, average_loss: 3.9285\n",
      "Epoch [9/50], Iter [200/439] Loss: 4.5387, average_loss: 3.9369\n",
      "Epoch [9/50], Iter [205/439] Loss: 3.0717, average_loss: 3.9421\n",
      "Epoch [9/50], Iter [210/439] Loss: 2.3141, average_loss: 3.9290\n",
      "Epoch [9/50], Iter [215/439] Loss: 5.7349, average_loss: 3.9381\n",
      "Epoch [9/50], Iter [220/439] Loss: 3.8109, average_loss: 3.9606\n",
      "Epoch [9/50], Iter [225/439] Loss: 3.9416, average_loss: 3.9628\n",
      "Epoch [9/50], Iter [230/439] Loss: 3.4191, average_loss: 3.9693\n",
      "Epoch [9/50], Iter [235/439] Loss: 6.1198, average_loss: 3.9950\n",
      "Epoch [9/50], Iter [240/439] Loss: 4.5983, average_loss: 4.0002\n",
      "Epoch [9/50], Iter [245/439] Loss: 3.7817, average_loss: 3.9991\n",
      "Epoch [9/50], Iter [250/439] Loss: 4.4416, average_loss: 4.0135\n",
      "Epoch [9/50], Iter [255/439] Loss: 3.5531, average_loss: 4.0224\n",
      "Epoch [9/50], Iter [260/439] Loss: 3.4540, average_loss: 4.0202\n",
      "Epoch [9/50], Iter [265/439] Loss: 5.0619, average_loss: 4.0282\n",
      "Epoch [9/50], Iter [270/439] Loss: 5.0479, average_loss: 4.0285\n",
      "Epoch [9/50], Iter [275/439] Loss: 4.7659, average_loss: 4.0489\n",
      "Epoch [9/50], Iter [280/439] Loss: 3.1485, average_loss: 4.0607\n",
      "Epoch [9/50], Iter [285/439] Loss: 1.7152, average_loss: 4.0366\n",
      "Epoch [9/50], Iter [290/439] Loss: 2.9199, average_loss: 4.0289\n",
      "Epoch [9/50], Iter [295/439] Loss: 4.2774, average_loss: 4.0425\n",
      "Epoch [9/50], Iter [300/439] Loss: 3.6979, average_loss: 4.0348\n",
      "Epoch [9/50], Iter [305/439] Loss: 3.0127, average_loss: 4.0284\n",
      "Epoch [9/50], Iter [310/439] Loss: 3.7720, average_loss: 4.0270\n",
      "Epoch [9/50], Iter [315/439] Loss: 3.1561, average_loss: 4.0315\n",
      "Epoch [9/50], Iter [320/439] Loss: 2.8751, average_loss: 4.0284\n",
      "Epoch [9/50], Iter [325/439] Loss: 2.8308, average_loss: 4.0168\n",
      "Epoch [9/50], Iter [330/439] Loss: 5.5992, average_loss: 4.0349\n",
      "Epoch [9/50], Iter [335/439] Loss: 2.9823, average_loss: 4.0212\n",
      "Epoch [9/50], Iter [340/439] Loss: 4.9172, average_loss: 4.0218\n",
      "Epoch [9/50], Iter [345/439] Loss: 3.6996, average_loss: 4.0176\n",
      "Epoch [9/50], Iter [350/439] Loss: 2.0746, average_loss: 4.0066\n",
      "Epoch [9/50], Iter [355/439] Loss: 2.9730, average_loss: 4.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Iter [360/439] Loss: 2.9632, average_loss: 4.0120\n",
      "Epoch [9/50], Iter [365/439] Loss: 5.7117, average_loss: 4.0238\n",
      "Epoch [9/50], Iter [370/439] Loss: 3.4163, average_loss: 4.0236\n",
      "Epoch [9/50], Iter [375/439] Loss: 3.4482, average_loss: 4.0257\n",
      "Epoch [9/50], Iter [380/439] Loss: 3.2873, average_loss: 4.0255\n",
      "Epoch [9/50], Iter [385/439] Loss: 2.8152, average_loss: 4.0234\n",
      "Epoch [9/50], Iter [390/439] Loss: 2.8963, average_loss: 4.0071\n",
      "Epoch [9/50], Iter [395/439] Loss: 4.5371, average_loss: 4.0053\n",
      "Epoch [9/50], Iter [400/439] Loss: 3.8095, average_loss: 4.0093\n",
      "Epoch [9/50], Iter [405/439] Loss: 2.8692, average_loss: 4.0008\n",
      "Epoch [9/50], Iter [410/439] Loss: 6.9277, average_loss: 4.0092\n",
      "Epoch [9/50], Iter [415/439] Loss: 3.8618, average_loss: 4.0079\n",
      "Epoch [9/50], Iter [420/439] Loss: 2.7960, average_loss: 4.0022\n",
      "Epoch [9/50], Iter [425/439] Loss: 5.3797, average_loss: 4.0036\n",
      "Epoch [9/50], Iter [430/439] Loss: 4.2384, average_loss: 4.0023\n",
      "Epoch [9/50], Iter [435/439] Loss: 2.7785, average_loss: 3.9957\n",
      "Test epoch [9/50], average_loss: 4.1074\n",
      "Epoch [10/50], Iter [5/439] Loss: 4.1810, average_loss: 4.9606\n",
      "Epoch [10/50], Iter [10/439] Loss: 4.2321, average_loss: 4.7090\n",
      "Epoch [10/50], Iter [15/439] Loss: 2.7530, average_loss: 4.2833\n",
      "Epoch [10/50], Iter [20/439] Loss: 4.4851, average_loss: 4.3015\n",
      "Epoch [10/50], Iter [25/439] Loss: 5.6345, average_loss: 4.2425\n",
      "Epoch [10/50], Iter [30/439] Loss: 2.9515, average_loss: 4.1703\n",
      "Epoch [10/50], Iter [35/439] Loss: 2.8021, average_loss: 4.1042\n",
      "Epoch [10/50], Iter [40/439] Loss: 2.7486, average_loss: 3.9858\n",
      "Epoch [10/50], Iter [45/439] Loss: 4.2404, average_loss: 4.0536\n",
      "Epoch [10/50], Iter [50/439] Loss: 3.7387, average_loss: 3.9758\n",
      "Epoch [10/50], Iter [55/439] Loss: 2.6319, average_loss: 3.9732\n",
      "Epoch [10/50], Iter [60/439] Loss: 6.9418, average_loss: 4.0850\n",
      "Epoch [10/50], Iter [65/439] Loss: 2.4040, average_loss: 4.0470\n",
      "Epoch [10/50], Iter [70/439] Loss: 3.3441, average_loss: 4.0776\n",
      "Epoch [10/50], Iter [75/439] Loss: 3.4397, average_loss: 4.0763\n",
      "Epoch [10/50], Iter [80/439] Loss: 3.1332, average_loss: 4.0477\n",
      "Epoch [10/50], Iter [85/439] Loss: 4.5876, average_loss: 4.0495\n",
      "Epoch [10/50], Iter [90/439] Loss: 3.3070, average_loss: 4.0259\n",
      "Epoch [10/50], Iter [95/439] Loss: 3.8134, average_loss: 3.9975\n",
      "Epoch [10/50], Iter [100/439] Loss: 4.9251, average_loss: 3.9922\n",
      "Epoch [10/50], Iter [105/439] Loss: 3.6570, average_loss: 3.9784\n",
      "Epoch [10/50], Iter [110/439] Loss: 3.7044, average_loss: 3.9580\n",
      "Epoch [10/50], Iter [115/439] Loss: 3.0923, average_loss: 3.9461\n",
      "Epoch [10/50], Iter [120/439] Loss: 2.7060, average_loss: 3.9032\n",
      "Epoch [10/50], Iter [125/439] Loss: 3.1615, average_loss: 3.8908\n",
      "Epoch [10/50], Iter [130/439] Loss: 3.0630, average_loss: 3.8562\n",
      "Epoch [10/50], Iter [135/439] Loss: 3.2515, average_loss: 3.8361\n",
      "Epoch [10/50], Iter [140/439] Loss: 3.7817, average_loss: 3.8405\n",
      "Epoch [10/50], Iter [145/439] Loss: 3.1737, average_loss: 3.8367\n",
      "Epoch [10/50], Iter [150/439] Loss: 3.6923, average_loss: 3.8397\n",
      "Epoch [10/50], Iter [155/439] Loss: 3.4404, average_loss: 3.8344\n",
      "Epoch [10/50], Iter [160/439] Loss: 4.2448, average_loss: 3.8468\n",
      "Epoch [10/50], Iter [165/439] Loss: 4.7109, average_loss: 3.8805\n",
      "Epoch [10/50], Iter [170/439] Loss: 4.9219, average_loss: 3.8697\n",
      "Epoch [10/50], Iter [175/439] Loss: 4.7188, average_loss: 3.8932\n",
      "Epoch [10/50], Iter [180/439] Loss: 5.7326, average_loss: 3.9092\n",
      "Epoch [10/50], Iter [185/439] Loss: 4.8496, average_loss: 3.9047\n",
      "Epoch [10/50], Iter [190/439] Loss: 5.1491, average_loss: 3.9183\n",
      "Epoch [10/50], Iter [195/439] Loss: 3.2739, average_loss: 3.9195\n",
      "Epoch [10/50], Iter [200/439] Loss: 3.5325, average_loss: 3.9185\n",
      "Epoch [10/50], Iter [205/439] Loss: 5.6422, average_loss: 3.9416\n",
      "Epoch [10/50], Iter [210/439] Loss: 2.9449, average_loss: 3.9354\n",
      "Epoch [10/50], Iter [215/439] Loss: 4.5323, average_loss: 3.9558\n",
      "Epoch [10/50], Iter [220/439] Loss: 3.4880, average_loss: 3.9407\n",
      "Epoch [10/50], Iter [225/439] Loss: 5.5173, average_loss: 3.9301\n",
      "Epoch [10/50], Iter [230/439] Loss: 4.0784, average_loss: 3.9320\n",
      "Epoch [10/50], Iter [235/439] Loss: 3.5547, average_loss: 3.9325\n",
      "Epoch [10/50], Iter [240/439] Loss: 4.0633, average_loss: 3.9342\n",
      "Epoch [10/50], Iter [245/439] Loss: 2.0629, average_loss: 3.9340\n",
      "Epoch [10/50], Iter [250/439] Loss: 2.7370, average_loss: 3.9307\n",
      "Epoch [10/50], Iter [255/439] Loss: 4.5863, average_loss: 3.9374\n",
      "Epoch [10/50], Iter [260/439] Loss: 2.8096, average_loss: 3.9409\n",
      "Epoch [10/50], Iter [265/439] Loss: 4.0526, average_loss: 3.9423\n",
      "Epoch [10/50], Iter [270/439] Loss: 4.8940, average_loss: 3.9431\n",
      "Epoch [10/50], Iter [275/439] Loss: 2.5721, average_loss: 3.9441\n",
      "Epoch [10/50], Iter [280/439] Loss: 9.1884, average_loss: 3.9604\n",
      "Epoch [10/50], Iter [285/439] Loss: 3.7978, average_loss: 3.9633\n",
      "Epoch [10/50], Iter [290/439] Loss: 4.0487, average_loss: 3.9657\n",
      "Epoch [10/50], Iter [295/439] Loss: 4.6211, average_loss: 3.9713\n",
      "Epoch [10/50], Iter [300/439] Loss: 3.9432, average_loss: 3.9705\n",
      "Epoch [10/50], Iter [305/439] Loss: 5.1191, average_loss: 3.9690\n",
      "Epoch [10/50], Iter [310/439] Loss: 2.4801, average_loss: 3.9640\n",
      "Epoch [10/50], Iter [315/439] Loss: 4.6225, average_loss: 3.9794\n",
      "Epoch [10/50], Iter [320/439] Loss: 5.6867, average_loss: 3.9782\n",
      "Epoch [10/50], Iter [325/439] Loss: 5.6826, average_loss: 3.9874\n",
      "Epoch [10/50], Iter [330/439] Loss: 4.1226, average_loss: 3.9979\n",
      "Epoch [10/50], Iter [335/439] Loss: 3.7889, average_loss: 4.0009\n",
      "Epoch [10/50], Iter [340/439] Loss: 2.9754, average_loss: 4.0146\n",
      "Epoch [10/50], Iter [345/439] Loss: 4.0123, average_loss: 4.0129\n",
      "Epoch [10/50], Iter [350/439] Loss: 3.4660, average_loss: 4.0178\n",
      "Epoch [10/50], Iter [355/439] Loss: 3.6551, average_loss: 4.0064\n",
      "Epoch [10/50], Iter [360/439] Loss: 3.9892, average_loss: 4.0056\n",
      "Epoch [10/50], Iter [365/439] Loss: 4.1160, average_loss: 4.0056\n",
      "Epoch [10/50], Iter [370/439] Loss: 3.8853, average_loss: 4.0051\n",
      "Epoch [10/50], Iter [375/439] Loss: 2.5317, average_loss: 3.9989\n",
      "Epoch [10/50], Iter [380/439] Loss: 2.4931, average_loss: 4.0018\n",
      "Epoch [10/50], Iter [385/439] Loss: 5.1011, average_loss: 4.0007\n",
      "Epoch [10/50], Iter [390/439] Loss: 3.7551, average_loss: 4.0034\n",
      "Epoch [10/50], Iter [395/439] Loss: 4.6392, average_loss: 4.0126\n",
      "Epoch [10/50], Iter [400/439] Loss: 5.6554, average_loss: 4.0144\n",
      "Epoch [10/50], Iter [405/439] Loss: 4.2442, average_loss: 4.0124\n",
      "Epoch [10/50], Iter [410/439] Loss: 3.0908, average_loss: 4.0042\n",
      "Epoch [10/50], Iter [415/439] Loss: 3.9611, average_loss: 4.0018\n",
      "Epoch [10/50], Iter [420/439] Loss: 4.4519, average_loss: 3.9988\n",
      "Epoch [10/50], Iter [425/439] Loss: 2.4061, average_loss: 3.9926\n",
      "Epoch [10/50], Iter [430/439] Loss: 3.0617, average_loss: 3.9891\n",
      "Epoch [10/50], Iter [435/439] Loss: 2.7903, average_loss: 3.9871\n",
      "Test epoch [10/50], average_loss: 4.0103\n",
      "Epoch [11/50], Iter [5/439] Loss: 2.5754, average_loss: 3.3830\n",
      "Epoch [11/50], Iter [10/439] Loss: 4.6397, average_loss: 3.7395\n",
      "Epoch [11/50], Iter [15/439] Loss: 3.1776, average_loss: 3.6822\n",
      "Epoch [11/50], Iter [20/439] Loss: 4.3381, average_loss: 3.7232\n",
      "Epoch [11/50], Iter [25/439] Loss: 5.7804, average_loss: 3.8570\n",
      "Epoch [11/50], Iter [30/439] Loss: 3.4426, average_loss: 3.9124\n",
      "Epoch [11/50], Iter [35/439] Loss: 3.7400, average_loss: 3.9427\n",
      "Epoch [11/50], Iter [40/439] Loss: 3.9770, average_loss: 3.9056\n",
      "Epoch [11/50], Iter [45/439] Loss: 2.2539, average_loss: 3.8577\n",
      "Epoch [11/50], Iter [50/439] Loss: 3.8050, average_loss: 3.8371\n",
      "Epoch [11/50], Iter [55/439] Loss: 2.8230, average_loss: 3.7886\n",
      "Epoch [11/50], Iter [60/439] Loss: 5.0207, average_loss: 3.9276\n",
      "Epoch [11/50], Iter [65/439] Loss: 3.2592, average_loss: 3.9189\n",
      "Epoch [11/50], Iter [70/439] Loss: 4.4344, average_loss: 3.9629\n",
      "Epoch [11/50], Iter [75/439] Loss: 4.2558, average_loss: 3.9778\n",
      "Epoch [11/50], Iter [80/439] Loss: 4.1906, average_loss: 4.0464\n",
      "Epoch [11/50], Iter [85/439] Loss: 2.7453, average_loss: 4.0577\n",
      "Epoch [11/50], Iter [90/439] Loss: 5.2421, average_loss: 4.0759\n",
      "Epoch [11/50], Iter [95/439] Loss: 3.9795, average_loss: 4.0696\n",
      "Epoch [11/50], Iter [100/439] Loss: 3.5925, average_loss: 4.0407\n",
      "Epoch [11/50], Iter [105/439] Loss: 2.1404, average_loss: 4.0004\n",
      "Epoch [11/50], Iter [110/439] Loss: 2.4891, average_loss: 4.0081\n",
      "Epoch [11/50], Iter [115/439] Loss: 3.9014, average_loss: 4.0223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Iter [120/439] Loss: 4.9250, average_loss: 4.0033\n",
      "Epoch [11/50], Iter [125/439] Loss: 3.9795, average_loss: 4.0413\n",
      "Epoch [11/50], Iter [130/439] Loss: 3.0353, average_loss: 4.0286\n",
      "Epoch [11/50], Iter [135/439] Loss: 2.9878, average_loss: 4.0081\n",
      "Epoch [11/50], Iter [140/439] Loss: 3.1401, average_loss: 3.9806\n",
      "Epoch [11/50], Iter [145/439] Loss: 2.7247, average_loss: 3.9540\n",
      "Epoch [11/50], Iter [150/439] Loss: 3.0643, average_loss: 3.9660\n",
      "Epoch [11/50], Iter [155/439] Loss: 3.7457, average_loss: 3.9358\n",
      "Epoch [11/50], Iter [160/439] Loss: 3.6332, average_loss: 3.9094\n",
      "Epoch [11/50], Iter [165/439] Loss: 2.6581, average_loss: 3.9068\n",
      "Epoch [11/50], Iter [170/439] Loss: 3.5211, average_loss: 3.9099\n",
      "Epoch [11/50], Iter [175/439] Loss: 6.8415, average_loss: 3.9143\n",
      "Epoch [11/50], Iter [180/439] Loss: 2.8163, average_loss: 3.9039\n",
      "Epoch [11/50], Iter [185/439] Loss: 2.5366, average_loss: 3.8941\n",
      "Epoch [11/50], Iter [190/439] Loss: 4.4872, average_loss: 3.8867\n",
      "Epoch [11/50], Iter [195/439] Loss: 3.7052, average_loss: 3.8781\n",
      "Epoch [11/50], Iter [200/439] Loss: 4.8463, average_loss: 3.8972\n",
      "Epoch [11/50], Iter [205/439] Loss: 3.7144, average_loss: 3.8818\n",
      "Epoch [11/50], Iter [210/439] Loss: 3.9571, average_loss: 3.8868\n",
      "Epoch [11/50], Iter [215/439] Loss: 2.6968, average_loss: 3.8693\n",
      "Epoch [11/50], Iter [220/439] Loss: 3.8799, average_loss: 3.8809\n",
      "Epoch [11/50], Iter [225/439] Loss: 6.1528, average_loss: 3.8863\n",
      "Epoch [11/50], Iter [230/439] Loss: 3.5183, average_loss: 3.8846\n",
      "Epoch [11/50], Iter [235/439] Loss: 2.8772, average_loss: 3.8928\n",
      "Epoch [11/50], Iter [240/439] Loss: 3.1530, average_loss: 3.8942\n",
      "Epoch [11/50], Iter [245/439] Loss: 4.1021, average_loss: 3.8873\n",
      "Epoch [11/50], Iter [250/439] Loss: 3.1825, average_loss: 3.8852\n",
      "Epoch [11/50], Iter [255/439] Loss: 4.9276, average_loss: 3.9006\n",
      "Epoch [11/50], Iter [260/439] Loss: 3.4888, average_loss: 3.9282\n",
      "Epoch [11/50], Iter [265/439] Loss: 3.4810, average_loss: 3.9202\n",
      "Epoch [11/50], Iter [270/439] Loss: 3.6114, average_loss: 3.9209\n",
      "Epoch [11/50], Iter [275/439] Loss: 3.2483, average_loss: 3.9148\n",
      "Epoch [11/50], Iter [280/439] Loss: 6.9083, average_loss: 3.9259\n",
      "Epoch [11/50], Iter [285/439] Loss: 4.1887, average_loss: 3.9273\n",
      "Epoch [11/50], Iter [290/439] Loss: 4.3164, average_loss: 3.9291\n",
      "Epoch [11/50], Iter [295/439] Loss: 2.9496, average_loss: 3.9297\n",
      "Epoch [11/50], Iter [300/439] Loss: 3.4980, average_loss: 3.9249\n",
      "Epoch [11/50], Iter [305/439] Loss: 4.3740, average_loss: 3.9207\n",
      "Epoch [11/50], Iter [310/439] Loss: 3.4786, average_loss: 3.9214\n",
      "Epoch [11/50], Iter [315/439] Loss: 5.1174, average_loss: 3.9154\n",
      "Epoch [11/50], Iter [320/439] Loss: 2.8637, average_loss: 3.9175\n",
      "Epoch [11/50], Iter [325/439] Loss: 4.2814, average_loss: 3.9330\n",
      "Epoch [11/50], Iter [330/439] Loss: 2.4286, average_loss: 3.9160\n",
      "Epoch [11/50], Iter [335/439] Loss: 3.8558, average_loss: 3.9076\n",
      "Epoch [11/50], Iter [340/439] Loss: 3.6659, average_loss: 3.9186\n",
      "Epoch [11/50], Iter [345/439] Loss: 3.6101, average_loss: 3.9170\n",
      "Epoch [11/50], Iter [350/439] Loss: 2.7256, average_loss: 3.9102\n",
      "Epoch [11/50], Iter [355/439] Loss: 3.5099, average_loss: 3.9225\n",
      "Epoch [11/50], Iter [360/439] Loss: 4.9038, average_loss: 3.9362\n",
      "Epoch [11/50], Iter [365/439] Loss: 4.3776, average_loss: 3.9455\n",
      "Epoch [11/50], Iter [370/439] Loss: 3.0936, average_loss: 3.9442\n",
      "Epoch [11/50], Iter [375/439] Loss: 2.8454, average_loss: 3.9390\n",
      "Epoch [11/50], Iter [380/439] Loss: 3.6472, average_loss: 3.9515\n",
      "Epoch [11/50], Iter [385/439] Loss: 2.9480, average_loss: 3.9521\n",
      "Epoch [11/50], Iter [390/439] Loss: 4.6334, average_loss: 3.9545\n",
      "Epoch [11/50], Iter [395/439] Loss: 3.3517, average_loss: 3.9512\n",
      "Epoch [11/50], Iter [400/439] Loss: 3.7957, average_loss: 3.9479\n",
      "Epoch [11/50], Iter [405/439] Loss: 3.7073, average_loss: 3.9426\n",
      "Epoch [11/50], Iter [410/439] Loss: 2.5640, average_loss: 3.9475\n",
      "Epoch [11/50], Iter [415/439] Loss: 4.5969, average_loss: 3.9477\n",
      "Epoch [11/50], Iter [420/439] Loss: 3.9532, average_loss: 3.9485\n",
      "Epoch [11/50], Iter [425/439] Loss: 2.3717, average_loss: 3.9502\n",
      "Epoch [11/50], Iter [430/439] Loss: 2.4222, average_loss: 3.9450\n",
      "Epoch [11/50], Iter [435/439] Loss: 3.8073, average_loss: 3.9417\n",
      "Test epoch [11/50], average_loss: 3.9761\n",
      "Epoch [12/50], Iter [5/439] Loss: 5.8987, average_loss: 4.2316\n",
      "Epoch [12/50], Iter [10/439] Loss: 4.1791, average_loss: 4.1518\n",
      "Epoch [12/50], Iter [15/439] Loss: 3.2282, average_loss: 4.0202\n",
      "Epoch [12/50], Iter [20/439] Loss: 2.7655, average_loss: 3.9436\n",
      "Epoch [12/50], Iter [25/439] Loss: 7.4860, average_loss: 4.0196\n",
      "Epoch [12/50], Iter [30/439] Loss: 4.2412, average_loss: 4.0155\n",
      "Epoch [12/50], Iter [35/439] Loss: 2.7175, average_loss: 4.0090\n",
      "Epoch [12/50], Iter [40/439] Loss: 3.4740, average_loss: 4.0158\n",
      "Epoch [12/50], Iter [45/439] Loss: 3.2375, average_loss: 3.9862\n",
      "Epoch [12/50], Iter [50/439] Loss: 3.3669, average_loss: 4.0453\n",
      "Epoch [12/50], Iter [55/439] Loss: 4.8729, average_loss: 3.9986\n",
      "Epoch [12/50], Iter [60/439] Loss: 5.0813, average_loss: 4.0311\n",
      "Epoch [12/50], Iter [65/439] Loss: 3.3009, average_loss: 4.0314\n",
      "Epoch [12/50], Iter [70/439] Loss: 5.3427, average_loss: 4.0708\n",
      "Epoch [12/50], Iter [75/439] Loss: 3.8823, average_loss: 4.0499\n",
      "Epoch [12/50], Iter [80/439] Loss: 3.5909, average_loss: 4.0244\n",
      "Epoch [12/50], Iter [85/439] Loss: 5.8580, average_loss: 4.0187\n",
      "Epoch [12/50], Iter [90/439] Loss: 3.5966, average_loss: 3.9840\n",
      "Epoch [12/50], Iter [95/439] Loss: 3.5414, average_loss: 3.9702\n",
      "Epoch [12/50], Iter [100/439] Loss: 2.8825, average_loss: 3.9466\n",
      "Epoch [12/50], Iter [105/439] Loss: 2.3660, average_loss: 3.9185\n",
      "Epoch [12/50], Iter [110/439] Loss: 4.5371, average_loss: 3.9164\n",
      "Epoch [12/50], Iter [115/439] Loss: 3.0945, average_loss: 3.9000\n",
      "Epoch [12/50], Iter [120/439] Loss: 5.4053, average_loss: 3.9270\n",
      "Epoch [12/50], Iter [125/439] Loss: 2.1102, average_loss: 3.9421\n",
      "Epoch [12/50], Iter [130/439] Loss: 4.0728, average_loss: 3.9629\n",
      "Epoch [12/50], Iter [135/439] Loss: 3.7520, average_loss: 3.9474\n",
      "Epoch [12/50], Iter [140/439] Loss: 2.7835, average_loss: 3.9271\n",
      "Epoch [12/50], Iter [145/439] Loss: 4.1639, average_loss: 3.9339\n",
      "Epoch [12/50], Iter [150/439] Loss: 5.7666, average_loss: 3.9300\n",
      "Epoch [12/50], Iter [155/439] Loss: 3.9214, average_loss: 3.9263\n",
      "Epoch [12/50], Iter [160/439] Loss: 3.0439, average_loss: 3.9231\n",
      "Epoch [12/50], Iter [165/439] Loss: 4.8654, average_loss: 3.9239\n",
      "Epoch [12/50], Iter [170/439] Loss: 3.9578, average_loss: 3.9192\n",
      "Epoch [12/50], Iter [175/439] Loss: 4.3067, average_loss: 3.9045\n",
      "Epoch [12/50], Iter [180/439] Loss: 4.9751, average_loss: 3.9029\n",
      "Epoch [12/50], Iter [185/439] Loss: 2.6859, average_loss: 3.8808\n",
      "Epoch [12/50], Iter [190/439] Loss: 2.7546, average_loss: 3.8792\n",
      "Epoch [12/50], Iter [195/439] Loss: 3.2454, average_loss: 3.8682\n",
      "Epoch [12/50], Iter [200/439] Loss: 3.8858, average_loss: 3.8943\n",
      "Epoch [12/50], Iter [205/439] Loss: 4.8012, average_loss: 3.9040\n",
      "Epoch [12/50], Iter [210/439] Loss: 2.8020, average_loss: 3.9031\n",
      "Epoch [12/50], Iter [215/439] Loss: 4.4117, average_loss: 3.8996\n",
      "Epoch [12/50], Iter [220/439] Loss: 3.9693, average_loss: 3.8869\n",
      "Epoch [12/50], Iter [225/439] Loss: 3.5851, average_loss: 3.8925\n",
      "Epoch [12/50], Iter [230/439] Loss: 3.1877, average_loss: 3.8891\n",
      "Epoch [12/50], Iter [235/439] Loss: 3.8889, average_loss: 3.8924\n",
      "Epoch [12/50], Iter [240/439] Loss: 4.5014, average_loss: 3.8902\n",
      "Epoch [12/50], Iter [245/439] Loss: 2.9487, average_loss: 3.8879\n",
      "Epoch [12/50], Iter [250/439] Loss: 3.3340, average_loss: 3.8836\n",
      "Epoch [12/50], Iter [255/439] Loss: 4.9259, average_loss: 3.8872\n",
      "Epoch [12/50], Iter [260/439] Loss: 3.0853, average_loss: 3.8797\n",
      "Epoch [12/50], Iter [265/439] Loss: 4.1175, average_loss: 3.8879\n",
      "Epoch [12/50], Iter [270/439] Loss: 5.1878, average_loss: 3.8884\n",
      "Epoch [12/50], Iter [275/439] Loss: 6.4121, average_loss: 3.8981\n",
      "Epoch [12/50], Iter [280/439] Loss: 5.2083, average_loss: 3.9153\n",
      "Epoch [12/50], Iter [285/439] Loss: 2.9128, average_loss: 3.9116\n",
      "Epoch [12/50], Iter [290/439] Loss: 3.4186, average_loss: 3.9081\n",
      "Epoch [12/50], Iter [295/439] Loss: 3.1215, average_loss: 3.9058\n",
      "Epoch [12/50], Iter [300/439] Loss: 4.2757, average_loss: 3.9044\n",
      "Epoch [12/50], Iter [305/439] Loss: 3.7272, average_loss: 3.8922\n",
      "Epoch [12/50], Iter [310/439] Loss: 2.7205, average_loss: 3.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Iter [315/439] Loss: 3.5531, average_loss: 3.9042\n",
      "Epoch [12/50], Iter [320/439] Loss: 7.9205, average_loss: 3.9114\n",
      "Epoch [12/50], Iter [325/439] Loss: 3.1741, average_loss: 3.8965\n",
      "Epoch [12/50], Iter [330/439] Loss: 4.0307, average_loss: 3.9052\n",
      "Epoch [12/50], Iter [335/439] Loss: 2.9745, average_loss: 3.8952\n",
      "Epoch [12/50], Iter [340/439] Loss: 3.4647, average_loss: 3.8951\n",
      "Epoch [12/50], Iter [345/439] Loss: 3.6309, average_loss: 3.9024\n",
      "Epoch [12/50], Iter [350/439] Loss: 4.1191, average_loss: 3.9069\n",
      "Epoch [12/50], Iter [355/439] Loss: 2.6574, average_loss: 3.8955\n",
      "Epoch [12/50], Iter [360/439] Loss: 2.2033, average_loss: 3.8875\n",
      "Epoch [12/50], Iter [365/439] Loss: 3.6908, average_loss: 3.8810\n",
      "Epoch [12/50], Iter [370/439] Loss: 3.2349, average_loss: 3.8975\n",
      "Epoch [12/50], Iter [375/439] Loss: 8.3574, average_loss: 3.9065\n",
      "Epoch [12/50], Iter [380/439] Loss: 2.3396, average_loss: 3.8931\n",
      "Epoch [12/50], Iter [385/439] Loss: 4.9794, average_loss: 3.8957\n",
      "Epoch [12/50], Iter [390/439] Loss: 4.6435, average_loss: 3.9021\n",
      "Epoch [12/50], Iter [395/439] Loss: 4.2979, average_loss: 3.8955\n",
      "Epoch [12/50], Iter [400/439] Loss: 4.4853, average_loss: 3.9008\n",
      "Epoch [12/50], Iter [405/439] Loss: 4.2095, average_loss: 3.9013\n",
      "Epoch [12/50], Iter [410/439] Loss: 3.3068, average_loss: 3.8959\n",
      "Epoch [12/50], Iter [415/439] Loss: 2.0905, average_loss: 3.8956\n",
      "Epoch [12/50], Iter [420/439] Loss: 2.6803, average_loss: 3.9056\n",
      "Epoch [12/50], Iter [425/439] Loss: 5.3859, average_loss: 3.9085\n",
      "Epoch [12/50], Iter [430/439] Loss: 4.9940, average_loss: 3.9094\n",
      "Epoch [12/50], Iter [435/439] Loss: 3.7620, average_loss: 3.9084\n",
      "Test epoch [12/50], average_loss: 3.9523\n",
      "Epoch [13/50], Iter [5/439] Loss: 4.5325, average_loss: 3.6638\n",
      "Epoch [13/50], Iter [10/439] Loss: 3.5606, average_loss: 3.9052\n",
      "Epoch [13/50], Iter [15/439] Loss: 4.7096, average_loss: 3.7139\n",
      "Epoch [13/50], Iter [20/439] Loss: 2.8509, average_loss: 3.7073\n",
      "Epoch [13/50], Iter [25/439] Loss: 3.7414, average_loss: 3.8210\n",
      "Epoch [13/50], Iter [30/439] Loss: 3.2195, average_loss: 3.9364\n",
      "Epoch [13/50], Iter [35/439] Loss: 4.4264, average_loss: 3.9231\n",
      "Epoch [13/50], Iter [40/439] Loss: 2.9337, average_loss: 3.8078\n",
      "Epoch [13/50], Iter [45/439] Loss: 3.3896, average_loss: 3.7678\n",
      "Epoch [13/50], Iter [50/439] Loss: 3.3692, average_loss: 3.7640\n",
      "Epoch [13/50], Iter [55/439] Loss: 4.0875, average_loss: 3.7842\n",
      "Epoch [13/50], Iter [60/439] Loss: 3.1095, average_loss: 3.7688\n",
      "Epoch [13/50], Iter [65/439] Loss: 3.0774, average_loss: 3.7983\n",
      "Epoch [13/50], Iter [70/439] Loss: 3.9560, average_loss: 3.7740\n",
      "Epoch [13/50], Iter [75/439] Loss: 3.8183, average_loss: 3.7894\n",
      "Epoch [13/50], Iter [80/439] Loss: 5.2504, average_loss: 3.8052\n",
      "Epoch [13/50], Iter [85/439] Loss: 6.2509, average_loss: 3.8071\n",
      "Epoch [13/50], Iter [90/439] Loss: 4.6631, average_loss: 3.7764\n",
      "Epoch [13/50], Iter [95/439] Loss: 4.9209, average_loss: 3.7858\n",
      "Epoch [13/50], Iter [100/439] Loss: 4.1487, average_loss: 3.7820\n",
      "Epoch [13/50], Iter [105/439] Loss: 3.8712, average_loss: 3.7820\n",
      "Epoch [13/50], Iter [110/439] Loss: 2.2722, average_loss: 3.7628\n",
      "Epoch [13/50], Iter [115/439] Loss: 3.1036, average_loss: 3.7469\n",
      "Epoch [13/50], Iter [120/439] Loss: 2.5341, average_loss: 3.7407\n",
      "Epoch [13/50], Iter [125/439] Loss: 2.9172, average_loss: 3.7515\n",
      "Epoch [13/50], Iter [130/439] Loss: 3.7272, average_loss: 3.7380\n",
      "Epoch [13/50], Iter [135/439] Loss: 3.2972, average_loss: 3.7503\n",
      "Epoch [13/50], Iter [140/439] Loss: 3.0240, average_loss: 3.7479\n",
      "Epoch [13/50], Iter [145/439] Loss: 3.5566, average_loss: 3.7295\n",
      "Epoch [13/50], Iter [150/439] Loss: 4.2459, average_loss: 3.7257\n",
      "Epoch [13/50], Iter [155/439] Loss: 4.2420, average_loss: 3.7641\n",
      "Epoch [13/50], Iter [160/439] Loss: 3.7523, average_loss: 3.7784\n",
      "Epoch [13/50], Iter [165/439] Loss: 4.1966, average_loss: 3.7854\n",
      "Epoch [13/50], Iter [170/439] Loss: 3.4976, average_loss: 3.7697\n",
      "Epoch [13/50], Iter [175/439] Loss: 3.3927, average_loss: 3.7696\n",
      "Epoch [13/50], Iter [180/439] Loss: 3.2594, average_loss: 3.7797\n",
      "Epoch [13/50], Iter [185/439] Loss: 4.1045, average_loss: 3.7738\n",
      "Epoch [13/50], Iter [190/439] Loss: 2.9227, average_loss: 3.7585\n",
      "Epoch [13/50], Iter [195/439] Loss: 3.6252, average_loss: 3.7454\n",
      "Epoch [13/50], Iter [200/439] Loss: 2.9104, average_loss: 3.7450\n",
      "Epoch [13/50], Iter [205/439] Loss: 3.3234, average_loss: 3.7484\n",
      "Epoch [13/50], Iter [210/439] Loss: 4.5516, average_loss: 3.7710\n",
      "Epoch [13/50], Iter [215/439] Loss: 4.7686, average_loss: 3.7647\n",
      "Epoch [13/50], Iter [220/439] Loss: 4.1080, average_loss: 3.7498\n",
      "Epoch [13/50], Iter [225/439] Loss: 2.0484, average_loss: 3.7374\n",
      "Epoch [13/50], Iter [230/439] Loss: 3.6565, average_loss: 3.7222\n",
      "Epoch [13/50], Iter [235/439] Loss: 3.9051, average_loss: 3.7274\n",
      "Epoch [13/50], Iter [240/439] Loss: 3.1015, average_loss: 3.7267\n",
      "Epoch [13/50], Iter [245/439] Loss: 5.2016, average_loss: 3.7475\n",
      "Epoch [13/50], Iter [250/439] Loss: 3.4292, average_loss: 3.7401\n",
      "Epoch [13/50], Iter [255/439] Loss: 6.2062, average_loss: 3.7432\n",
      "Epoch [13/50], Iter [260/439] Loss: 4.1790, average_loss: 3.7384\n",
      "Epoch [13/50], Iter [265/439] Loss: 5.6964, average_loss: 3.7506\n",
      "Epoch [13/50], Iter [270/439] Loss: 4.8254, average_loss: 3.7602\n",
      "Epoch [13/50], Iter [275/439] Loss: 4.1621, average_loss: 3.7598\n",
      "Epoch [13/50], Iter [280/439] Loss: 7.4436, average_loss: 3.7806\n",
      "Epoch [13/50], Iter [285/439] Loss: 4.0119, average_loss: 3.7909\n",
      "Epoch [13/50], Iter [290/439] Loss: 3.4175, average_loss: 3.7846\n",
      "Epoch [13/50], Iter [295/439] Loss: 2.6874, average_loss: 3.7789\n",
      "Epoch [13/50], Iter [300/439] Loss: 2.6361, average_loss: 3.7978\n",
      "Epoch [13/50], Iter [305/439] Loss: 2.6899, average_loss: 3.7912\n",
      "Epoch [13/50], Iter [310/439] Loss: 2.7434, average_loss: 3.7949\n",
      "Epoch [13/50], Iter [315/439] Loss: 5.7131, average_loss: 3.7957\n",
      "Epoch [13/50], Iter [320/439] Loss: 3.5893, average_loss: 3.7947\n",
      "Epoch [13/50], Iter [325/439] Loss: 2.7277, average_loss: 3.8073\n",
      "Epoch [13/50], Iter [330/439] Loss: 5.1732, average_loss: 3.8239\n",
      "Epoch [13/50], Iter [335/439] Loss: 2.0489, average_loss: 3.8277\n",
      "Epoch [13/50], Iter [340/439] Loss: 3.2906, average_loss: 3.8342\n",
      "Epoch [13/50], Iter [345/439] Loss: 2.8691, average_loss: 3.8311\n",
      "Epoch [13/50], Iter [350/439] Loss: 2.7923, average_loss: 3.8389\n",
      "Epoch [13/50], Iter [355/439] Loss: 5.1058, average_loss: 3.8387\n",
      "Epoch [13/50], Iter [360/439] Loss: 3.0931, average_loss: 3.8261\n",
      "Epoch [13/50], Iter [365/439] Loss: 2.8264, average_loss: 3.8359\n",
      "Epoch [13/50], Iter [370/439] Loss: 4.8895, average_loss: 3.8310\n",
      "Epoch [13/50], Iter [375/439] Loss: 3.9045, average_loss: 3.8314\n",
      "Epoch [13/50], Iter [380/439] Loss: 4.2079, average_loss: 3.8290\n",
      "Epoch [13/50], Iter [385/439] Loss: 2.9179, average_loss: 3.8345\n",
      "Epoch [13/50], Iter [390/439] Loss: 5.8445, average_loss: 3.8286\n",
      "Epoch [13/50], Iter [395/439] Loss: 5.3809, average_loss: 3.8362\n",
      "Epoch [13/50], Iter [400/439] Loss: 2.7856, average_loss: 3.8347\n",
      "Epoch [13/50], Iter [405/439] Loss: 3.7736, average_loss: 3.8390\n",
      "Epoch [13/50], Iter [410/439] Loss: 4.3385, average_loss: 3.8447\n",
      "Epoch [13/50], Iter [415/439] Loss: 3.0512, average_loss: 3.8424\n",
      "Epoch [13/50], Iter [420/439] Loss: 5.1344, average_loss: 3.8430\n",
      "Epoch [13/50], Iter [425/439] Loss: 4.7902, average_loss: 3.8498\n",
      "Epoch [13/50], Iter [430/439] Loss: 3.4599, average_loss: 3.8433\n",
      "Epoch [13/50], Iter [435/439] Loss: 2.5691, average_loss: 3.8382\n",
      "Test epoch [13/50], average_loss: 3.8836\n",
      "Epoch [14/50], Iter [5/439] Loss: 3.9061, average_loss: 4.3748\n",
      "Epoch [14/50], Iter [10/439] Loss: 3.6167, average_loss: 4.0986\n",
      "Epoch [14/50], Iter [15/439] Loss: 2.7283, average_loss: 4.3077\n",
      "Epoch [14/50], Iter [20/439] Loss: 2.9775, average_loss: 4.1670\n",
      "Epoch [14/50], Iter [25/439] Loss: 4.5380, average_loss: 4.0266\n",
      "Epoch [14/50], Iter [30/439] Loss: 4.0477, average_loss: 3.9837\n",
      "Epoch [14/50], Iter [35/439] Loss: 3.3612, average_loss: 3.8956\n",
      "Epoch [14/50], Iter [40/439] Loss: 4.1709, average_loss: 3.8781\n",
      "Epoch [14/50], Iter [45/439] Loss: 2.6668, average_loss: 3.8336\n",
      "Epoch [14/50], Iter [50/439] Loss: 2.9166, average_loss: 3.7743\n",
      "Epoch [14/50], Iter [55/439] Loss: 5.0417, average_loss: 3.7597\n",
      "Epoch [14/50], Iter [60/439] Loss: 6.4510, average_loss: 3.8062\n",
      "Epoch [14/50], Iter [65/439] Loss: 4.2220, average_loss: 3.7572\n",
      "Epoch [14/50], Iter [70/439] Loss: 4.2813, average_loss: 3.7615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Iter [75/439] Loss: 2.8208, average_loss: 3.7063\n",
      "Epoch [14/50], Iter [80/439] Loss: 4.5357, average_loss: 3.7150\n",
      "Epoch [14/50], Iter [85/439] Loss: 4.0813, average_loss: 3.7755\n",
      "Epoch [14/50], Iter [90/439] Loss: 5.1464, average_loss: 3.8072\n",
      "Epoch [14/50], Iter [95/439] Loss: 3.4353, average_loss: 3.7803\n",
      "Epoch [14/50], Iter [100/439] Loss: 4.3787, average_loss: 3.7404\n",
      "Epoch [14/50], Iter [105/439] Loss: 3.2843, average_loss: 3.7629\n",
      "Epoch [14/50], Iter [110/439] Loss: 3.0041, average_loss: 3.7766\n",
      "Epoch [14/50], Iter [115/439] Loss: 6.1603, average_loss: 3.7979\n",
      "Epoch [14/50], Iter [120/439] Loss: 2.0800, average_loss: 3.7715\n",
      "Epoch [14/50], Iter [125/439] Loss: 4.8369, average_loss: 3.7674\n",
      "Epoch [14/50], Iter [130/439] Loss: 3.1965, average_loss: 3.7764\n",
      "Epoch [14/50], Iter [135/439] Loss: 4.3841, average_loss: 3.7834\n",
      "Epoch [14/50], Iter [140/439] Loss: 3.0357, average_loss: 3.8157\n",
      "Epoch [14/50], Iter [145/439] Loss: 3.2106, average_loss: 3.8272\n",
      "Epoch [14/50], Iter [150/439] Loss: 3.0986, average_loss: 3.8378\n",
      "Epoch [14/50], Iter [155/439] Loss: 2.3476, average_loss: 3.8323\n",
      "Epoch [14/50], Iter [160/439] Loss: 5.3161, average_loss: 3.8319\n",
      "Epoch [14/50], Iter [165/439] Loss: 2.9092, average_loss: 3.8259\n",
      "Epoch [14/50], Iter [170/439] Loss: 3.8939, average_loss: 3.8190\n",
      "Epoch [14/50], Iter [175/439] Loss: 2.4387, average_loss: 3.7956\n",
      "Epoch [14/50], Iter [180/439] Loss: 3.0896, average_loss: 3.8168\n",
      "Epoch [14/50], Iter [185/439] Loss: 3.0083, average_loss: 3.8046\n",
      "Epoch [14/50], Iter [190/439] Loss: 4.2624, average_loss: 3.8270\n",
      "Epoch [14/50], Iter [195/439] Loss: 3.1554, average_loss: 3.8227\n",
      "Epoch [14/50], Iter [200/439] Loss: 4.7375, average_loss: 3.8491\n",
      "Epoch [14/50], Iter [205/439] Loss: 3.6540, average_loss: 3.8577\n",
      "Epoch [14/50], Iter [210/439] Loss: 6.7172, average_loss: 3.8838\n",
      "Epoch [14/50], Iter [215/439] Loss: 2.7574, average_loss: 3.8743\n",
      "Epoch [14/50], Iter [220/439] Loss: 3.8583, average_loss: 3.8719\n",
      "Epoch [14/50], Iter [225/439] Loss: 4.9055, average_loss: 3.8804\n",
      "Epoch [14/50], Iter [230/439] Loss: 5.2676, average_loss: 3.8768\n",
      "Epoch [14/50], Iter [235/439] Loss: 5.4028, average_loss: 3.8643\n",
      "Epoch [14/50], Iter [240/439] Loss: 3.3217, average_loss: 3.8651\n",
      "Epoch [14/50], Iter [245/439] Loss: 4.0038, average_loss: 3.8706\n",
      "Epoch [14/50], Iter [250/439] Loss: 3.9326, average_loss: 3.8671\n",
      "Epoch [14/50], Iter [255/439] Loss: 3.3610, average_loss: 3.8776\n",
      "Epoch [14/50], Iter [260/439] Loss: 2.8660, average_loss: 3.8726\n",
      "Epoch [14/50], Iter [265/439] Loss: 3.6727, average_loss: 3.8601\n",
      "Epoch [14/50], Iter [270/439] Loss: 3.7810, average_loss: 3.8763\n",
      "Epoch [14/50], Iter [275/439] Loss: 3.9311, average_loss: 3.8670\n",
      "Epoch [14/50], Iter [280/439] Loss: 3.8211, average_loss: 3.8658\n",
      "Epoch [14/50], Iter [285/439] Loss: 5.8212, average_loss: 3.8780\n",
      "Epoch [14/50], Iter [290/439] Loss: 3.3220, average_loss: 3.8710\n",
      "Epoch [14/50], Iter [295/439] Loss: 3.0834, average_loss: 3.8669\n",
      "Epoch [14/50], Iter [300/439] Loss: 2.3681, average_loss: 3.8533\n",
      "Epoch [14/50], Iter [305/439] Loss: 5.3062, average_loss: 3.8461\n",
      "Epoch [14/50], Iter [310/439] Loss: 3.1032, average_loss: 3.8414\n",
      "Epoch [14/50], Iter [315/439] Loss: 2.6028, average_loss: 3.8385\n",
      "Epoch [14/50], Iter [320/439] Loss: 2.4559, average_loss: 3.8322\n",
      "Epoch [14/50], Iter [325/439] Loss: 3.4565, average_loss: 3.8240\n",
      "Epoch [14/50], Iter [330/439] Loss: 3.2181, average_loss: 3.8297\n",
      "Epoch [14/50], Iter [335/439] Loss: 4.1398, average_loss: 3.8350\n",
      "Epoch [14/50], Iter [340/439] Loss: 3.8068, average_loss: 3.8320\n",
      "Epoch [14/50], Iter [345/439] Loss: 5.8468, average_loss: 3.8398\n",
      "Epoch [14/50], Iter [350/439] Loss: 3.5945, average_loss: 3.8445\n",
      "Epoch [14/50], Iter [355/439] Loss: 4.3636, average_loss: 3.8379\n",
      "Epoch [14/50], Iter [360/439] Loss: 5.1240, average_loss: 3.8410\n",
      "Epoch [14/50], Iter [365/439] Loss: 3.4667, average_loss: 3.8406\n",
      "Epoch [14/50], Iter [370/439] Loss: 4.2469, average_loss: 3.8526\n",
      "Epoch [14/50], Iter [375/439] Loss: 3.1740, average_loss: 3.8530\n",
      "Epoch [14/50], Iter [380/439] Loss: 3.5695, average_loss: 3.8520\n",
      "Epoch [14/50], Iter [385/439] Loss: 4.5413, average_loss: 3.8505\n",
      "Epoch [14/50], Iter [390/439] Loss: 3.0215, average_loss: 3.8462\n",
      "Epoch [14/50], Iter [395/439] Loss: 3.5232, average_loss: 3.8508\n",
      "Epoch [14/50], Iter [400/439] Loss: 5.6528, average_loss: 3.8430\n",
      "Epoch [14/50], Iter [405/439] Loss: 6.2392, average_loss: 3.8525\n",
      "Epoch [14/50], Iter [410/439] Loss: 2.8440, average_loss: 3.8450\n",
      "Epoch [14/50], Iter [415/439] Loss: 2.4129, average_loss: 3.8464\n",
      "Epoch [14/50], Iter [420/439] Loss: 3.0244, average_loss: 3.8522\n",
      "Epoch [14/50], Iter [425/439] Loss: 2.8529, average_loss: 3.8519\n",
      "Epoch [14/50], Iter [430/439] Loss: 3.2894, average_loss: 3.8479\n",
      "Epoch [14/50], Iter [435/439] Loss: 3.2936, average_loss: 3.8447\n",
      "Test epoch [14/50], average_loss: 3.8760\n",
      "Epoch [15/50], Iter [5/439] Loss: 4.4862, average_loss: 4.5183\n",
      "Epoch [15/50], Iter [10/439] Loss: 2.9432, average_loss: 3.9037\n",
      "Epoch [15/50], Iter [15/439] Loss: 5.4501, average_loss: 3.9966\n",
      "Epoch [15/50], Iter [20/439] Loss: 3.0199, average_loss: 4.0452\n",
      "Epoch [15/50], Iter [25/439] Loss: 3.8798, average_loss: 3.8588\n",
      "Epoch [15/50], Iter [30/439] Loss: 2.8137, average_loss: 3.7780\n",
      "Epoch [15/50], Iter [35/439] Loss: 3.9409, average_loss: 3.9630\n",
      "Epoch [15/50], Iter [40/439] Loss: 3.7902, average_loss: 3.9852\n",
      "Epoch [15/50], Iter [45/439] Loss: 4.0075, average_loss: 3.9358\n",
      "Epoch [15/50], Iter [50/439] Loss: 3.8762, average_loss: 3.9436\n",
      "Epoch [15/50], Iter [55/439] Loss: 3.5183, average_loss: 3.8660\n",
      "Epoch [15/50], Iter [60/439] Loss: 4.5938, average_loss: 3.8465\n",
      "Epoch [15/50], Iter [65/439] Loss: 3.5757, average_loss: 3.8077\n",
      "Epoch [15/50], Iter [70/439] Loss: 5.3430, average_loss: 3.8078\n",
      "Epoch [15/50], Iter [75/439] Loss: 5.3510, average_loss: 3.7978\n",
      "Epoch [15/50], Iter [80/439] Loss: 3.0018, average_loss: 3.7632\n",
      "Epoch [15/50], Iter [85/439] Loss: 5.9022, average_loss: 3.7924\n",
      "Epoch [15/50], Iter [90/439] Loss: 2.9486, average_loss: 3.7564\n",
      "Epoch [15/50], Iter [95/439] Loss: 5.1046, average_loss: 3.7515\n",
      "Epoch [15/50], Iter [100/439] Loss: 3.8218, average_loss: 3.7459\n",
      "Epoch [15/50], Iter [105/439] Loss: 2.6212, average_loss: 3.7117\n",
      "Epoch [15/50], Iter [110/439] Loss: 2.3685, average_loss: 3.6863\n",
      "Epoch [15/50], Iter [115/439] Loss: 4.5547, average_loss: 3.6747\n",
      "Epoch [15/50], Iter [120/439] Loss: 2.0165, average_loss: 3.6913\n",
      "Epoch [15/50], Iter [125/439] Loss: 3.4035, average_loss: 3.7168\n",
      "Epoch [15/50], Iter [130/439] Loss: 3.5380, average_loss: 3.7797\n",
      "Epoch [15/50], Iter [135/439] Loss: 4.7914, average_loss: 3.7992\n",
      "Epoch [15/50], Iter [140/439] Loss: 4.2652, average_loss: 3.8035\n",
      "Epoch [15/50], Iter [145/439] Loss: 3.6436, average_loss: 3.7994\n",
      "Epoch [15/50], Iter [150/439] Loss: 3.1176, average_loss: 3.7951\n",
      "Epoch [15/50], Iter [155/439] Loss: 4.3318, average_loss: 3.7906\n",
      "Epoch [15/50], Iter [160/439] Loss: 3.2195, average_loss: 3.7830\n",
      "Epoch [15/50], Iter [165/439] Loss: 3.0845, average_loss: 3.7629\n",
      "Epoch [15/50], Iter [170/439] Loss: 4.2202, average_loss: 3.7585\n",
      "Epoch [15/50], Iter [175/439] Loss: 3.9054, average_loss: 3.7798\n",
      "Epoch [15/50], Iter [180/439] Loss: 3.1763, average_loss: 3.7791\n",
      "Epoch [15/50], Iter [185/439] Loss: 2.3458, average_loss: 3.7734\n",
      "Epoch [15/50], Iter [190/439] Loss: 2.0810, average_loss: 3.7658\n",
      "Epoch [15/50], Iter [195/439] Loss: 2.5400, average_loss: 3.7798\n",
      "Epoch [15/50], Iter [200/439] Loss: 3.8051, average_loss: 3.7789\n",
      "Epoch [15/50], Iter [205/439] Loss: 4.3951, average_loss: 3.7649\n",
      "Epoch [15/50], Iter [210/439] Loss: 4.2020, average_loss: 3.7706\n",
      "Epoch [15/50], Iter [215/439] Loss: 4.3374, average_loss: 3.7810\n",
      "Epoch [15/50], Iter [220/439] Loss: 4.5761, average_loss: 3.7627\n",
      "Epoch [15/50], Iter [225/439] Loss: 3.3307, average_loss: 3.7486\n",
      "Epoch [15/50], Iter [230/439] Loss: 2.9913, average_loss: 3.7815\n",
      "Epoch [15/50], Iter [235/439] Loss: 4.7370, average_loss: 3.8023\n",
      "Epoch [15/50], Iter [240/439] Loss: 2.7391, average_loss: 3.8005\n",
      "Epoch [15/50], Iter [245/439] Loss: 3.6834, average_loss: 3.7957\n",
      "Epoch [15/50], Iter [250/439] Loss: 3.3683, average_loss: 3.7862\n",
      "Epoch [15/50], Iter [255/439] Loss: 3.8372, average_loss: 3.7834\n",
      "Epoch [15/50], Iter [260/439] Loss: 3.4148, average_loss: 3.7971\n",
      "Epoch [15/50], Iter [265/439] Loss: 5.7977, average_loss: 3.7982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Iter [270/439] Loss: 4.9468, average_loss: 3.8150\n",
      "Epoch [15/50], Iter [275/439] Loss: 3.6901, average_loss: 3.8141\n",
      "Epoch [15/50], Iter [280/439] Loss: 3.7424, average_loss: 3.8111\n",
      "Epoch [15/50], Iter [285/439] Loss: 4.0481, average_loss: 3.8248\n",
      "Epoch [15/50], Iter [290/439] Loss: 3.0764, average_loss: 3.8198\n",
      "Epoch [15/50], Iter [295/439] Loss: 3.5426, average_loss: 3.8222\n",
      "Epoch [15/50], Iter [300/439] Loss: 4.1524, average_loss: 3.8340\n",
      "Epoch [15/50], Iter [305/439] Loss: 3.2254, average_loss: 3.8257\n",
      "Epoch [15/50], Iter [310/439] Loss: 3.1752, average_loss: 3.8180\n",
      "Epoch [15/50], Iter [315/439] Loss: 4.0598, average_loss: 3.8384\n",
      "Epoch [15/50], Iter [320/439] Loss: 3.4465, average_loss: 3.8414\n",
      "Epoch [15/50], Iter [325/439] Loss: 3.8954, average_loss: 3.8420\n",
      "Epoch [15/50], Iter [330/439] Loss: 1.9549, average_loss: 3.8308\n",
      "Epoch [15/50], Iter [335/439] Loss: 3.4234, average_loss: 3.8276\n",
      "Epoch [15/50], Iter [340/439] Loss: 3.6350, average_loss: 3.8304\n",
      "Epoch [15/50], Iter [345/439] Loss: 4.1360, average_loss: 3.8220\n",
      "Epoch [15/50], Iter [350/439] Loss: 4.6268, average_loss: 3.8262\n",
      "Epoch [15/50], Iter [355/439] Loss: 3.5562, average_loss: 3.8138\n",
      "Epoch [15/50], Iter [360/439] Loss: 2.9667, average_loss: 3.8024\n",
      "Epoch [15/50], Iter [365/439] Loss: 3.0841, average_loss: 3.7921\n",
      "Epoch [15/50], Iter [370/439] Loss: 4.4954, average_loss: 3.7956\n",
      "Epoch [15/50], Iter [375/439] Loss: 3.6839, average_loss: 3.7932\n",
      "Epoch [15/50], Iter [380/439] Loss: 2.3474, average_loss: 3.7831\n",
      "Epoch [15/50], Iter [385/439] Loss: 5.2677, average_loss: 3.7895\n",
      "Epoch [15/50], Iter [390/439] Loss: 5.0538, average_loss: 3.7874\n",
      "Epoch [15/50], Iter [395/439] Loss: 3.3819, average_loss: 3.7887\n",
      "Epoch [15/50], Iter [400/439] Loss: 3.3008, average_loss: 3.7865\n",
      "Epoch [15/50], Iter [405/439] Loss: 2.7189, average_loss: 3.7888\n",
      "Epoch [15/50], Iter [410/439] Loss: 3.5070, average_loss: 3.7891\n",
      "Epoch [15/50], Iter [415/439] Loss: 4.1882, average_loss: 3.7809\n",
      "Epoch [15/50], Iter [420/439] Loss: 2.0832, average_loss: 3.7816\n",
      "Epoch [15/50], Iter [425/439] Loss: 2.2409, average_loss: 3.7761\n",
      "Epoch [15/50], Iter [430/439] Loss: 2.6143, average_loss: 3.7700\n",
      "Epoch [15/50], Iter [435/439] Loss: 4.9050, average_loss: 3.7888\n",
      "Test epoch [15/50], average_loss: 3.9682\n",
      "Epoch [16/50], Iter [5/439] Loss: 3.1088, average_loss: 3.8916\n",
      "Epoch [16/50], Iter [10/439] Loss: 4.0942, average_loss: 3.9591\n",
      "Epoch [16/50], Iter [15/439] Loss: 3.1956, average_loss: 3.9041\n",
      "Epoch [16/50], Iter [20/439] Loss: 4.9439, average_loss: 3.7910\n",
      "Epoch [16/50], Iter [25/439] Loss: 4.6454, average_loss: 3.8576\n",
      "Epoch [16/50], Iter [30/439] Loss: 2.2961, average_loss: 3.9142\n",
      "Epoch [16/50], Iter [35/439] Loss: 6.5030, average_loss: 3.9461\n",
      "Epoch [16/50], Iter [40/439] Loss: 2.5720, average_loss: 3.8905\n",
      "Epoch [16/50], Iter [45/439] Loss: 2.1630, average_loss: 3.7721\n",
      "Epoch [16/50], Iter [50/439] Loss: 2.6487, average_loss: 3.7940\n",
      "Epoch [16/50], Iter [55/439] Loss: 2.7536, average_loss: 3.7920\n",
      "Epoch [16/50], Iter [60/439] Loss: 4.0775, average_loss: 3.7978\n",
      "Epoch [16/50], Iter [65/439] Loss: 2.7908, average_loss: 3.7632\n",
      "Epoch [16/50], Iter [70/439] Loss: 3.0799, average_loss: 3.7357\n",
      "Epoch [16/50], Iter [75/439] Loss: 3.1442, average_loss: 3.8628\n",
      "Epoch [16/50], Iter [80/439] Loss: 5.0252, average_loss: 3.9617\n",
      "Epoch [16/50], Iter [85/439] Loss: 4.0923, average_loss: 3.9359\n",
      "Epoch [16/50], Iter [90/439] Loss: 3.8083, average_loss: 3.9575\n",
      "Epoch [16/50], Iter [95/439] Loss: 4.4950, average_loss: 3.9466\n",
      "Epoch [16/50], Iter [100/439] Loss: 2.9179, average_loss: 3.9402\n",
      "Epoch [16/50], Iter [105/439] Loss: 2.7449, average_loss: 3.9310\n",
      "Epoch [16/50], Iter [110/439] Loss: 4.8632, average_loss: 3.9110\n",
      "Epoch [16/50], Iter [115/439] Loss: 3.0797, average_loss: 3.8809\n",
      "Epoch [16/50], Iter [120/439] Loss: 4.5000, average_loss: 3.8641\n",
      "Epoch [16/50], Iter [125/439] Loss: 4.7605, average_loss: 3.8648\n",
      "Epoch [16/50], Iter [130/439] Loss: 2.3417, average_loss: 3.8299\n",
      "Epoch [16/50], Iter [135/439] Loss: 3.7053, average_loss: 3.8096\n",
      "Epoch [16/50], Iter [140/439] Loss: 2.7139, average_loss: 3.7857\n",
      "Epoch [16/50], Iter [145/439] Loss: 3.1536, average_loss: 3.7685\n",
      "Epoch [16/50], Iter [150/439] Loss: 3.1720, average_loss: 3.7658\n",
      "Epoch [16/50], Iter [155/439] Loss: 4.4267, average_loss: 3.7643\n",
      "Epoch [16/50], Iter [160/439] Loss: 4.3808, average_loss: 3.7580\n",
      "Epoch [16/50], Iter [165/439] Loss: 3.7191, average_loss: 3.7536\n",
      "Epoch [16/50], Iter [170/439] Loss: 3.4513, average_loss: 3.7620\n",
      "Epoch [16/50], Iter [175/439] Loss: 3.1789, average_loss: 3.7515\n",
      "Epoch [16/50], Iter [180/439] Loss: 5.2570, average_loss: 3.7721\n",
      "Epoch [16/50], Iter [185/439] Loss: 2.9476, average_loss: 3.7598\n",
      "Epoch [16/50], Iter [190/439] Loss: 3.4453, average_loss: 3.7473\n",
      "Epoch [16/50], Iter [195/439] Loss: 2.4344, average_loss: 3.7384\n",
      "Epoch [16/50], Iter [200/439] Loss: 2.6136, average_loss: 3.7306\n",
      "Epoch [16/50], Iter [205/439] Loss: 3.3507, average_loss: 3.7246\n",
      "Epoch [16/50], Iter [210/439] Loss: 3.8124, average_loss: 3.7167\n",
      "Epoch [16/50], Iter [215/439] Loss: 2.8657, average_loss: 3.7055\n",
      "Epoch [16/50], Iter [220/439] Loss: 3.5253, average_loss: 3.7137\n",
      "Epoch [16/50], Iter [225/439] Loss: 2.1261, average_loss: 3.7184\n",
      "Epoch [16/50], Iter [230/439] Loss: 3.5981, average_loss: 3.7265\n",
      "Epoch [16/50], Iter [235/439] Loss: 4.0653, average_loss: 3.7398\n",
      "Epoch [16/50], Iter [240/439] Loss: 2.0546, average_loss: 3.7616\n",
      "Epoch [16/50], Iter [245/439] Loss: 3.9643, average_loss: 3.7604\n",
      "Epoch [16/50], Iter [250/439] Loss: 2.7552, average_loss: 3.7490\n",
      "Epoch [16/50], Iter [255/439] Loss: 3.5238, average_loss: 3.7403\n",
      "Epoch [16/50], Iter [260/439] Loss: 3.2587, average_loss: 3.7342\n",
      "Epoch [16/50], Iter [265/439] Loss: 5.0024, average_loss: 3.7446\n",
      "Epoch [16/50], Iter [270/439] Loss: 4.0862, average_loss: 3.7389\n",
      "Epoch [16/50], Iter [275/439] Loss: 2.3981, average_loss: 3.7320\n",
      "Epoch [16/50], Iter [280/439] Loss: 3.5013, average_loss: 3.7332\n",
      "Epoch [16/50], Iter [285/439] Loss: 2.6724, average_loss: 3.7335\n",
      "Epoch [16/50], Iter [290/439] Loss: 5.2092, average_loss: 3.7422\n",
      "Epoch [16/50], Iter [295/439] Loss: 4.1636, average_loss: 3.7385\n",
      "Epoch [16/50], Iter [300/439] Loss: 3.4243, average_loss: 3.7284\n",
      "Epoch [16/50], Iter [305/439] Loss: 4.1283, average_loss: 3.7340\n",
      "Epoch [16/50], Iter [310/439] Loss: 4.8432, average_loss: 3.7400\n",
      "Epoch [16/50], Iter [315/439] Loss: 4.3634, average_loss: 3.7373\n",
      "Epoch [16/50], Iter [320/439] Loss: 3.4262, average_loss: 3.7326\n",
      "Epoch [16/50], Iter [325/439] Loss: 3.0110, average_loss: 3.7306\n",
      "Epoch [16/50], Iter [330/439] Loss: 4.5856, average_loss: 3.7409\n",
      "Epoch [16/50], Iter [335/439] Loss: 4.4924, average_loss: 3.7446\n",
      "Epoch [16/50], Iter [340/439] Loss: 5.2472, average_loss: 3.7468\n",
      "Epoch [16/50], Iter [345/439] Loss: 3.2733, average_loss: 3.7438\n",
      "Epoch [16/50], Iter [350/439] Loss: 2.3938, average_loss: 3.7525\n",
      "Epoch [16/50], Iter [355/439] Loss: 2.1267, average_loss: 3.7397\n",
      "Epoch [16/50], Iter [360/439] Loss: 4.6436, average_loss: 3.7507\n",
      "Epoch [16/50], Iter [365/439] Loss: 3.0888, average_loss: 3.7403\n",
      "Epoch [16/50], Iter [370/439] Loss: 4.1226, average_loss: 3.7423\n",
      "Epoch [16/50], Iter [375/439] Loss: 5.2170, average_loss: 3.7391\n",
      "Epoch [16/50], Iter [380/439] Loss: 3.0392, average_loss: 3.7335\n",
      "Epoch [16/50], Iter [385/439] Loss: 4.6197, average_loss: 3.7394\n",
      "Epoch [16/50], Iter [390/439] Loss: 3.0345, average_loss: 3.7355\n",
      "Epoch [16/50], Iter [395/439] Loss: 4.2440, average_loss: 3.7366\n",
      "Epoch [16/50], Iter [400/439] Loss: 2.6835, average_loss: 3.7348\n",
      "Epoch [16/50], Iter [405/439] Loss: 2.9958, average_loss: 3.7267\n",
      "Epoch [16/50], Iter [410/439] Loss: 4.3533, average_loss: 3.7304\n",
      "Epoch [16/50], Iter [415/439] Loss: 3.1142, average_loss: 3.7389\n",
      "Epoch [16/50], Iter [420/439] Loss: 2.6332, average_loss: 3.7325\n",
      "Epoch [16/50], Iter [425/439] Loss: 5.7720, average_loss: 3.7509\n",
      "Epoch [16/50], Iter [430/439] Loss: 3.8517, average_loss: 3.7561\n",
      "Epoch [16/50], Iter [435/439] Loss: 3.8848, average_loss: 3.7536\n",
      "Test epoch [16/50], average_loss: 3.7892\n",
      "Epoch [17/50], Iter [5/439] Loss: 4.8419, average_loss: 3.9167\n",
      "Epoch [17/50], Iter [10/439] Loss: 5.6084, average_loss: 4.2662\n",
      "Epoch [17/50], Iter [15/439] Loss: 2.2431, average_loss: 4.1381\n",
      "Epoch [17/50], Iter [20/439] Loss: 4.1121, average_loss: 4.0965\n",
      "Epoch [17/50], Iter [25/439] Loss: 3.9961, average_loss: 4.2789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Iter [30/439] Loss: 4.0886, average_loss: 4.1698\n",
      "Epoch [17/50], Iter [35/439] Loss: 3.3698, average_loss: 4.0667\n",
      "Epoch [17/50], Iter [40/439] Loss: 3.7255, average_loss: 3.9704\n",
      "Epoch [17/50], Iter [45/439] Loss: 4.2336, average_loss: 4.0582\n",
      "Epoch [17/50], Iter [50/439] Loss: 2.2107, average_loss: 3.9768\n",
      "Epoch [17/50], Iter [55/439] Loss: 3.4745, average_loss: 3.9206\n",
      "Epoch [17/50], Iter [60/439] Loss: 2.6245, average_loss: 3.8993\n",
      "Epoch [17/50], Iter [65/439] Loss: 4.9108, average_loss: 3.9277\n",
      "Epoch [17/50], Iter [70/439] Loss: 2.7458, average_loss: 3.8656\n",
      "Epoch [17/50], Iter [75/439] Loss: 5.1016, average_loss: 3.8280\n",
      "Epoch [17/50], Iter [80/439] Loss: 4.2212, average_loss: 3.8066\n",
      "Epoch [17/50], Iter [85/439] Loss: 2.3417, average_loss: 3.7921\n",
      "Epoch [17/50], Iter [90/439] Loss: 2.4626, average_loss: 3.7482\n",
      "Epoch [17/50], Iter [95/439] Loss: 2.9391, average_loss: 3.7233\n",
      "Epoch [17/50], Iter [100/439] Loss: 3.1988, average_loss: 3.7125\n",
      "Epoch [17/50], Iter [105/439] Loss: 3.6024, average_loss: 3.6861\n",
      "Epoch [17/50], Iter [110/439] Loss: 4.0628, average_loss: 3.6834\n",
      "Epoch [17/50], Iter [115/439] Loss: 3.6611, average_loss: 3.6858\n",
      "Epoch [17/50], Iter [120/439] Loss: 3.6157, average_loss: 3.6735\n",
      "Epoch [17/50], Iter [125/439] Loss: 2.9641, average_loss: 3.6454\n",
      "Epoch [17/50], Iter [130/439] Loss: 3.0741, average_loss: 3.6385\n",
      "Epoch [17/50], Iter [135/439] Loss: 3.5632, average_loss: 3.6265\n",
      "Epoch [17/50], Iter [140/439] Loss: 2.6907, average_loss: 3.6326\n",
      "Epoch [17/50], Iter [145/439] Loss: 7.6627, average_loss: 3.6497\n",
      "Epoch [17/50], Iter [150/439] Loss: 2.7833, average_loss: 3.6442\n",
      "Epoch [17/50], Iter [155/439] Loss: 2.9613, average_loss: 3.6594\n",
      "Epoch [17/50], Iter [160/439] Loss: 3.5798, average_loss: 3.6757\n",
      "Epoch [17/50], Iter [165/439] Loss: 4.0383, average_loss: 3.6744\n",
      "Epoch [17/50], Iter [170/439] Loss: 4.1033, average_loss: 3.6749\n",
      "Epoch [17/50], Iter [175/439] Loss: 2.6178, average_loss: 3.6715\n",
      "Epoch [17/50], Iter [180/439] Loss: 2.5153, average_loss: 3.6659\n",
      "Epoch [17/50], Iter [185/439] Loss: 4.2721, average_loss: 3.6556\n",
      "Epoch [17/50], Iter [190/439] Loss: 4.2292, average_loss: 3.6543\n",
      "Epoch [17/50], Iter [195/439] Loss: 4.1530, average_loss: 3.6707\n",
      "Epoch [17/50], Iter [200/439] Loss: 2.3442, average_loss: 3.6888\n",
      "Epoch [17/50], Iter [205/439] Loss: 3.9470, average_loss: 3.6942\n",
      "Epoch [17/50], Iter [210/439] Loss: 3.6674, average_loss: 3.6942\n",
      "Epoch [17/50], Iter [215/439] Loss: 4.8368, average_loss: 3.6893\n",
      "Epoch [17/50], Iter [220/439] Loss: 3.6307, average_loss: 3.6886\n",
      "Epoch [17/50], Iter [225/439] Loss: 4.2480, average_loss: 3.6835\n",
      "Epoch [17/50], Iter [230/439] Loss: 3.2277, average_loss: 3.6857\n",
      "Epoch [17/50], Iter [235/439] Loss: 3.1649, average_loss: 3.6759\n",
      "Epoch [17/50], Iter [240/439] Loss: 4.1130, average_loss: 3.6681\n",
      "Epoch [17/50], Iter [245/439] Loss: 2.9937, average_loss: 3.6560\n",
      "Epoch [17/50], Iter [250/439] Loss: 7.8063, average_loss: 3.6726\n",
      "Epoch [17/50], Iter [255/439] Loss: 4.8106, average_loss: 3.6863\n",
      "Epoch [17/50], Iter [260/439] Loss: 5.2948, average_loss: 3.6999\n",
      "Epoch [17/50], Iter [265/439] Loss: 2.2912, average_loss: 3.6832\n",
      "Epoch [17/50], Iter [270/439] Loss: 3.3386, average_loss: 3.6824\n",
      "Epoch [17/50], Iter [275/439] Loss: 4.3282, average_loss: 3.6767\n",
      "Epoch [17/50], Iter [280/439] Loss: 3.0800, average_loss: 3.6767\n",
      "Epoch [17/50], Iter [285/439] Loss: 2.6516, average_loss: 3.6657\n",
      "Epoch [17/50], Iter [290/439] Loss: 3.3239, average_loss: 3.6558\n",
      "Epoch [17/50], Iter [295/439] Loss: 3.3393, average_loss: 3.6485\n",
      "Epoch [17/50], Iter [300/439] Loss: 4.2004, average_loss: 3.6414\n",
      "Epoch [17/50], Iter [305/439] Loss: 3.2736, average_loss: 3.6461\n",
      "Epoch [17/50], Iter [310/439] Loss: 2.9974, average_loss: 3.6396\n",
      "Epoch [17/50], Iter [315/439] Loss: 4.9913, average_loss: 3.6445\n",
      "Epoch [17/50], Iter [320/439] Loss: 2.7848, average_loss: 3.6439\n",
      "Epoch [17/50], Iter [325/439] Loss: 3.0759, average_loss: 3.6395\n",
      "Epoch [17/50], Iter [330/439] Loss: 2.0027, average_loss: 3.6495\n",
      "Epoch [17/50], Iter [335/439] Loss: 4.6858, average_loss: 3.6509\n",
      "Epoch [17/50], Iter [340/439] Loss: 3.3724, average_loss: 3.6469\n",
      "Epoch [17/50], Iter [345/439] Loss: 2.7298, average_loss: 3.6496\n",
      "Epoch [17/50], Iter [350/439] Loss: 2.7324, average_loss: 3.6530\n",
      "Epoch [17/50], Iter [355/439] Loss: 2.6630, average_loss: 3.6494\n",
      "Epoch [17/50], Iter [360/439] Loss: 3.8747, average_loss: 3.6509\n",
      "Epoch [17/50], Iter [365/439] Loss: 4.0623, average_loss: 3.6495\n",
      "Epoch [17/50], Iter [370/439] Loss: 3.9292, average_loss: 3.6676\n",
      "Epoch [17/50], Iter [375/439] Loss: 5.0720, average_loss: 3.6691\n",
      "Epoch [17/50], Iter [380/439] Loss: 3.3109, average_loss: 3.6678\n",
      "Epoch [17/50], Iter [385/439] Loss: 3.7126, average_loss: 3.6657\n",
      "Epoch [17/50], Iter [390/439] Loss: 3.5375, average_loss: 3.6715\n",
      "Epoch [17/50], Iter [395/439] Loss: 4.8755, average_loss: 3.6762\n",
      "Epoch [17/50], Iter [400/439] Loss: 4.7680, average_loss: 3.6813\n",
      "Epoch [17/50], Iter [405/439] Loss: 3.1528, average_loss: 3.6828\n",
      "Epoch [17/50], Iter [410/439] Loss: 2.3234, average_loss: 3.6861\n",
      "Epoch [17/50], Iter [415/439] Loss: 3.8099, average_loss: 3.6889\n",
      "Epoch [17/50], Iter [420/439] Loss: 2.1426, average_loss: 3.6832\n",
      "Epoch [17/50], Iter [425/439] Loss: 5.1551, average_loss: 3.6957\n",
      "Epoch [17/50], Iter [430/439] Loss: 2.9025, average_loss: 3.6960\n",
      "Epoch [17/50], Iter [435/439] Loss: 8.1961, average_loss: 3.7062\n",
      "Test epoch [17/50], average_loss: 3.7504\n",
      "Epoch [18/50], Iter [5/439] Loss: 4.6967, average_loss: 4.2127\n",
      "Epoch [18/50], Iter [10/439] Loss: 3.8070, average_loss: 4.1255\n",
      "Epoch [18/50], Iter [15/439] Loss: 3.8716, average_loss: 4.1032\n",
      "Epoch [18/50], Iter [20/439] Loss: 3.0054, average_loss: 3.8408\n",
      "Epoch [18/50], Iter [25/439] Loss: 4.6621, average_loss: 3.7876\n",
      "Epoch [18/50], Iter [30/439] Loss: 3.5154, average_loss: 3.6594\n",
      "Epoch [18/50], Iter [35/439] Loss: 3.4237, average_loss: 3.7675\n",
      "Epoch [18/50], Iter [40/439] Loss: 3.3098, average_loss: 3.6596\n",
      "Epoch [18/50], Iter [45/439] Loss: 3.6817, average_loss: 3.7331\n",
      "Epoch [18/50], Iter [50/439] Loss: 2.4123, average_loss: 3.7002\n",
      "Epoch [18/50], Iter [55/439] Loss: 3.7498, average_loss: 3.6568\n",
      "Epoch [18/50], Iter [60/439] Loss: 4.2181, average_loss: 3.6996\n",
      "Epoch [18/50], Iter [65/439] Loss: 2.8584, average_loss: 3.6438\n",
      "Epoch [18/50], Iter [70/439] Loss: 2.9110, average_loss: 3.6400\n",
      "Epoch [18/50], Iter [75/439] Loss: 3.7111, average_loss: 3.6692\n",
      "Epoch [18/50], Iter [80/439] Loss: 5.8186, average_loss: 3.7022\n",
      "Epoch [18/50], Iter [85/439] Loss: 3.2717, average_loss: 3.7065\n",
      "Epoch [18/50], Iter [90/439] Loss: 1.6198, average_loss: 3.6595\n",
      "Epoch [18/50], Iter [95/439] Loss: 2.8667, average_loss: 3.6502\n",
      "Epoch [18/50], Iter [100/439] Loss: 3.6497, average_loss: 3.6468\n",
      "Epoch [18/50], Iter [105/439] Loss: 4.2700, average_loss: 3.6717\n",
      "Epoch [18/50], Iter [110/439] Loss: 3.5191, average_loss: 3.6416\n",
      "Epoch [18/50], Iter [115/439] Loss: 3.8525, average_loss: 3.6571\n",
      "Epoch [18/50], Iter [120/439] Loss: 4.4782, average_loss: 3.6646\n",
      "Epoch [18/50], Iter [125/439] Loss: 4.8905, average_loss: 3.6796\n",
      "Epoch [18/50], Iter [130/439] Loss: 4.1247, average_loss: 3.6799\n",
      "Epoch [18/50], Iter [135/439] Loss: 2.8073, average_loss: 3.6879\n",
      "Epoch [18/50], Iter [140/439] Loss: 3.9941, average_loss: 3.6787\n",
      "Epoch [18/50], Iter [145/439] Loss: 3.6118, average_loss: 3.6651\n",
      "Epoch [18/50], Iter [150/439] Loss: 3.7479, average_loss: 3.6509\n",
      "Epoch [18/50], Iter [155/439] Loss: 3.2522, average_loss: 3.6570\n",
      "Epoch [18/50], Iter [160/439] Loss: 2.6325, average_loss: 3.6448\n",
      "Epoch [18/50], Iter [165/439] Loss: 5.1989, average_loss: 3.6703\n",
      "Epoch [18/50], Iter [170/439] Loss: 4.5407, average_loss: 3.6768\n",
      "Epoch [18/50], Iter [175/439] Loss: 2.0485, average_loss: 3.6839\n",
      "Epoch [18/50], Iter [180/439] Loss: 3.4757, average_loss: 3.6765\n",
      "Epoch [18/50], Iter [185/439] Loss: 8.3802, average_loss: 3.6855\n",
      "Epoch [18/50], Iter [190/439] Loss: 3.0077, average_loss: 3.6984\n",
      "Epoch [18/50], Iter [195/439] Loss: 3.0161, average_loss: 3.6802\n",
      "Epoch [18/50], Iter [200/439] Loss: 2.8465, average_loss: 3.6775\n",
      "Epoch [18/50], Iter [205/439] Loss: 3.0786, average_loss: 3.6581\n",
      "Epoch [18/50], Iter [210/439] Loss: 2.4133, average_loss: 3.6651\n",
      "Epoch [18/50], Iter [215/439] Loss: 3.5524, average_loss: 3.6643\n",
      "Epoch [18/50], Iter [220/439] Loss: 5.0217, average_loss: 3.6647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Iter [225/439] Loss: 4.4044, average_loss: 3.6767\n",
      "Epoch [18/50], Iter [230/439] Loss: 4.0058, average_loss: 3.6864\n",
      "Epoch [18/50], Iter [235/439] Loss: 4.6039, average_loss: 3.6842\n",
      "Epoch [18/50], Iter [240/439] Loss: 3.1445, average_loss: 3.6870\n",
      "Epoch [18/50], Iter [245/439] Loss: 2.6688, average_loss: 3.6801\n",
      "Epoch [18/50], Iter [250/439] Loss: 2.5428, average_loss: 3.6706\n",
      "Epoch [18/50], Iter [255/439] Loss: 2.9381, average_loss: 3.6753\n",
      "Epoch [18/50], Iter [260/439] Loss: 2.3374, average_loss: 3.6783\n",
      "Epoch [18/50], Iter [265/439] Loss: 4.1469, average_loss: 3.6758\n",
      "Epoch [18/50], Iter [270/439] Loss: 4.0176, average_loss: 3.6747\n",
      "Epoch [18/50], Iter [275/439] Loss: 2.9772, average_loss: 3.6646\n",
      "Epoch [18/50], Iter [280/439] Loss: 4.0086, average_loss: 3.6590\n",
      "Epoch [18/50], Iter [285/439] Loss: 5.4055, average_loss: 3.6608\n",
      "Epoch [18/50], Iter [290/439] Loss: 5.4035, average_loss: 3.6739\n",
      "Epoch [18/50], Iter [295/439] Loss: 2.9363, average_loss: 3.6788\n",
      "Epoch [18/50], Iter [300/439] Loss: 3.6138, average_loss: 3.6941\n",
      "Epoch [18/50], Iter [305/439] Loss: 1.9440, average_loss: 3.6831\n",
      "Epoch [18/50], Iter [310/439] Loss: 4.8806, average_loss: 3.6876\n",
      "Epoch [18/50], Iter [315/439] Loss: 3.1772, average_loss: 3.7005\n",
      "Epoch [18/50], Iter [320/439] Loss: 5.5113, average_loss: 3.6993\n",
      "Epoch [18/50], Iter [325/439] Loss: 1.5696, average_loss: 3.6916\n",
      "Epoch [18/50], Iter [330/439] Loss: 2.4173, average_loss: 3.7064\n",
      "Epoch [18/50], Iter [335/439] Loss: 3.6438, average_loss: 3.7005\n",
      "Epoch [18/50], Iter [340/439] Loss: 3.6759, average_loss: 3.6962\n",
      "Epoch [18/50], Iter [345/439] Loss: 5.5619, average_loss: 3.7052\n",
      "Epoch [18/50], Iter [350/439] Loss: 3.6122, average_loss: 3.6986\n",
      "Epoch [18/50], Iter [355/439] Loss: 4.7223, average_loss: 3.7027\n",
      "Epoch [18/50], Iter [360/439] Loss: 3.7638, average_loss: 3.7069\n",
      "Epoch [18/50], Iter [365/439] Loss: 3.5177, average_loss: 3.7054\n",
      "Epoch [18/50], Iter [370/439] Loss: 5.5262, average_loss: 3.7218\n",
      "Epoch [18/50], Iter [375/439] Loss: 4.0298, average_loss: 3.7209\n",
      "Epoch [18/50], Iter [380/439] Loss: 4.2426, average_loss: 3.7174\n",
      "Epoch [18/50], Iter [385/439] Loss: 4.0924, average_loss: 3.7205\n",
      "Epoch [18/50], Iter [390/439] Loss: 4.1996, average_loss: 3.7175\n",
      "Epoch [18/50], Iter [395/439] Loss: 1.6642, average_loss: 3.7143\n",
      "Epoch [18/50], Iter [400/439] Loss: 4.0994, average_loss: 3.7234\n",
      "Epoch [18/50], Iter [405/439] Loss: 4.0222, average_loss: 3.7225\n",
      "Epoch [18/50], Iter [410/439] Loss: 3.6277, average_loss: 3.7195\n",
      "Epoch [18/50], Iter [415/439] Loss: 2.6626, average_loss: 3.7161\n",
      "Epoch [18/50], Iter [420/439] Loss: 3.4173, average_loss: 3.7164\n",
      "Epoch [18/50], Iter [425/439] Loss: 3.4211, average_loss: 3.7143\n",
      "Epoch [18/50], Iter [430/439] Loss: 4.8268, average_loss: 3.7093\n",
      "Epoch [18/50], Iter [435/439] Loss: 6.1333, average_loss: 3.7104\n",
      "Test epoch [18/50], average_loss: 3.7497\n",
      "Epoch [19/50], Iter [5/439] Loss: 3.2622, average_loss: 3.9909\n",
      "Epoch [19/50], Iter [10/439] Loss: 4.8356, average_loss: 4.2209\n",
      "Epoch [19/50], Iter [15/439] Loss: 4.5343, average_loss: 4.1038\n",
      "Epoch [19/50], Iter [20/439] Loss: 2.8039, average_loss: 3.8952\n",
      "Epoch [19/50], Iter [25/439] Loss: 3.0638, average_loss: 3.7469\n",
      "Epoch [19/50], Iter [30/439] Loss: 2.9746, average_loss: 3.6179\n",
      "Epoch [19/50], Iter [35/439] Loss: 2.1555, average_loss: 3.5396\n",
      "Epoch [19/50], Iter [40/439] Loss: 1.7874, average_loss: 3.6255\n",
      "Epoch [19/50], Iter [45/439] Loss: 3.4184, average_loss: 3.7085\n",
      "Epoch [19/50], Iter [50/439] Loss: 3.0420, average_loss: 3.6810\n",
      "Epoch [19/50], Iter [55/439] Loss: 2.9063, average_loss: 3.6221\n",
      "Epoch [19/50], Iter [60/439] Loss: 3.5766, average_loss: 3.5950\n",
      "Epoch [19/50], Iter [65/439] Loss: 3.2870, average_loss: 3.5996\n",
      "Epoch [19/50], Iter [70/439] Loss: 2.7044, average_loss: 3.6161\n",
      "Epoch [19/50], Iter [75/439] Loss: 4.3621, average_loss: 3.6384\n",
      "Epoch [19/50], Iter [80/439] Loss: 4.1999, average_loss: 3.6067\n",
      "Epoch [19/50], Iter [85/439] Loss: 2.8588, average_loss: 3.5855\n",
      "Epoch [19/50], Iter [90/439] Loss: 3.9027, average_loss: 3.6304\n",
      "Epoch [19/50], Iter [95/439] Loss: 2.3426, average_loss: 3.6030\n",
      "Epoch [19/50], Iter [100/439] Loss: 5.2900, average_loss: 3.6410\n",
      "Epoch [19/50], Iter [105/439] Loss: 3.9177, average_loss: 3.6471\n",
      "Epoch [19/50], Iter [110/439] Loss: 5.2249, average_loss: 3.6416\n",
      "Epoch [19/50], Iter [115/439] Loss: 4.7554, average_loss: 3.6330\n",
      "Epoch [19/50], Iter [120/439] Loss: 3.1202, average_loss: 3.6280\n",
      "Epoch [19/50], Iter [125/439] Loss: 4.0767, average_loss: 3.6383\n",
      "Epoch [19/50], Iter [130/439] Loss: 2.9264, average_loss: 3.6352\n",
      "Epoch [19/50], Iter [135/439] Loss: 3.9479, average_loss: 3.6395\n",
      "Epoch [19/50], Iter [140/439] Loss: 4.8851, average_loss: 3.6382\n",
      "Epoch [19/50], Iter [145/439] Loss: 3.4075, average_loss: 3.6747\n",
      "Epoch [19/50], Iter [150/439] Loss: 2.3802, average_loss: 3.6682\n",
      "Epoch [19/50], Iter [155/439] Loss: 3.2326, average_loss: 3.6498\n",
      "Epoch [19/50], Iter [160/439] Loss: 3.2759, average_loss: 3.6470\n",
      "Epoch [19/50], Iter [165/439] Loss: 4.6957, average_loss: 3.6627\n",
      "Epoch [19/50], Iter [170/439] Loss: 2.8594, average_loss: 3.6512\n",
      "Epoch [19/50], Iter [175/439] Loss: 4.4028, average_loss: 3.6678\n",
      "Epoch [19/50], Iter [180/439] Loss: 4.7222, average_loss: 3.6762\n",
      "Epoch [19/50], Iter [185/439] Loss: 3.6114, average_loss: 3.6578\n",
      "Epoch [19/50], Iter [190/439] Loss: 2.2049, average_loss: 3.6526\n",
      "Epoch [19/50], Iter [195/439] Loss: 5.1793, average_loss: 3.6647\n",
      "Epoch [19/50], Iter [200/439] Loss: 2.8786, average_loss: 3.6647\n",
      "Epoch [19/50], Iter [205/439] Loss: 2.1250, average_loss: 3.6783\n",
      "Epoch [19/50], Iter [210/439] Loss: 6.1844, average_loss: 3.7037\n",
      "Epoch [19/50], Iter [215/439] Loss: 4.2593, average_loss: 3.7036\n",
      "Epoch [19/50], Iter [220/439] Loss: 2.1505, average_loss: 3.6983\n",
      "Epoch [19/50], Iter [225/439] Loss: 1.9613, average_loss: 3.7005\n",
      "Epoch [19/50], Iter [230/439] Loss: 4.3842, average_loss: 3.7234\n",
      "Epoch [19/50], Iter [235/439] Loss: 3.8316, average_loss: 3.7160\n",
      "Epoch [19/50], Iter [240/439] Loss: 3.4371, average_loss: 3.7085\n",
      "Epoch [19/50], Iter [245/439] Loss: 3.1127, average_loss: 3.7051\n",
      "Epoch [19/50], Iter [250/439] Loss: 3.4152, average_loss: 3.6914\n",
      "Epoch [19/50], Iter [255/439] Loss: 3.1102, average_loss: 3.6813\n",
      "Epoch [19/50], Iter [260/439] Loss: 5.0507, average_loss: 3.6850\n",
      "Epoch [19/50], Iter [265/439] Loss: 6.2108, average_loss: 3.6874\n",
      "Epoch [19/50], Iter [270/439] Loss: 3.1520, average_loss: 3.6805\n",
      "Epoch [19/50], Iter [275/439] Loss: 2.3072, average_loss: 3.6718\n",
      "Epoch [19/50], Iter [280/439] Loss: 4.2925, average_loss: 3.6741\n",
      "Epoch [19/50], Iter [285/439] Loss: 3.7164, average_loss: 3.6772\n",
      "Epoch [19/50], Iter [290/439] Loss: 2.9259, average_loss: 3.6581\n",
      "Epoch [19/50], Iter [295/439] Loss: 3.8161, average_loss: 3.6666\n",
      "Epoch [19/50], Iter [300/439] Loss: 4.8295, average_loss: 3.6771\n",
      "Epoch [19/50], Iter [305/439] Loss: 3.6723, average_loss: 3.6702\n",
      "Epoch [19/50], Iter [310/439] Loss: 4.1004, average_loss: 3.6671\n",
      "Epoch [19/50], Iter [315/439] Loss: 2.8911, average_loss: 3.6647\n",
      "Epoch [19/50], Iter [320/439] Loss: 2.3578, average_loss: 3.6529\n",
      "Epoch [19/50], Iter [325/439] Loss: 3.1852, average_loss: 3.6421\n",
      "Epoch [19/50], Iter [330/439] Loss: 3.6607, average_loss: 3.6248\n",
      "Epoch [19/50], Iter [335/439] Loss: 4.1641, average_loss: 3.6273\n",
      "Epoch [19/50], Iter [340/439] Loss: 3.8976, average_loss: 3.6327\n",
      "Epoch [19/50], Iter [345/439] Loss: 4.0884, average_loss: 3.6364\n",
      "Epoch [19/50], Iter [350/439] Loss: 2.4258, average_loss: 3.6462\n",
      "Epoch [19/50], Iter [355/439] Loss: 4.5502, average_loss: 3.6463\n",
      "Epoch [19/50], Iter [360/439] Loss: 2.8610, average_loss: 3.6390\n",
      "Epoch [19/50], Iter [365/439] Loss: 3.9180, average_loss: 3.6469\n",
      "Epoch [19/50], Iter [370/439] Loss: 3.1929, average_loss: 3.6439\n",
      "Epoch [19/50], Iter [375/439] Loss: 6.0023, average_loss: 3.6499\n",
      "Epoch [19/50], Iter [380/439] Loss: 2.9339, average_loss: 3.6448\n",
      "Epoch [19/50], Iter [385/439] Loss: 3.2140, average_loss: 3.6463\n",
      "Epoch [19/50], Iter [390/439] Loss: 2.1602, average_loss: 3.6352\n",
      "Epoch [19/50], Iter [395/439] Loss: 3.3804, average_loss: 3.6351\n",
      "Epoch [19/50], Iter [400/439] Loss: 2.5862, average_loss: 3.6365\n",
      "Epoch [19/50], Iter [405/439] Loss: 2.2733, average_loss: 3.6321\n",
      "Epoch [19/50], Iter [410/439] Loss: 5.4423, average_loss: 3.6341\n",
      "Epoch [19/50], Iter [415/439] Loss: 3.2476, average_loss: 3.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Iter [420/439] Loss: 2.8943, average_loss: 3.6337\n",
      "Epoch [19/50], Iter [425/439] Loss: 3.0486, average_loss: 3.6312\n",
      "Epoch [19/50], Iter [430/439] Loss: 4.1919, average_loss: 3.6394\n",
      "Epoch [19/50], Iter [435/439] Loss: 3.7020, average_loss: 3.6430\n",
      "Test epoch [19/50], average_loss: 3.7469\n",
      "Epoch [20/50], Iter [5/439] Loss: 2.8700, average_loss: 2.9292\n",
      "Epoch [20/50], Iter [10/439] Loss: 3.5862, average_loss: 3.0988\n",
      "Epoch [20/50], Iter [15/439] Loss: 3.7321, average_loss: 3.1892\n",
      "Epoch [20/50], Iter [20/439] Loss: 2.2241, average_loss: 3.2270\n",
      "Epoch [20/50], Iter [25/439] Loss: 3.0419, average_loss: 3.2845\n",
      "Epoch [20/50], Iter [30/439] Loss: 2.7550, average_loss: 3.4614\n",
      "Epoch [20/50], Iter [35/439] Loss: 3.6200, average_loss: 3.3725\n",
      "Epoch [20/50], Iter [40/439] Loss: 5.3345, average_loss: 3.4385\n",
      "Epoch [20/50], Iter [45/439] Loss: 7.0467, average_loss: 3.5002\n",
      "Epoch [20/50], Iter [50/439] Loss: 2.2898, average_loss: 3.4792\n",
      "Epoch [20/50], Iter [55/439] Loss: 2.9952, average_loss: 3.4508\n",
      "Epoch [20/50], Iter [60/439] Loss: 4.2085, average_loss: 3.4801\n",
      "Epoch [20/50], Iter [65/439] Loss: 2.5378, average_loss: 3.5116\n",
      "Epoch [20/50], Iter [70/439] Loss: 3.9569, average_loss: 3.5690\n",
      "Epoch [20/50], Iter [75/439] Loss: 4.0554, average_loss: 3.5213\n",
      "Epoch [20/50], Iter [80/439] Loss: 2.8050, average_loss: 3.4876\n",
      "Epoch [20/50], Iter [85/439] Loss: 3.6256, average_loss: 3.4964\n",
      "Epoch [20/50], Iter [90/439] Loss: 3.1944, average_loss: 3.5069\n",
      "Epoch [20/50], Iter [95/439] Loss: 3.2538, average_loss: 3.5304\n",
      "Epoch [20/50], Iter [100/439] Loss: 3.7006, average_loss: 3.5454\n",
      "Epoch [20/50], Iter [105/439] Loss: 3.9499, average_loss: 3.5493\n",
      "Epoch [20/50], Iter [110/439] Loss: 5.2231, average_loss: 3.5935\n",
      "Epoch [20/50], Iter [115/439] Loss: 2.9280, average_loss: 3.6050\n",
      "Epoch [20/50], Iter [120/439] Loss: 4.6168, average_loss: 3.5976\n",
      "Epoch [20/50], Iter [125/439] Loss: 4.0331, average_loss: 3.6154\n",
      "Epoch [20/50], Iter [130/439] Loss: 4.1788, average_loss: 3.6435\n",
      "Epoch [20/50], Iter [135/439] Loss: 3.9357, average_loss: 3.6332\n",
      "Epoch [20/50], Iter [140/439] Loss: 3.0825, average_loss: 3.6249\n",
      "Epoch [20/50], Iter [145/439] Loss: 3.1310, average_loss: 3.6082\n",
      "Epoch [20/50], Iter [150/439] Loss: 3.4004, average_loss: 3.6010\n",
      "Epoch [20/50], Iter [155/439] Loss: 3.6838, average_loss: 3.5743\n",
      "Epoch [20/50], Iter [160/439] Loss: 3.4194, average_loss: 3.5768\n",
      "Epoch [20/50], Iter [165/439] Loss: 3.7065, average_loss: 3.5830\n",
      "Epoch [20/50], Iter [170/439] Loss: 4.4115, average_loss: 3.5780\n",
      "Epoch [20/50], Iter [175/439] Loss: 4.7508, average_loss: 3.5835\n",
      "Epoch [20/50], Iter [180/439] Loss: 3.7712, average_loss: 3.5679\n",
      "Epoch [20/50], Iter [185/439] Loss: 6.1173, average_loss: 3.6150\n",
      "Epoch [20/50], Iter [190/439] Loss: 2.8696, average_loss: 3.5922\n",
      "Epoch [20/50], Iter [195/439] Loss: 2.6904, average_loss: 3.5911\n",
      "Epoch [20/50], Iter [200/439] Loss: 1.8537, average_loss: 3.5890\n",
      "Epoch [20/50], Iter [205/439] Loss: 3.7501, average_loss: 3.5928\n",
      "Epoch [20/50], Iter [210/439] Loss: 3.9470, average_loss: 3.5938\n",
      "Epoch [20/50], Iter [215/439] Loss: 3.4354, average_loss: 3.6002\n",
      "Epoch [20/50], Iter [220/439] Loss: 3.8275, average_loss: 3.6053\n",
      "Epoch [20/50], Iter [225/439] Loss: 5.2558, average_loss: 3.5915\n",
      "Epoch [20/50], Iter [230/439] Loss: 4.6734, average_loss: 3.5990\n",
      "Epoch [20/50], Iter [235/439] Loss: 2.6076, average_loss: 3.5815\n",
      "Epoch [20/50], Iter [240/439] Loss: 4.2048, average_loss: 3.5903\n",
      "Epoch [20/50], Iter [245/439] Loss: 2.6284, average_loss: 3.5855\n",
      "Epoch [20/50], Iter [250/439] Loss: 4.6156, average_loss: 3.5801\n",
      "Epoch [20/50], Iter [255/439] Loss: 4.3072, average_loss: 3.5941\n",
      "Epoch [20/50], Iter [260/439] Loss: 3.6314, average_loss: 3.6016\n",
      "Epoch [20/50], Iter [265/439] Loss: 3.1665, average_loss: 3.6135\n",
      "Epoch [20/50], Iter [270/439] Loss: 3.5695, average_loss: 3.6160\n",
      "Epoch [20/50], Iter [275/439] Loss: 3.4610, average_loss: 3.6106\n",
      "Epoch [20/50], Iter [280/439] Loss: 3.5923, average_loss: 3.6167\n",
      "Epoch [20/50], Iter [285/439] Loss: 7.0130, average_loss: 3.6241\n",
      "Epoch [20/50], Iter [290/439] Loss: 3.6863, average_loss: 3.6207\n",
      "Epoch [20/50], Iter [295/439] Loss: 2.5381, average_loss: 3.6110\n",
      "Epoch [20/50], Iter [300/439] Loss: 6.4464, average_loss: 3.6168\n",
      "Epoch [20/50], Iter [305/439] Loss: 2.5209, average_loss: 3.6044\n",
      "Epoch [20/50], Iter [310/439] Loss: 2.3957, average_loss: 3.6027\n",
      "Epoch [20/50], Iter [315/439] Loss: 4.6485, average_loss: 3.6075\n",
      "Epoch [20/50], Iter [320/439] Loss: 4.0632, average_loss: 3.6008\n",
      "Epoch [20/50], Iter [325/439] Loss: 3.8983, average_loss: 3.6081\n",
      "Epoch [20/50], Iter [330/439] Loss: 3.8176, average_loss: 3.6095\n",
      "Epoch [20/50], Iter [335/439] Loss: 3.9166, average_loss: 3.6141\n",
      "Epoch [20/50], Iter [340/439] Loss: 4.2577, average_loss: 3.6176\n",
      "Epoch [20/50], Iter [345/439] Loss: 2.1522, average_loss: 3.6163\n",
      "Epoch [20/50], Iter [350/439] Loss: 3.0615, average_loss: 3.6082\n",
      "Epoch [20/50], Iter [355/439] Loss: 4.2950, average_loss: 3.6070\n",
      "Epoch [20/50], Iter [360/439] Loss: 3.1722, average_loss: 3.6102\n",
      "Epoch [20/50], Iter [365/439] Loss: 3.8643, average_loss: 3.6103\n",
      "Epoch [20/50], Iter [370/439] Loss: 3.4750, average_loss: 3.6051\n",
      "Epoch [20/50], Iter [375/439] Loss: 2.2503, average_loss: 3.5957\n",
      "Epoch [20/50], Iter [380/439] Loss: 3.3778, average_loss: 3.5881\n",
      "Epoch [20/50], Iter [385/439] Loss: 2.5745, average_loss: 3.5896\n",
      "Epoch [20/50], Iter [390/439] Loss: 4.4973, average_loss: 3.5959\n",
      "Epoch [20/50], Iter [395/439] Loss: 6.3217, average_loss: 3.6061\n",
      "Epoch [20/50], Iter [400/439] Loss: 3.2819, average_loss: 3.6058\n",
      "Epoch [20/50], Iter [405/439] Loss: 2.4503, average_loss: 3.5993\n",
      "Epoch [20/50], Iter [410/439] Loss: 3.8412, average_loss: 3.6008\n",
      "Epoch [20/50], Iter [415/439] Loss: 3.1570, average_loss: 3.5942\n",
      "Epoch [20/50], Iter [420/439] Loss: 4.0490, average_loss: 3.5955\n",
      "Epoch [20/50], Iter [425/439] Loss: 2.2147, average_loss: 3.5924\n",
      "Epoch [20/50], Iter [430/439] Loss: 4.2507, average_loss: 3.5909\n",
      "Epoch [20/50], Iter [435/439] Loss: 4.4044, average_loss: 3.5961\n",
      "Test epoch [20/50], average_loss: 3.6491\n",
      "Epoch [21/50], Iter [5/439] Loss: 3.4193, average_loss: 3.4194\n",
      "Epoch [21/50], Iter [10/439] Loss: 3.5343, average_loss: 3.3153\n",
      "Epoch [21/50], Iter [15/439] Loss: 3.3704, average_loss: 3.8657\n",
      "Epoch [21/50], Iter [20/439] Loss: 8.0044, average_loss: 4.2426\n",
      "Epoch [21/50], Iter [25/439] Loss: 4.1224, average_loss: 4.0036\n",
      "Epoch [21/50], Iter [30/439] Loss: 3.9975, average_loss: 3.8567\n",
      "Epoch [21/50], Iter [35/439] Loss: 3.4539, average_loss: 3.8273\n",
      "Epoch [21/50], Iter [40/439] Loss: 2.3122, average_loss: 3.6905\n",
      "Epoch [21/50], Iter [45/439] Loss: 1.9541, average_loss: 3.5938\n",
      "Epoch [21/50], Iter [50/439] Loss: 2.8046, average_loss: 3.5871\n",
      "Epoch [21/50], Iter [55/439] Loss: 2.3279, average_loss: 3.5442\n",
      "Epoch [21/50], Iter [60/439] Loss: 1.8182, average_loss: 3.5065\n",
      "Epoch [21/50], Iter [65/439] Loss: 2.6253, average_loss: 3.4967\n",
      "Epoch [21/50], Iter [70/439] Loss: 4.9582, average_loss: 3.5655\n",
      "Epoch [21/50], Iter [75/439] Loss: 4.0367, average_loss: 3.5330\n",
      "Epoch [21/50], Iter [80/439] Loss: 3.7522, average_loss: 3.4934\n",
      "Epoch [21/50], Iter [85/439] Loss: 3.8776, average_loss: 3.4704\n",
      "Epoch [21/50], Iter [90/439] Loss: 4.5955, average_loss: 3.5180\n",
      "Epoch [21/50], Iter [95/439] Loss: 3.4928, average_loss: 3.5135\n",
      "Epoch [21/50], Iter [100/439] Loss: 5.4979, average_loss: 3.5235\n",
      "Epoch [21/50], Iter [105/439] Loss: 3.1576, average_loss: 3.5479\n",
      "Epoch [21/50], Iter [110/439] Loss: 3.3333, average_loss: 3.5945\n",
      "Epoch [21/50], Iter [115/439] Loss: 5.9075, average_loss: 3.6087\n",
      "Epoch [21/50], Iter [120/439] Loss: 3.5634, average_loss: 3.6563\n",
      "Epoch [21/50], Iter [125/439] Loss: 2.6979, average_loss: 3.6478\n",
      "Epoch [21/50], Iter [130/439] Loss: 3.5161, average_loss: 3.6534\n",
      "Epoch [21/50], Iter [135/439] Loss: 3.3249, average_loss: 3.6461\n",
      "Epoch [21/50], Iter [140/439] Loss: 4.1097, average_loss: 3.6227\n",
      "Epoch [21/50], Iter [145/439] Loss: 5.0338, average_loss: 3.6541\n",
      "Epoch [21/50], Iter [150/439] Loss: 3.9162, average_loss: 3.6469\n",
      "Epoch [21/50], Iter [155/439] Loss: 6.3244, average_loss: 3.6784\n",
      "Epoch [21/50], Iter [160/439] Loss: 2.7857, average_loss: 3.6673\n",
      "Epoch [21/50], Iter [165/439] Loss: 3.1411, average_loss: 3.6400\n",
      "Epoch [21/50], Iter [170/439] Loss: 3.6547, average_loss: 3.6543\n",
      "Epoch [21/50], Iter [175/439] Loss: 6.5461, average_loss: 3.6747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Iter [180/439] Loss: 7.3323, average_loss: 3.7044\n",
      "Epoch [21/50], Iter [185/439] Loss: 5.2147, average_loss: 3.7190\n",
      "Epoch [21/50], Iter [190/439] Loss: 2.2886, average_loss: 3.7200\n",
      "Epoch [21/50], Iter [195/439] Loss: 3.7143, average_loss: 3.7178\n",
      "Epoch [21/50], Iter [200/439] Loss: 3.3032, average_loss: 3.7081\n",
      "Epoch [21/50], Iter [205/439] Loss: 6.9444, average_loss: 3.7255\n",
      "Epoch [21/50], Iter [210/439] Loss: 2.4699, average_loss: 3.7059\n",
      "Epoch [21/50], Iter [215/439] Loss: 4.2235, average_loss: 3.7087\n",
      "Epoch [21/50], Iter [220/439] Loss: 3.2088, average_loss: 3.6948\n",
      "Epoch [21/50], Iter [225/439] Loss: 3.3314, average_loss: 3.6822\n",
      "Epoch [21/50], Iter [230/439] Loss: 3.4822, average_loss: 3.6881\n",
      "Epoch [21/50], Iter [235/439] Loss: 3.8667, average_loss: 3.6780\n",
      "Epoch [21/50], Iter [240/439] Loss: 2.2389, average_loss: 3.6739\n",
      "Epoch [21/50], Iter [245/439] Loss: 2.6508, average_loss: 3.6669\n",
      "Epoch [21/50], Iter [250/439] Loss: 7.1404, average_loss: 3.6817\n",
      "Epoch [21/50], Iter [255/439] Loss: 3.1154, average_loss: 3.6692\n",
      "Epoch [21/50], Iter [260/439] Loss: 2.7434, average_loss: 3.6550\n",
      "Epoch [21/50], Iter [265/439] Loss: 4.1950, average_loss: 3.6583\n",
      "Epoch [21/50], Iter [270/439] Loss: 3.1243, average_loss: 3.6595\n",
      "Epoch [21/50], Iter [275/439] Loss: 3.4064, average_loss: 3.6659\n",
      "Epoch [21/50], Iter [280/439] Loss: 2.4131, average_loss: 3.6671\n",
      "Epoch [21/50], Iter [285/439] Loss: 2.7394, average_loss: 3.6589\n",
      "Epoch [21/50], Iter [290/439] Loss: 4.3277, average_loss: 3.6481\n",
      "Epoch [21/50], Iter [295/439] Loss: 3.3680, average_loss: 3.6387\n",
      "Epoch [21/50], Iter [300/439] Loss: 4.5149, average_loss: 3.6345\n",
      "Epoch [21/50], Iter [305/439] Loss: 3.7076, average_loss: 3.6410\n",
      "Epoch [21/50], Iter [310/439] Loss: 2.6756, average_loss: 3.6330\n",
      "Epoch [21/50], Iter [315/439] Loss: 3.7159, average_loss: 3.6397\n",
      "Epoch [21/50], Iter [320/439] Loss: 2.3458, average_loss: 3.6360\n",
      "Epoch [21/50], Iter [325/439] Loss: 2.9625, average_loss: 3.6438\n",
      "Epoch [21/50], Iter [330/439] Loss: 4.4767, average_loss: 3.6438\n",
      "Epoch [21/50], Iter [335/439] Loss: 4.4847, average_loss: 3.6447\n",
      "Epoch [21/50], Iter [340/439] Loss: 1.9903, average_loss: 3.6328\n",
      "Epoch [21/50], Iter [345/439] Loss: 3.7745, average_loss: 3.6248\n",
      "Epoch [21/50], Iter [350/439] Loss: 2.9082, average_loss: 3.6207\n",
      "Epoch [21/50], Iter [355/439] Loss: 4.4227, average_loss: 3.6179\n",
      "Epoch [21/50], Iter [360/439] Loss: 4.6970, average_loss: 3.6183\n",
      "Epoch [21/50], Iter [365/439] Loss: 2.4454, average_loss: 3.6090\n",
      "Epoch [21/50], Iter [370/439] Loss: 4.2778, average_loss: 3.6063\n",
      "Epoch [21/50], Iter [375/439] Loss: 5.6700, average_loss: 3.6034\n",
      "Epoch [21/50], Iter [380/439] Loss: 2.0541, average_loss: 3.5992\n",
      "Epoch [21/50], Iter [385/439] Loss: 3.0193, average_loss: 3.6004\n",
      "Epoch [21/50], Iter [390/439] Loss: 4.2010, average_loss: 3.6128\n",
      "Epoch [21/50], Iter [395/439] Loss: 2.3863, average_loss: 3.6113\n",
      "Epoch [21/50], Iter [400/439] Loss: 2.1258, average_loss: 3.6087\n",
      "Epoch [21/50], Iter [405/439] Loss: 2.2979, average_loss: 3.6173\n",
      "Epoch [21/50], Iter [410/439] Loss: 4.1781, average_loss: 3.6219\n",
      "Epoch [21/50], Iter [415/439] Loss: 3.6749, average_loss: 3.6240\n",
      "Epoch [21/50], Iter [420/439] Loss: 4.0014, average_loss: 3.6181\n",
      "Epoch [21/50], Iter [425/439] Loss: 3.0458, average_loss: 3.6152\n",
      "Epoch [21/50], Iter [430/439] Loss: 3.2992, average_loss: 3.6251\n",
      "Epoch [21/50], Iter [435/439] Loss: 7.2381, average_loss: 3.6328\n",
      "Test epoch [21/50], average_loss: 3.5936\n",
      "Epoch [22/50], Iter [5/439] Loss: 3.1239, average_loss: 3.2111\n",
      "Epoch [22/50], Iter [10/439] Loss: 2.6043, average_loss: 3.3884\n",
      "Epoch [22/50], Iter [15/439] Loss: 5.7804, average_loss: 3.7300\n",
      "Epoch [22/50], Iter [20/439] Loss: 4.3672, average_loss: 3.7872\n",
      "Epoch [22/50], Iter [25/439] Loss: 3.8518, average_loss: 3.8165\n",
      "Epoch [22/50], Iter [30/439] Loss: 2.4318, average_loss: 3.7434\n",
      "Epoch [22/50], Iter [35/439] Loss: 4.7288, average_loss: 3.7683\n",
      "Epoch [22/50], Iter [40/439] Loss: 1.8450, average_loss: 3.6487\n",
      "Epoch [22/50], Iter [45/439] Loss: 5.0874, average_loss: 3.7183\n",
      "Epoch [22/50], Iter [50/439] Loss: 2.3156, average_loss: 3.6327\n",
      "Epoch [22/50], Iter [55/439] Loss: 2.0601, average_loss: 3.5601\n",
      "Epoch [22/50], Iter [60/439] Loss: 2.6086, average_loss: 3.5771\n",
      "Epoch [22/50], Iter [65/439] Loss: 3.1805, average_loss: 3.6146\n",
      "Epoch [22/50], Iter [70/439] Loss: 2.3468, average_loss: 3.6244\n",
      "Epoch [22/50], Iter [75/439] Loss: 3.8905, average_loss: 3.5938\n",
      "Epoch [22/50], Iter [80/439] Loss: 3.5785, average_loss: 3.5576\n",
      "Epoch [22/50], Iter [85/439] Loss: 3.1878, average_loss: 3.5379\n",
      "Epoch [22/50], Iter [90/439] Loss: 4.9607, average_loss: 3.5539\n",
      "Epoch [22/50], Iter [95/439] Loss: 2.6844, average_loss: 3.5417\n",
      "Epoch [22/50], Iter [100/439] Loss: 5.3741, average_loss: 3.5430\n",
      "Epoch [22/50], Iter [105/439] Loss: 3.4664, average_loss: 3.5242\n",
      "Epoch [22/50], Iter [110/439] Loss: 3.5979, average_loss: 3.5323\n",
      "Epoch [22/50], Iter [115/439] Loss: 3.0032, average_loss: 3.5253\n",
      "Epoch [22/50], Iter [120/439] Loss: 3.2527, average_loss: 3.4913\n",
      "Epoch [22/50], Iter [125/439] Loss: 3.0099, average_loss: 3.5119\n",
      "Epoch [22/50], Iter [130/439] Loss: 3.5646, average_loss: 3.5026\n",
      "Epoch [22/50], Iter [135/439] Loss: 4.4118, average_loss: 3.5159\n",
      "Epoch [22/50], Iter [140/439] Loss: 2.3061, average_loss: 3.4881\n",
      "Epoch [22/50], Iter [145/439] Loss: 2.8311, average_loss: 3.4872\n",
      "Epoch [22/50], Iter [150/439] Loss: 4.0691, average_loss: 3.4823\n",
      "Epoch [22/50], Iter [155/439] Loss: 4.5663, average_loss: 3.4801\n",
      "Epoch [22/50], Iter [160/439] Loss: 2.0837, average_loss: 3.4554\n",
      "Epoch [22/50], Iter [165/439] Loss: 3.1596, average_loss: 3.4583\n",
      "Epoch [22/50], Iter [170/439] Loss: 3.8204, average_loss: 3.5047\n",
      "Epoch [22/50], Iter [175/439] Loss: 2.7939, average_loss: 3.4949\n",
      "Epoch [22/50], Iter [180/439] Loss: 3.9167, average_loss: 3.5046\n",
      "Epoch [22/50], Iter [185/439] Loss: 4.4708, average_loss: 3.5107\n",
      "Epoch [22/50], Iter [190/439] Loss: 2.0935, average_loss: 3.5047\n",
      "Epoch [22/50], Iter [195/439] Loss: 3.7399, average_loss: 3.5008\n",
      "Epoch [22/50], Iter [200/439] Loss: 4.6625, average_loss: 3.5108\n",
      "Epoch [22/50], Iter [205/439] Loss: 4.1548, average_loss: 3.5335\n",
      "Epoch [22/50], Iter [210/439] Loss: 3.7603, average_loss: 3.5358\n",
      "Epoch [22/50], Iter [215/439] Loss: 3.9721, average_loss: 3.5334\n",
      "Epoch [22/50], Iter [220/439] Loss: 4.7149, average_loss: 3.5570\n",
      "Epoch [22/50], Iter [225/439] Loss: 2.5289, average_loss: 3.5507\n",
      "Epoch [22/50], Iter [230/439] Loss: 4.0628, average_loss: 3.5530\n",
      "Epoch [22/50], Iter [235/439] Loss: 5.1172, average_loss: 3.5575\n",
      "Epoch [22/50], Iter [240/439] Loss: 3.3418, average_loss: 3.5732\n",
      "Epoch [22/50], Iter [245/439] Loss: 4.0166, average_loss: 3.5692\n",
      "Epoch [22/50], Iter [250/439] Loss: 3.1695, average_loss: 3.5605\n",
      "Epoch [22/50], Iter [255/439] Loss: 2.6915, average_loss: 3.5478\n",
      "Epoch [22/50], Iter [260/439] Loss: 4.0191, average_loss: 3.5454\n",
      "Epoch [22/50], Iter [265/439] Loss: 3.7982, average_loss: 3.5460\n",
      "Epoch [22/50], Iter [270/439] Loss: 3.0179, average_loss: 3.5585\n",
      "Epoch [22/50], Iter [275/439] Loss: 4.6086, average_loss: 3.5793\n",
      "Epoch [22/50], Iter [280/439] Loss: 2.9558, average_loss: 3.5660\n",
      "Epoch [22/50], Iter [285/439] Loss: 3.3737, average_loss: 3.5633\n",
      "Epoch [22/50], Iter [290/439] Loss: 4.3732, average_loss: 3.5618\n",
      "Epoch [22/50], Iter [295/439] Loss: 4.0407, average_loss: 3.5624\n",
      "Epoch [22/50], Iter [300/439] Loss: 2.1166, average_loss: 3.5556\n",
      "Epoch [22/50], Iter [305/439] Loss: 3.2428, average_loss: 3.5580\n",
      "Epoch [22/50], Iter [310/439] Loss: 3.2284, average_loss: 3.5509\n",
      "Epoch [22/50], Iter [315/439] Loss: 2.9470, average_loss: 3.5492\n",
      "Epoch [22/50], Iter [320/439] Loss: 2.8687, average_loss: 3.5403\n",
      "Epoch [22/50], Iter [325/439] Loss: 4.9557, average_loss: 3.5371\n",
      "Epoch [22/50], Iter [330/439] Loss: 5.4595, average_loss: 3.5378\n",
      "Epoch [22/50], Iter [335/439] Loss: 3.0244, average_loss: 3.5319\n",
      "Epoch [22/50], Iter [340/439] Loss: 3.8116, average_loss: 3.5423\n",
      "Epoch [22/50], Iter [345/439] Loss: 3.2473, average_loss: 3.5350\n",
      "Epoch [22/50], Iter [350/439] Loss: 5.7927, average_loss: 3.5394\n",
      "Epoch [22/50], Iter [355/439] Loss: 3.8639, average_loss: 3.5365\n",
      "Epoch [22/50], Iter [360/439] Loss: 2.4259, average_loss: 3.5294\n",
      "Epoch [22/50], Iter [365/439] Loss: 2.9896, average_loss: 3.5272\n",
      "Epoch [22/50], Iter [370/439] Loss: 5.6541, average_loss: 3.5320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Iter [375/439] Loss: 2.9844, average_loss: 3.5279\n",
      "Epoch [22/50], Iter [380/439] Loss: 5.6508, average_loss: 3.5435\n",
      "Epoch [22/50], Iter [385/439] Loss: 3.0406, average_loss: 3.5499\n",
      "Epoch [22/50], Iter [390/439] Loss: 3.2593, average_loss: 3.5463\n",
      "Epoch [22/50], Iter [395/439] Loss: 3.0408, average_loss: 3.5466\n",
      "Epoch [22/50], Iter [400/439] Loss: 5.1030, average_loss: 3.5518\n",
      "Epoch [22/50], Iter [405/439] Loss: 2.4269, average_loss: 3.5540\n",
      "Epoch [22/50], Iter [410/439] Loss: 3.3307, average_loss: 3.5440\n",
      "Epoch [22/50], Iter [415/439] Loss: 2.1774, average_loss: 3.5377\n",
      "Epoch [22/50], Iter [420/439] Loss: 3.7464, average_loss: 3.5351\n",
      "Epoch [22/50], Iter [425/439] Loss: 1.9314, average_loss: 3.5379\n",
      "Epoch [22/50], Iter [430/439] Loss: 4.2721, average_loss: 3.5511\n",
      "Epoch [22/50], Iter [435/439] Loss: 4.6328, average_loss: 3.5540\n",
      "Test epoch [22/50], average_loss: 3.6491\n",
      "Epoch [23/50], Iter [5/439] Loss: 3.5099, average_loss: 3.7586\n",
      "Epoch [23/50], Iter [10/439] Loss: 3.2263, average_loss: 3.5420\n",
      "Epoch [23/50], Iter [15/439] Loss: 3.5343, average_loss: 3.4766\n",
      "Epoch [23/50], Iter [20/439] Loss: 3.5235, average_loss: 3.5904\n",
      "Epoch [23/50], Iter [25/439] Loss: 2.9412, average_loss: 3.5012\n",
      "Epoch [23/50], Iter [30/439] Loss: 4.4746, average_loss: 3.4745\n",
      "Epoch [23/50], Iter [35/439] Loss: 4.1857, average_loss: 3.4531\n",
      "Epoch [23/50], Iter [40/439] Loss: 1.9562, average_loss: 3.3400\n",
      "Epoch [23/50], Iter [45/439] Loss: 4.0676, average_loss: 3.4114\n",
      "Epoch [23/50], Iter [50/439] Loss: 2.9435, average_loss: 3.3834\n",
      "Epoch [23/50], Iter [55/439] Loss: 3.3784, average_loss: 3.3385\n",
      "Epoch [23/50], Iter [60/439] Loss: 3.5011, average_loss: 3.3568\n",
      "Epoch [23/50], Iter [65/439] Loss: 3.4768, average_loss: 3.4397\n",
      "Epoch [23/50], Iter [70/439] Loss: 3.9527, average_loss: 3.4472\n",
      "Epoch [23/50], Iter [75/439] Loss: 2.6839, average_loss: 3.4297\n",
      "Epoch [23/50], Iter [80/439] Loss: 3.0126, average_loss: 3.4167\n",
      "Epoch [23/50], Iter [85/439] Loss: 3.3748, average_loss: 3.4066\n",
      "Epoch [23/50], Iter [90/439] Loss: 4.6425, average_loss: 3.4033\n",
      "Epoch [23/50], Iter [95/439] Loss: 3.1075, average_loss: 3.4143\n",
      "Epoch [23/50], Iter [100/439] Loss: 4.1473, average_loss: 3.4426\n",
      "Epoch [23/50], Iter [105/439] Loss: 4.0160, average_loss: 3.4809\n",
      "Epoch [23/50], Iter [110/439] Loss: 2.3189, average_loss: 3.5232\n",
      "Epoch [23/50], Iter [115/439] Loss: 3.9079, average_loss: 3.5866\n",
      "Epoch [23/50], Iter [120/439] Loss: 3.1090, average_loss: 3.5839\n",
      "Epoch [23/50], Iter [125/439] Loss: 4.2048, average_loss: 3.5920\n",
      "Epoch [23/50], Iter [130/439] Loss: 2.4716, average_loss: 3.5888\n",
      "Epoch [23/50], Iter [135/439] Loss: 4.5843, average_loss: 3.5791\n",
      "Epoch [23/50], Iter [140/439] Loss: 3.4373, average_loss: 3.5817\n",
      "Epoch [23/50], Iter [145/439] Loss: 3.8585, average_loss: 3.5757\n",
      "Epoch [23/50], Iter [150/439] Loss: 2.1400, average_loss: 3.5454\n",
      "Epoch [23/50], Iter [155/439] Loss: 3.6158, average_loss: 3.5631\n",
      "Epoch [23/50], Iter [160/439] Loss: 2.1374, average_loss: 3.5499\n",
      "Epoch [23/50], Iter [165/439] Loss: 2.3834, average_loss: 3.5508\n",
      "Epoch [23/50], Iter [170/439] Loss: 3.6876, average_loss: 3.5385\n",
      "Epoch [23/50], Iter [175/439] Loss: 2.0987, average_loss: 3.5135\n",
      "Epoch [23/50], Iter [180/439] Loss: 2.9354, average_loss: 3.5084\n",
      "Epoch [23/50], Iter [185/439] Loss: 4.7307, average_loss: 3.5231\n",
      "Epoch [23/50], Iter [190/439] Loss: 2.8640, average_loss: 3.5133\n",
      "Epoch [23/50], Iter [195/439] Loss: 2.3484, average_loss: 3.5114\n",
      "Epoch [23/50], Iter [200/439] Loss: 3.1531, average_loss: 3.5068\n",
      "Epoch [23/50], Iter [205/439] Loss: 3.2474, average_loss: 3.5130\n",
      "Epoch [23/50], Iter [210/439] Loss: 4.5832, average_loss: 3.5192\n",
      "Epoch [23/50], Iter [215/439] Loss: 3.4355, average_loss: 3.5257\n",
      "Epoch [23/50], Iter [220/439] Loss: 4.8910, average_loss: 3.5351\n",
      "Epoch [23/50], Iter [225/439] Loss: 2.8543, average_loss: 3.5315\n",
      "Epoch [23/50], Iter [230/439] Loss: 3.4641, average_loss: 3.5200\n",
      "Epoch [23/50], Iter [235/439] Loss: 1.8361, average_loss: 3.4999\n",
      "Epoch [23/50], Iter [240/439] Loss: 2.4082, average_loss: 3.4856\n",
      "Epoch [23/50], Iter [245/439] Loss: 3.8059, average_loss: 3.4842\n",
      "Epoch [23/50], Iter [250/439] Loss: 3.2154, average_loss: 3.4787\n",
      "Epoch [23/50], Iter [255/439] Loss: 4.3500, average_loss: 3.4818\n",
      "Epoch [23/50], Iter [260/439] Loss: 5.2001, average_loss: 3.5065\n",
      "Epoch [23/50], Iter [265/439] Loss: 2.2723, average_loss: 3.5018\n",
      "Epoch [23/50], Iter [270/439] Loss: 7.3225, average_loss: 3.5143\n",
      "Epoch [23/50], Iter [275/439] Loss: 3.6127, average_loss: 3.5159\n",
      "Epoch [23/50], Iter [280/439] Loss: 3.6091, average_loss: 3.5234\n",
      "Epoch [23/50], Iter [285/439] Loss: 3.9471, average_loss: 3.5270\n",
      "Epoch [23/50], Iter [290/439] Loss: 3.8409, average_loss: 3.5185\n",
      "Epoch [23/50], Iter [295/439] Loss: 2.2671, average_loss: 3.5184\n",
      "Epoch [23/50], Iter [300/439] Loss: 2.6196, average_loss: 3.5108\n",
      "Epoch [23/50], Iter [305/439] Loss: 2.7454, average_loss: 3.4988\n",
      "Epoch [23/50], Iter [310/439] Loss: 2.6195, average_loss: 3.5007\n",
      "Epoch [23/50], Iter [315/439] Loss: 3.4468, average_loss: 3.4990\n",
      "Epoch [23/50], Iter [320/439] Loss: 2.4399, average_loss: 3.4912\n",
      "Epoch [23/50], Iter [325/439] Loss: 3.5484, average_loss: 3.4839\n",
      "Epoch [23/50], Iter [330/439] Loss: 3.3378, average_loss: 3.4815\n",
      "Epoch [23/50], Iter [335/439] Loss: 2.1841, average_loss: 3.4782\n",
      "Epoch [23/50], Iter [340/439] Loss: 4.6384, average_loss: 3.4792\n",
      "Epoch [23/50], Iter [345/439] Loss: 2.3176, average_loss: 3.4701\n",
      "Epoch [23/50], Iter [350/439] Loss: 3.1102, average_loss: 3.4663\n",
      "Epoch [23/50], Iter [355/439] Loss: 3.3116, average_loss: 3.4705\n",
      "Epoch [23/50], Iter [360/439] Loss: 4.8664, average_loss: 3.4851\n",
      "Epoch [23/50], Iter [365/439] Loss: 3.9981, average_loss: 3.4831\n",
      "Epoch [23/50], Iter [370/439] Loss: 2.8201, average_loss: 3.4787\n",
      "Epoch [23/50], Iter [375/439] Loss: 4.4952, average_loss: 3.4827\n",
      "Epoch [23/50], Iter [380/439] Loss: 3.5180, average_loss: 3.4870\n",
      "Epoch [23/50], Iter [385/439] Loss: 3.3644, average_loss: 3.4822\n",
      "Epoch [23/50], Iter [390/439] Loss: 2.7481, average_loss: 3.4827\n",
      "Epoch [23/50], Iter [395/439] Loss: 4.3935, average_loss: 3.4793\n",
      "Epoch [23/50], Iter [400/439] Loss: 3.5692, average_loss: 3.4927\n",
      "Epoch [23/50], Iter [405/439] Loss: 2.1740, average_loss: 3.4919\n",
      "Epoch [23/50], Iter [410/439] Loss: 4.5922, average_loss: 3.4941\n",
      "Epoch [23/50], Iter [415/439] Loss: 3.8951, average_loss: 3.4883\n",
      "Epoch [23/50], Iter [420/439] Loss: 3.9207, average_loss: 3.4943\n",
      "Epoch [23/50], Iter [425/439] Loss: 4.2686, average_loss: 3.4955\n",
      "Epoch [23/50], Iter [430/439] Loss: 6.1985, average_loss: 3.5016\n",
      "Epoch [23/50], Iter [435/439] Loss: 2.3561, average_loss: 3.5158\n",
      "Test epoch [23/50], average_loss: 3.5798\n",
      "Epoch [24/50], Iter [5/439] Loss: 3.7231, average_loss: 3.1326\n",
      "Epoch [24/50], Iter [10/439] Loss: 2.9679, average_loss: 3.5471\n",
      "Epoch [24/50], Iter [15/439] Loss: 1.7489, average_loss: 3.6250\n",
      "Epoch [24/50], Iter [20/439] Loss: 2.3483, average_loss: 3.8724\n",
      "Epoch [24/50], Iter [25/439] Loss: 2.6762, average_loss: 3.7757\n",
      "Epoch [24/50], Iter [30/439] Loss: 4.7518, average_loss: 3.7570\n",
      "Epoch [24/50], Iter [35/439] Loss: 3.3453, average_loss: 3.6401\n",
      "Epoch [24/50], Iter [40/439] Loss: 2.5837, average_loss: 3.5790\n",
      "Epoch [24/50], Iter [45/439] Loss: 5.3018, average_loss: 3.6696\n",
      "Epoch [24/50], Iter [50/439] Loss: 3.3403, average_loss: 3.6111\n",
      "Epoch [24/50], Iter [55/439] Loss: 4.5632, average_loss: 3.7384\n",
      "Epoch [24/50], Iter [60/439] Loss: 3.4398, average_loss: 3.6899\n",
      "Epoch [24/50], Iter [65/439] Loss: 2.2967, average_loss: 3.6132\n",
      "Epoch [24/50], Iter [70/439] Loss: 2.9432, average_loss: 3.6711\n",
      "Epoch [24/50], Iter [75/439] Loss: 3.1710, average_loss: 3.6036\n",
      "Epoch [24/50], Iter [80/439] Loss: 2.9736, average_loss: 3.5812\n",
      "Epoch [24/50], Iter [85/439] Loss: 2.6212, average_loss: 3.5609\n",
      "Epoch [24/50], Iter [90/439] Loss: 4.9489, average_loss: 3.5662\n",
      "Epoch [24/50], Iter [95/439] Loss: 6.4636, average_loss: 3.5826\n",
      "Epoch [24/50], Iter [100/439] Loss: 4.1370, average_loss: 3.6191\n",
      "Epoch [24/50], Iter [105/439] Loss: 2.6909, average_loss: 3.5777\n",
      "Epoch [24/50], Iter [110/439] Loss: 2.6398, average_loss: 3.5590\n",
      "Epoch [24/50], Iter [115/439] Loss: 1.9642, average_loss: 3.5463\n",
      "Epoch [24/50], Iter [120/439] Loss: 2.7621, average_loss: 3.5056\n",
      "Epoch [24/50], Iter [125/439] Loss: 3.0179, average_loss: 3.5098\n",
      "Epoch [24/50], Iter [130/439] Loss: 2.3707, average_loss: 3.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Iter [135/439] Loss: 4.1258, average_loss: 3.5068\n",
      "Epoch [24/50], Iter [140/439] Loss: 3.3972, average_loss: 3.4996\n",
      "Epoch [24/50], Iter [145/439] Loss: 5.4424, average_loss: 3.5125\n",
      "Epoch [24/50], Iter [150/439] Loss: 2.8309, average_loss: 3.5086\n",
      "Epoch [24/50], Iter [155/439] Loss: 2.7598, average_loss: 3.5134\n",
      "Epoch [24/50], Iter [160/439] Loss: 3.6139, average_loss: 3.4955\n",
      "Epoch [24/50], Iter [165/439] Loss: 2.6941, average_loss: 3.5122\n",
      "Epoch [24/50], Iter [170/439] Loss: 2.6657, average_loss: 3.5055\n",
      "Epoch [24/50], Iter [175/439] Loss: 3.8493, average_loss: 3.5126\n",
      "Epoch [24/50], Iter [180/439] Loss: 2.9015, average_loss: 3.5125\n",
      "Epoch [24/50], Iter [185/439] Loss: 4.1532, average_loss: 3.5070\n",
      "Epoch [24/50], Iter [190/439] Loss: 3.2622, average_loss: 3.4954\n",
      "Epoch [24/50], Iter [195/439] Loss: 1.6166, average_loss: 3.5107\n",
      "Epoch [24/50], Iter [200/439] Loss: 3.3515, average_loss: 3.5172\n",
      "Epoch [24/50], Iter [205/439] Loss: 2.5388, average_loss: 3.5156\n",
      "Epoch [24/50], Iter [210/439] Loss: 2.7309, average_loss: 3.5280\n",
      "Epoch [24/50], Iter [215/439] Loss: 3.2756, average_loss: 3.5288\n",
      "Epoch [24/50], Iter [220/439] Loss: 2.4189, average_loss: 3.5387\n",
      "Epoch [24/50], Iter [225/439] Loss: 2.7571, average_loss: 3.5236\n",
      "Epoch [24/50], Iter [230/439] Loss: 3.8101, average_loss: 3.5238\n",
      "Epoch [24/50], Iter [235/439] Loss: 5.0825, average_loss: 3.5288\n",
      "Epoch [24/50], Iter [240/439] Loss: 3.4014, average_loss: 3.5091\n",
      "Epoch [24/50], Iter [245/439] Loss: 5.7537, average_loss: 3.5250\n",
      "Epoch [24/50], Iter [250/439] Loss: 3.3361, average_loss: 3.5184\n",
      "Epoch [24/50], Iter [255/439] Loss: 2.3909, average_loss: 3.5215\n",
      "Epoch [24/50], Iter [260/439] Loss: 4.9379, average_loss: 3.5153\n",
      "Epoch [24/50], Iter [265/439] Loss: 3.1032, average_loss: 3.5103\n",
      "Epoch [24/50], Iter [270/439] Loss: 3.9540, average_loss: 3.4951\n",
      "Epoch [24/50], Iter [275/439] Loss: 1.8567, average_loss: 3.5011\n",
      "Epoch [24/50], Iter [280/439] Loss: 3.0545, average_loss: 3.4847\n",
      "Epoch [24/50], Iter [285/439] Loss: 4.8349, average_loss: 3.4899\n",
      "Epoch [24/50], Iter [290/439] Loss: 3.6825, average_loss: 3.4939\n",
      "Epoch [24/50], Iter [295/439] Loss: 2.3451, average_loss: 3.4949\n",
      "Epoch [24/50], Iter [300/439] Loss: 2.6601, average_loss: 3.4913\n",
      "Epoch [24/50], Iter [305/439] Loss: 3.7666, average_loss: 3.4910\n",
      "Epoch [24/50], Iter [310/439] Loss: 5.5643, average_loss: 3.4940\n",
      "Epoch [24/50], Iter [315/439] Loss: 3.2825, average_loss: 3.4824\n",
      "Epoch [24/50], Iter [320/439] Loss: 4.6112, average_loss: 3.4888\n",
      "Epoch [24/50], Iter [325/439] Loss: 2.4066, average_loss: 3.4791\n",
      "Epoch [24/50], Iter [330/439] Loss: 3.0640, average_loss: 3.4794\n",
      "Epoch [24/50], Iter [335/439] Loss: 3.5342, average_loss: 3.4759\n",
      "Epoch [24/50], Iter [340/439] Loss: 2.6607, average_loss: 3.4762\n",
      "Epoch [24/50], Iter [345/439] Loss: 5.0407, average_loss: 3.4723\n",
      "Epoch [24/50], Iter [350/439] Loss: 2.8135, average_loss: 3.4689\n",
      "Epoch [24/50], Iter [355/439] Loss: 2.6250, average_loss: 3.4699\n",
      "Epoch [24/50], Iter [360/439] Loss: 3.7675, average_loss: 3.4657\n",
      "Epoch [24/50], Iter [365/439] Loss: 2.8125, average_loss: 3.4606\n",
      "Epoch [24/50], Iter [370/439] Loss: 3.4754, average_loss: 3.4603\n",
      "Epoch [24/50], Iter [375/439] Loss: 4.1907, average_loss: 3.4630\n",
      "Epoch [24/50], Iter [380/439] Loss: 3.3151, average_loss: 3.4567\n",
      "Epoch [24/50], Iter [385/439] Loss: 3.2432, average_loss: 3.4545\n",
      "Epoch [24/50], Iter [390/439] Loss: 3.5382, average_loss: 3.4570\n",
      "Epoch [24/50], Iter [395/439] Loss: 4.0381, average_loss: 3.4561\n",
      "Epoch [24/50], Iter [400/439] Loss: 4.0444, average_loss: 3.4611\n",
      "Epoch [24/50], Iter [405/439] Loss: 2.1740, average_loss: 3.4523\n",
      "Epoch [24/50], Iter [410/439] Loss: 2.9814, average_loss: 3.4509\n",
      "Epoch [24/50], Iter [415/439] Loss: 1.7277, average_loss: 3.4461\n",
      "Epoch [24/50], Iter [420/439] Loss: 5.1132, average_loss: 3.4515\n",
      "Epoch [24/50], Iter [425/439] Loss: 2.9459, average_loss: 3.4547\n",
      "Epoch [24/50], Iter [430/439] Loss: 4.1635, average_loss: 3.4557\n",
      "Epoch [24/50], Iter [435/439] Loss: 2.8095, average_loss: 3.4502\n",
      "Test epoch [24/50], average_loss: 3.6068\n",
      "Epoch [25/50], Iter [5/439] Loss: 3.3822, average_loss: 3.2502\n",
      "Epoch [25/50], Iter [10/439] Loss: 3.6769, average_loss: 3.3534\n",
      "Epoch [25/50], Iter [15/439] Loss: 3.0609, average_loss: 3.3277\n",
      "Epoch [25/50], Iter [20/439] Loss: 3.6606, average_loss: 3.2342\n",
      "Epoch [25/50], Iter [25/439] Loss: 4.1828, average_loss: 3.4797\n",
      "Epoch [25/50], Iter [30/439] Loss: 2.9153, average_loss: 3.4832\n",
      "Epoch [25/50], Iter [35/439] Loss: 4.6712, average_loss: 3.5614\n",
      "Epoch [25/50], Iter [40/439] Loss: 3.1115, average_loss: 3.7002\n",
      "Epoch [25/50], Iter [45/439] Loss: 3.8056, average_loss: 3.6288\n",
      "Epoch [25/50], Iter [50/439] Loss: 3.6736, average_loss: 3.5867\n",
      "Epoch [25/50], Iter [55/439] Loss: 4.6508, average_loss: 3.6032\n",
      "Epoch [25/50], Iter [60/439] Loss: 4.5970, average_loss: 3.6896\n",
      "Epoch [25/50], Iter [65/439] Loss: 2.5297, average_loss: 3.6618\n",
      "Epoch [25/50], Iter [70/439] Loss: 3.6270, average_loss: 3.7028\n",
      "Epoch [25/50], Iter [75/439] Loss: 2.6559, average_loss: 3.6698\n",
      "Epoch [25/50], Iter [80/439] Loss: 2.3226, average_loss: 3.7071\n",
      "Epoch [25/50], Iter [85/439] Loss: 3.4068, average_loss: 3.6824\n",
      "Epoch [25/50], Iter [90/439] Loss: 2.3814, average_loss: 3.6395\n",
      "Epoch [25/50], Iter [95/439] Loss: 3.5152, average_loss: 3.6517\n",
      "Epoch [25/50], Iter [100/439] Loss: 2.6432, average_loss: 3.6298\n",
      "Epoch [25/50], Iter [105/439] Loss: 5.2612, average_loss: 3.6151\n",
      "Epoch [25/50], Iter [110/439] Loss: 3.1093, average_loss: 3.5953\n",
      "Epoch [25/50], Iter [115/439] Loss: 2.6268, average_loss: 3.5914\n",
      "Epoch [25/50], Iter [120/439] Loss: 2.7637, average_loss: 3.5696\n",
      "Epoch [25/50], Iter [125/439] Loss: 3.5252, average_loss: 3.5732\n",
      "Epoch [25/50], Iter [130/439] Loss: 2.5932, average_loss: 3.6044\n",
      "Epoch [25/50], Iter [135/439] Loss: 4.0422, average_loss: 3.5884\n",
      "Epoch [25/50], Iter [140/439] Loss: 3.6427, average_loss: 3.5829\n",
      "Epoch [25/50], Iter [145/439] Loss: 4.5885, average_loss: 3.5911\n",
      "Epoch [25/50], Iter [150/439] Loss: 4.0050, average_loss: 3.5617\n",
      "Epoch [25/50], Iter [155/439] Loss: 6.3353, average_loss: 3.5631\n",
      "Epoch [25/50], Iter [160/439] Loss: 3.4249, average_loss: 3.5661\n",
      "Epoch [25/50], Iter [165/439] Loss: 2.3020, average_loss: 3.5467\n",
      "Epoch [25/50], Iter [170/439] Loss: 3.9351, average_loss: 3.5445\n",
      "Epoch [25/50], Iter [175/439] Loss: 1.9919, average_loss: 3.5212\n",
      "Epoch [25/50], Iter [180/439] Loss: 3.3189, average_loss: 3.5159\n",
      "Epoch [25/50], Iter [185/439] Loss: 1.6761, average_loss: 3.5350\n",
      "Epoch [25/50], Iter [190/439] Loss: 6.4250, average_loss: 3.5425\n",
      "Epoch [25/50], Iter [195/439] Loss: 2.8229, average_loss: 3.5292\n",
      "Epoch [25/50], Iter [200/439] Loss: 3.3251, average_loss: 3.5234\n",
      "Epoch [25/50], Iter [205/439] Loss: 3.7662, average_loss: 3.5215\n",
      "Epoch [25/50], Iter [210/439] Loss: 2.9627, average_loss: 3.5227\n",
      "Epoch [25/50], Iter [215/439] Loss: 3.1116, average_loss: 3.5088\n",
      "Epoch [25/50], Iter [220/439] Loss: 4.0673, average_loss: 3.5023\n",
      "Epoch [25/50], Iter [225/439] Loss: 2.7962, average_loss: 3.5066\n",
      "Epoch [25/50], Iter [230/439] Loss: 3.3387, average_loss: 3.4998\n",
      "Epoch [25/50], Iter [235/439] Loss: 2.2862, average_loss: 3.5012\n",
      "Epoch [25/50], Iter [240/439] Loss: 2.1574, average_loss: 3.5071\n",
      "Epoch [25/50], Iter [245/439] Loss: 3.5992, average_loss: 3.5118\n",
      "Epoch [25/50], Iter [250/439] Loss: 2.2055, average_loss: 3.4996\n",
      "Epoch [25/50], Iter [255/439] Loss: 2.7647, average_loss: 3.5071\n",
      "Epoch [25/50], Iter [260/439] Loss: 4.4224, average_loss: 3.5061\n",
      "Epoch [25/50], Iter [265/439] Loss: 2.8537, average_loss: 3.4889\n",
      "Epoch [25/50], Iter [270/439] Loss: 2.8990, average_loss: 3.4728\n",
      "Epoch [25/50], Iter [275/439] Loss: 5.0366, average_loss: 3.4772\n",
      "Epoch [25/50], Iter [280/439] Loss: 2.1052, average_loss: 3.4642\n",
      "Epoch [25/50], Iter [285/439] Loss: 2.2299, average_loss: 3.4514\n",
      "Epoch [25/50], Iter [290/439] Loss: 5.4839, average_loss: 3.4483\n",
      "Epoch [25/50], Iter [295/439] Loss: 2.1444, average_loss: 3.4439\n",
      "Epoch [25/50], Iter [300/439] Loss: 3.8369, average_loss: 3.4511\n",
      "Epoch [25/50], Iter [305/439] Loss: 3.6174, average_loss: 3.4474\n",
      "Epoch [25/50], Iter [310/439] Loss: 3.4068, average_loss: 3.4467\n",
      "Epoch [25/50], Iter [315/439] Loss: 4.8370, average_loss: 3.4553\n",
      "Epoch [25/50], Iter [320/439] Loss: 2.6483, average_loss: 3.4454\n",
      "Epoch [25/50], Iter [325/439] Loss: 3.6456, average_loss: 3.4431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Iter [330/439] Loss: 4.2385, average_loss: 3.4401\n",
      "Epoch [25/50], Iter [335/439] Loss: 3.2584, average_loss: 3.4353\n",
      "Epoch [25/50], Iter [340/439] Loss: 3.4248, average_loss: 3.4368\n",
      "Epoch [25/50], Iter [345/439] Loss: 3.1564, average_loss: 3.4431\n",
      "Epoch [25/50], Iter [350/439] Loss: 2.4758, average_loss: 3.4356\n",
      "Epoch [25/50], Iter [355/439] Loss: 1.8441, average_loss: 3.4309\n",
      "Epoch [25/50], Iter [360/439] Loss: 3.5052, average_loss: 3.4310\n",
      "Epoch [25/50], Iter [365/439] Loss: 2.0692, average_loss: 3.4239\n",
      "Epoch [25/50], Iter [370/439] Loss: 5.3373, average_loss: 3.4230\n",
      "Epoch [25/50], Iter [375/439] Loss: 2.3022, average_loss: 3.4187\n",
      "Epoch [25/50], Iter [380/439] Loss: 2.8361, average_loss: 3.4142\n",
      "Epoch [25/50], Iter [385/439] Loss: 4.7047, average_loss: 3.4128\n",
      "Epoch [25/50], Iter [390/439] Loss: 3.4949, average_loss: 3.4187\n",
      "Epoch [25/50], Iter [395/439] Loss: 3.2315, average_loss: 3.4165\n",
      "Epoch [25/50], Iter [400/439] Loss: 3.1047, average_loss: 3.4109\n",
      "Epoch [25/50], Iter [405/439] Loss: 2.5108, average_loss: 3.4119\n",
      "Epoch [25/50], Iter [410/439] Loss: 5.3793, average_loss: 3.4118\n",
      "Epoch [25/50], Iter [415/439] Loss: 3.5702, average_loss: 3.4067\n",
      "Epoch [25/50], Iter [420/439] Loss: 4.3366, average_loss: 3.4159\n",
      "Epoch [25/50], Iter [425/439] Loss: 1.9303, average_loss: 3.4226\n",
      "Epoch [25/50], Iter [430/439] Loss: 3.5798, average_loss: 3.4225\n",
      "Epoch [25/50], Iter [435/439] Loss: 3.7746, average_loss: 3.4195\n",
      "Test epoch [25/50], average_loss: 3.5479\n",
      "Epoch [26/50], Iter [5/439] Loss: 4.4681, average_loss: 4.2740\n",
      "Epoch [26/50], Iter [10/439] Loss: 3.8024, average_loss: 3.8304\n",
      "Epoch [26/50], Iter [15/439] Loss: 3.3448, average_loss: 3.4718\n",
      "Epoch [26/50], Iter [20/439] Loss: 2.2109, average_loss: 3.3601\n",
      "Epoch [26/50], Iter [25/439] Loss: 2.5845, average_loss: 3.3330\n",
      "Epoch [26/50], Iter [30/439] Loss: 4.9772, average_loss: 3.4371\n",
      "Epoch [26/50], Iter [35/439] Loss: 3.5485, average_loss: 3.4080\n",
      "Epoch [26/50], Iter [40/439] Loss: 5.1051, average_loss: 3.4716\n",
      "Epoch [26/50], Iter [45/439] Loss: 1.3929, average_loss: 3.4045\n",
      "Epoch [26/50], Iter [50/439] Loss: 4.0255, average_loss: 3.4491\n",
      "Epoch [26/50], Iter [55/439] Loss: 5.5809, average_loss: 3.5761\n",
      "Epoch [26/50], Iter [60/439] Loss: 3.9875, average_loss: 3.5562\n",
      "Epoch [26/50], Iter [65/439] Loss: 2.7180, average_loss: 3.4777\n",
      "Epoch [26/50], Iter [70/439] Loss: 2.1409, average_loss: 3.4910\n",
      "Epoch [26/50], Iter [75/439] Loss: 1.9687, average_loss: 3.4809\n",
      "Epoch [26/50], Iter [80/439] Loss: 4.0318, average_loss: 3.4528\n",
      "Epoch [26/50], Iter [85/439] Loss: 3.8791, average_loss: 3.4572\n",
      "Epoch [26/50], Iter [90/439] Loss: 2.6419, average_loss: 3.4598\n",
      "Epoch [26/50], Iter [95/439] Loss: 2.8292, average_loss: 3.4603\n",
      "Epoch [26/50], Iter [100/439] Loss: 3.0450, average_loss: 3.4734\n",
      "Epoch [26/50], Iter [105/439] Loss: 2.8203, average_loss: 3.5040\n",
      "Epoch [26/50], Iter [110/439] Loss: 3.5718, average_loss: 3.5133\n",
      "Epoch [26/50], Iter [115/439] Loss: 3.9701, average_loss: 3.5212\n",
      "Epoch [26/50], Iter [120/439] Loss: 4.0109, average_loss: 3.5139\n",
      "Epoch [26/50], Iter [125/439] Loss: 3.1621, average_loss: 3.5132\n",
      "Epoch [26/50], Iter [130/439] Loss: 3.4369, average_loss: 3.5227\n",
      "Epoch [26/50], Iter [135/439] Loss: 2.7827, average_loss: 3.5056\n",
      "Epoch [26/50], Iter [140/439] Loss: 3.0471, average_loss: 3.5007\n",
      "Epoch [26/50], Iter [145/439] Loss: 3.5446, average_loss: 3.4735\n",
      "Epoch [26/50], Iter [150/439] Loss: 3.4667, average_loss: 3.4669\n",
      "Epoch [26/50], Iter [155/439] Loss: 3.8810, average_loss: 3.4730\n",
      "Epoch [26/50], Iter [160/439] Loss: 2.0462, average_loss: 3.4595\n",
      "Epoch [26/50], Iter [165/439] Loss: 2.3163, average_loss: 3.4359\n",
      "Epoch [26/50], Iter [170/439] Loss: 2.5077, average_loss: 3.4324\n",
      "Epoch [26/50], Iter [175/439] Loss: 3.9883, average_loss: 3.4226\n",
      "Epoch [26/50], Iter [180/439] Loss: 4.5520, average_loss: 3.4311\n",
      "Epoch [26/50], Iter [185/439] Loss: 3.1781, average_loss: 3.4195\n",
      "Epoch [26/50], Iter [190/439] Loss: 4.2240, average_loss: 3.4111\n",
      "Epoch [26/50], Iter [195/439] Loss: 2.4081, average_loss: 3.4020\n",
      "Epoch [26/50], Iter [200/439] Loss: 3.5202, average_loss: 3.4038\n",
      "Epoch [26/50], Iter [205/439] Loss: 4.7940, average_loss: 3.4093\n",
      "Epoch [26/50], Iter [210/439] Loss: 5.1063, average_loss: 3.4003\n",
      "Epoch [26/50], Iter [215/439] Loss: 2.0774, average_loss: 3.3976\n",
      "Epoch [26/50], Iter [220/439] Loss: 5.1320, average_loss: 3.3977\n",
      "Epoch [26/50], Iter [225/439] Loss: 1.8445, average_loss: 3.3941\n",
      "Epoch [26/50], Iter [230/439] Loss: 6.5883, average_loss: 3.4204\n",
      "Epoch [26/50], Iter [235/439] Loss: 4.0778, average_loss: 3.4346\n",
      "Epoch [26/50], Iter [240/439] Loss: 5.0595, average_loss: 3.4399\n",
      "Epoch [26/50], Iter [245/439] Loss: 2.7153, average_loss: 3.4464\n",
      "Epoch [26/50], Iter [250/439] Loss: 2.4805, average_loss: 3.4339\n",
      "Epoch [26/50], Iter [255/439] Loss: 3.6771, average_loss: 3.4315\n",
      "Epoch [26/50], Iter [260/439] Loss: 2.4639, average_loss: 3.4227\n",
      "Epoch [26/50], Iter [265/439] Loss: 2.4869, average_loss: 3.4180\n",
      "Epoch [26/50], Iter [270/439] Loss: 4.1948, average_loss: 3.4257\n",
      "Epoch [26/50], Iter [275/439] Loss: 3.5317, average_loss: 3.4401\n",
      "Epoch [26/50], Iter [280/439] Loss: 3.7618, average_loss: 3.4350\n",
      "Epoch [26/50], Iter [285/439] Loss: 3.1840, average_loss: 3.4337\n",
      "Epoch [26/50], Iter [290/439] Loss: 3.0188, average_loss: 3.4330\n",
      "Epoch [26/50], Iter [295/439] Loss: 4.6921, average_loss: 3.4346\n",
      "Epoch [26/50], Iter [300/439] Loss: 2.3820, average_loss: 3.4255\n",
      "Epoch [26/50], Iter [305/439] Loss: 3.3399, average_loss: 3.4219\n",
      "Epoch [26/50], Iter [310/439] Loss: 3.0107, average_loss: 3.4262\n",
      "Epoch [26/50], Iter [315/439] Loss: 4.1342, average_loss: 3.4334\n",
      "Epoch [26/50], Iter [320/439] Loss: 3.3718, average_loss: 3.4330\n",
      "Epoch [26/50], Iter [325/439] Loss: 2.6463, average_loss: 3.4296\n",
      "Epoch [26/50], Iter [330/439] Loss: 2.5987, average_loss: 3.4284\n",
      "Epoch [26/50], Iter [335/439] Loss: 4.6714, average_loss: 3.4258\n",
      "Epoch [26/50], Iter [340/439] Loss: 3.0401, average_loss: 3.4371\n",
      "Epoch [26/50], Iter [345/439] Loss: 3.3034, average_loss: 3.4314\n",
      "Epoch [26/50], Iter [350/439] Loss: 4.1595, average_loss: 3.4311\n",
      "Epoch [26/50], Iter [355/439] Loss: 5.1643, average_loss: 3.4411\n",
      "Epoch [26/50], Iter [360/439] Loss: 1.7959, average_loss: 3.4293\n",
      "Epoch [26/50], Iter [365/439] Loss: 5.0802, average_loss: 3.4372\n",
      "Epoch [26/50], Iter [370/439] Loss: 2.2272, average_loss: 3.4290\n",
      "Epoch [26/50], Iter [375/439] Loss: 2.2946, average_loss: 3.4209\n",
      "Epoch [26/50], Iter [380/439] Loss: 3.0093, average_loss: 3.4244\n",
      "Epoch [26/50], Iter [385/439] Loss: 3.2274, average_loss: 3.4189\n",
      "Epoch [26/50], Iter [390/439] Loss: 3.4396, average_loss: 3.4118\n",
      "Epoch [26/50], Iter [395/439] Loss: 2.2129, average_loss: 3.4082\n",
      "Epoch [26/50], Iter [400/439] Loss: 4.3379, average_loss: 3.4095\n",
      "Epoch [26/50], Iter [405/439] Loss: 4.8184, average_loss: 3.4131\n",
      "Epoch [26/50], Iter [410/439] Loss: 3.9890, average_loss: 3.4105\n",
      "Epoch [26/50], Iter [415/439] Loss: 1.8974, average_loss: 3.4233\n",
      "Epoch [26/50], Iter [420/439] Loss: 3.8127, average_loss: 3.4191\n",
      "Epoch [26/50], Iter [425/439] Loss: 2.9241, average_loss: 3.4192\n",
      "Epoch [26/50], Iter [430/439] Loss: 5.0898, average_loss: 3.4295\n",
      "Epoch [26/50], Iter [435/439] Loss: 2.7306, average_loss: 3.4306\n",
      "Test epoch [26/50], average_loss: 3.5829\n",
      "Epoch [27/50], Iter [5/439] Loss: 3.8662, average_loss: 3.6361\n",
      "Epoch [27/50], Iter [10/439] Loss: 3.8361, average_loss: 3.8748\n",
      "Epoch [27/50], Iter [15/439] Loss: 3.0496, average_loss: 3.7121\n",
      "Epoch [27/50], Iter [20/439] Loss: 2.3470, average_loss: 3.5873\n",
      "Epoch [27/50], Iter [25/439] Loss: 3.8070, average_loss: 3.6030\n",
      "Epoch [27/50], Iter [30/439] Loss: 2.9933, average_loss: 3.5647\n",
      "Epoch [27/50], Iter [35/439] Loss: 3.2246, average_loss: 3.6732\n",
      "Epoch [27/50], Iter [40/439] Loss: 3.0200, average_loss: 3.6158\n",
      "Epoch [27/50], Iter [45/439] Loss: 3.1253, average_loss: 3.5915\n",
      "Epoch [27/50], Iter [50/439] Loss: 3.8765, average_loss: 3.5771\n",
      "Epoch [27/50], Iter [55/439] Loss: 3.0703, average_loss: 3.5668\n",
      "Epoch [27/50], Iter [60/439] Loss: 4.5324, average_loss: 3.5714\n",
      "Epoch [27/50], Iter [65/439] Loss: 2.3824, average_loss: 3.5536\n",
      "Epoch [27/50], Iter [70/439] Loss: 4.3579, average_loss: 3.5708\n",
      "Epoch [27/50], Iter [75/439] Loss: 3.7805, average_loss: 3.6102\n",
      "Epoch [27/50], Iter [80/439] Loss: 3.6561, average_loss: 3.6192\n",
      "Epoch [27/50], Iter [85/439] Loss: 2.5471, average_loss: 3.5970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Iter [90/439] Loss: 1.6611, average_loss: 3.5573\n",
      "Epoch [27/50], Iter [95/439] Loss: 3.7363, average_loss: 3.5420\n",
      "Epoch [27/50], Iter [100/439] Loss: 2.7027, average_loss: 3.5110\n",
      "Epoch [27/50], Iter [105/439] Loss: 3.2983, average_loss: 3.4853\n",
      "Epoch [27/50], Iter [110/439] Loss: 4.6765, average_loss: 3.4933\n",
      "Epoch [27/50], Iter [115/439] Loss: 3.1655, average_loss: 3.4967\n",
      "Epoch [27/50], Iter [120/439] Loss: 3.3975, average_loss: 3.4699\n",
      "Epoch [27/50], Iter [125/439] Loss: 3.6030, average_loss: 3.4802\n",
      "Epoch [27/50], Iter [130/439] Loss: 4.4855, average_loss: 3.4910\n",
      "Epoch [27/50], Iter [135/439] Loss: 4.4177, average_loss: 3.4811\n",
      "Epoch [27/50], Iter [140/439] Loss: 4.4306, average_loss: 3.4738\n",
      "Epoch [27/50], Iter [145/439] Loss: 3.1061, average_loss: 3.4676\n",
      "Epoch [27/50], Iter [150/439] Loss: 2.9910, average_loss: 3.4463\n",
      "Epoch [27/50], Iter [155/439] Loss: 2.1865, average_loss: 3.4198\n",
      "Epoch [27/50], Iter [160/439] Loss: 3.3398, average_loss: 3.4089\n",
      "Epoch [27/50], Iter [165/439] Loss: 2.8371, average_loss: 3.3929\n",
      "Epoch [27/50], Iter [170/439] Loss: 2.7340, average_loss: 3.4075\n",
      "Epoch [27/50], Iter [175/439] Loss: 1.6841, average_loss: 3.3901\n",
      "Epoch [27/50], Iter [180/439] Loss: 2.6286, average_loss: 3.3965\n",
      "Epoch [27/50], Iter [185/439] Loss: 4.4540, average_loss: 3.3889\n",
      "Epoch [27/50], Iter [190/439] Loss: 4.3191, average_loss: 3.4188\n",
      "Epoch [27/50], Iter [195/439] Loss: 3.0877, average_loss: 3.4241\n",
      "Epoch [27/50], Iter [200/439] Loss: 4.0280, average_loss: 3.4232\n",
      "Epoch [27/50], Iter [205/439] Loss: 2.0341, average_loss: 3.4141\n",
      "Epoch [27/50], Iter [210/439] Loss: 4.7310, average_loss: 3.4122\n",
      "Epoch [27/50], Iter [215/439] Loss: 4.8261, average_loss: 3.4357\n",
      "Epoch [27/50], Iter [220/439] Loss: 4.5402, average_loss: 3.4580\n",
      "Epoch [27/50], Iter [225/439] Loss: 3.8080, average_loss: 3.5028\n",
      "Epoch [27/50], Iter [230/439] Loss: 2.4418, average_loss: 3.4965\n",
      "Epoch [27/50], Iter [235/439] Loss: 2.0219, average_loss: 3.4869\n",
      "Epoch [27/50], Iter [240/439] Loss: 3.1719, average_loss: 3.4755\n",
      "Epoch [27/50], Iter [245/439] Loss: 3.0415, average_loss: 3.4694\n",
      "Epoch [27/50], Iter [250/439] Loss: 2.8989, average_loss: 3.4745\n",
      "Epoch [27/50], Iter [255/439] Loss: 2.7638, average_loss: 3.4717\n",
      "Epoch [27/50], Iter [260/439] Loss: 6.5612, average_loss: 3.4743\n",
      "Epoch [27/50], Iter [265/439] Loss: 2.7658, average_loss: 3.4683\n",
      "Epoch [27/50], Iter [270/439] Loss: 3.5300, average_loss: 3.4663\n",
      "Epoch [27/50], Iter [275/439] Loss: 3.7983, average_loss: 3.4634\n",
      "Epoch [27/50], Iter [280/439] Loss: 2.5139, average_loss: 3.4560\n",
      "Epoch [27/50], Iter [285/439] Loss: 3.1961, average_loss: 3.4568\n",
      "Epoch [27/50], Iter [290/439] Loss: 3.3963, average_loss: 3.4575\n",
      "Epoch [27/50], Iter [295/439] Loss: 2.8020, average_loss: 3.4551\n",
      "Epoch [27/50], Iter [300/439] Loss: 2.9875, average_loss: 3.4568\n",
      "Epoch [27/50], Iter [305/439] Loss: 4.0224, average_loss: 3.4526\n",
      "Epoch [27/50], Iter [310/439] Loss: 2.4098, average_loss: 3.4423\n",
      "Epoch [27/50], Iter [315/439] Loss: 3.7431, average_loss: 3.4318\n",
      "Epoch [27/50], Iter [320/439] Loss: 4.6642, average_loss: 3.4426\n",
      "Epoch [27/50], Iter [325/439] Loss: 1.9786, average_loss: 3.4420\n",
      "Epoch [27/50], Iter [330/439] Loss: 2.5277, average_loss: 3.4425\n",
      "Epoch [27/50], Iter [335/439] Loss: 4.3611, average_loss: 3.4462\n",
      "Epoch [27/50], Iter [340/439] Loss: 2.7488, average_loss: 3.4465\n",
      "Epoch [27/50], Iter [345/439] Loss: 3.3277, average_loss: 3.4416\n",
      "Epoch [27/50], Iter [350/439] Loss: 1.8509, average_loss: 3.4380\n",
      "Epoch [27/50], Iter [355/439] Loss: 3.2081, average_loss: 3.4356\n",
      "Epoch [27/50], Iter [360/439] Loss: 3.1261, average_loss: 3.4279\n",
      "Epoch [27/50], Iter [365/439] Loss: 2.5302, average_loss: 3.4226\n",
      "Epoch [27/50], Iter [370/439] Loss: 1.9645, average_loss: 3.4164\n",
      "Epoch [27/50], Iter [375/439] Loss: 3.5748, average_loss: 3.4122\n",
      "Epoch [27/50], Iter [380/439] Loss: 2.6916, average_loss: 3.4117\n",
      "Epoch [27/50], Iter [385/439] Loss: 3.5698, average_loss: 3.4145\n",
      "Epoch [27/50], Iter [390/439] Loss: 4.0106, average_loss: 3.4092\n",
      "Epoch [27/50], Iter [395/439] Loss: 1.9935, average_loss: 3.4099\n",
      "Epoch [27/50], Iter [400/439] Loss: 2.3544, average_loss: 3.4022\n",
      "Epoch [27/50], Iter [405/439] Loss: 4.1118, average_loss: 3.4024\n",
      "Epoch [27/50], Iter [410/439] Loss: 3.0396, average_loss: 3.4114\n",
      "Epoch [27/50], Iter [415/439] Loss: 3.9314, average_loss: 3.4093\n",
      "Epoch [27/50], Iter [420/439] Loss: 4.4594, average_loss: 3.4113\n",
      "Epoch [27/50], Iter [425/439] Loss: 4.5967, average_loss: 3.4161\n",
      "Epoch [27/50], Iter [430/439] Loss: 3.9911, average_loss: 3.4253\n",
      "Epoch [27/50], Iter [435/439] Loss: 2.5865, average_loss: 3.4247\n",
      "Test epoch [27/50], average_loss: 3.4945\n",
      "Epoch [28/50], Iter [5/439] Loss: 5.4849, average_loss: 3.1874\n",
      "Epoch [28/50], Iter [10/439] Loss: 5.2197, average_loss: 3.4289\n",
      "Epoch [28/50], Iter [15/439] Loss: 3.1255, average_loss: 3.3497\n",
      "Epoch [28/50], Iter [20/439] Loss: 3.5761, average_loss: 3.3219\n",
      "Epoch [28/50], Iter [25/439] Loss: 6.5058, average_loss: 3.4443\n",
      "Epoch [28/50], Iter [30/439] Loss: 4.6619, average_loss: 3.3380\n",
      "Epoch [28/50], Iter [35/439] Loss: 5.4598, average_loss: 3.4129\n",
      "Epoch [28/50], Iter [40/439] Loss: 2.3241, average_loss: 3.3515\n",
      "Epoch [28/50], Iter [45/439] Loss: 3.1055, average_loss: 3.3001\n",
      "Epoch [28/50], Iter [50/439] Loss: 4.8614, average_loss: 3.2999\n",
      "Epoch [28/50], Iter [55/439] Loss: 2.6973, average_loss: 3.2909\n",
      "Epoch [28/50], Iter [60/439] Loss: 2.8375, average_loss: 3.2755\n",
      "Epoch [28/50], Iter [65/439] Loss: 3.0141, average_loss: 3.2911\n",
      "Epoch [28/50], Iter [70/439] Loss: 2.5825, average_loss: 3.3156\n",
      "Epoch [28/50], Iter [75/439] Loss: 4.9130, average_loss: 3.3771\n",
      "Epoch [28/50], Iter [80/439] Loss: 3.0988, average_loss: 3.3809\n",
      "Epoch [28/50], Iter [85/439] Loss: 3.0166, average_loss: 3.4136\n",
      "Epoch [28/50], Iter [90/439] Loss: 2.7446, average_loss: 3.3816\n",
      "Epoch [28/50], Iter [95/439] Loss: 3.6086, average_loss: 3.3973\n",
      "Epoch [28/50], Iter [100/439] Loss: 3.4995, average_loss: 3.3699\n",
      "Epoch [28/50], Iter [105/439] Loss: 3.0309, average_loss: 3.3361\n",
      "Epoch [28/50], Iter [110/439] Loss: 6.3067, average_loss: 3.3610\n",
      "Epoch [28/50], Iter [115/439] Loss: 2.6806, average_loss: 3.3553\n",
      "Epoch [28/50], Iter [120/439] Loss: 2.6790, average_loss: 3.3638\n",
      "Epoch [28/50], Iter [125/439] Loss: 2.5055, average_loss: 3.3378\n",
      "Epoch [28/50], Iter [130/439] Loss: 2.4268, average_loss: 3.3186\n",
      "Epoch [28/50], Iter [135/439] Loss: 3.3448, average_loss: 3.3033\n",
      "Epoch [28/50], Iter [140/439] Loss: 2.7631, average_loss: 3.2907\n",
      "Epoch [28/50], Iter [145/439] Loss: 2.1044, average_loss: 3.2878\n",
      "Epoch [28/50], Iter [150/439] Loss: 3.3160, average_loss: 3.2823\n",
      "Epoch [28/50], Iter [155/439] Loss: 3.1820, average_loss: 3.2583\n",
      "Epoch [28/50], Iter [160/439] Loss: 3.0124, average_loss: 3.2957\n",
      "Epoch [28/50], Iter [165/439] Loss: 3.7928, average_loss: 3.2976\n",
      "Epoch [28/50], Iter [170/439] Loss: 2.4005, average_loss: 3.3194\n",
      "Epoch [28/50], Iter [175/439] Loss: 2.9621, average_loss: 3.3303\n",
      "Epoch [28/50], Iter [180/439] Loss: 1.9493, average_loss: 3.3307\n",
      "Epoch [28/50], Iter [185/439] Loss: 4.3220, average_loss: 3.3590\n",
      "Epoch [28/50], Iter [190/439] Loss: 2.8611, average_loss: 3.3696\n",
      "Epoch [28/50], Iter [195/439] Loss: 3.1943, average_loss: 3.3893\n",
      "Epoch [28/50], Iter [200/439] Loss: 3.3575, average_loss: 3.4016\n",
      "Epoch [28/50], Iter [205/439] Loss: 3.7157, average_loss: 3.3969\n",
      "Epoch [28/50], Iter [210/439] Loss: 4.1450, average_loss: 3.3900\n",
      "Epoch [28/50], Iter [215/439] Loss: 2.7011, average_loss: 3.3991\n",
      "Epoch [28/50], Iter [220/439] Loss: 3.4634, average_loss: 3.3834\n",
      "Epoch [28/50], Iter [225/439] Loss: 2.9710, average_loss: 3.3894\n",
      "Epoch [28/50], Iter [230/439] Loss: 3.4926, average_loss: 3.4159\n",
      "Epoch [28/50], Iter [235/439] Loss: 2.4868, average_loss: 3.4267\n",
      "Epoch [28/50], Iter [240/439] Loss: 3.7472, average_loss: 3.4137\n",
      "Epoch [28/50], Iter [245/439] Loss: 6.3480, average_loss: 3.4199\n",
      "Epoch [28/50], Iter [250/439] Loss: 2.5702, average_loss: 3.4150\n",
      "Epoch [28/50], Iter [255/439] Loss: 3.5052, average_loss: 3.4128\n",
      "Epoch [28/50], Iter [260/439] Loss: 2.4902, average_loss: 3.3987\n",
      "Epoch [28/50], Iter [265/439] Loss: 4.3200, average_loss: 3.3970\n",
      "Epoch [28/50], Iter [270/439] Loss: 3.0066, average_loss: 3.3894\n",
      "Epoch [28/50], Iter [275/439] Loss: 2.9375, average_loss: 3.3842\n",
      "Epoch [28/50], Iter [280/439] Loss: 1.6966, average_loss: 3.3690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Iter [285/439] Loss: 4.5291, average_loss: 3.3834\n",
      "Epoch [28/50], Iter [290/439] Loss: 2.5146, average_loss: 3.3752\n",
      "Epoch [28/50], Iter [295/439] Loss: 3.7618, average_loss: 3.3687\n",
      "Epoch [28/50], Iter [300/439] Loss: 3.4471, average_loss: 3.3787\n",
      "Epoch [28/50], Iter [305/439] Loss: 2.0083, average_loss: 3.3788\n",
      "Epoch [28/50], Iter [310/439] Loss: 3.7686, average_loss: 3.3941\n",
      "Epoch [28/50], Iter [315/439] Loss: 5.5799, average_loss: 3.3970\n",
      "Epoch [28/50], Iter [320/439] Loss: 2.7527, average_loss: 3.3914\n",
      "Epoch [28/50], Iter [325/439] Loss: 3.9558, average_loss: 3.3937\n",
      "Epoch [28/50], Iter [330/439] Loss: 4.2094, average_loss: 3.3944\n",
      "Epoch [28/50], Iter [335/439] Loss: 2.4561, average_loss: 3.3882\n",
      "Epoch [28/50], Iter [340/439] Loss: 4.0030, average_loss: 3.3931\n",
      "Epoch [28/50], Iter [345/439] Loss: 2.5519, average_loss: 3.3901\n",
      "Epoch [28/50], Iter [350/439] Loss: 2.7568, average_loss: 3.3863\n",
      "Epoch [28/50], Iter [355/439] Loss: 3.2911, average_loss: 3.3909\n",
      "Epoch [28/50], Iter [360/439] Loss: 5.9247, average_loss: 3.4019\n",
      "Epoch [28/50], Iter [365/439] Loss: 2.3283, average_loss: 3.3971\n",
      "Epoch [28/50], Iter [370/439] Loss: 2.7515, average_loss: 3.3887\n",
      "Epoch [28/50], Iter [375/439] Loss: 3.0473, average_loss: 3.3958\n",
      "Epoch [28/50], Iter [380/439] Loss: 4.4138, average_loss: 3.3949\n",
      "Epoch [28/50], Iter [385/439] Loss: 3.8513, average_loss: 3.3978\n",
      "Epoch [28/50], Iter [390/439] Loss: 3.6373, average_loss: 3.3990\n",
      "Epoch [28/50], Iter [395/439] Loss: 2.2100, average_loss: 3.3987\n",
      "Epoch [28/50], Iter [400/439] Loss: 4.2746, average_loss: 3.3974\n",
      "Epoch [28/50], Iter [405/439] Loss: 3.9714, average_loss: 3.3937\n",
      "Epoch [28/50], Iter [410/439] Loss: 3.2480, average_loss: 3.3944\n",
      "Epoch [28/50], Iter [415/439] Loss: 4.2271, average_loss: 3.3972\n",
      "Epoch [28/50], Iter [420/439] Loss: 2.3615, average_loss: 3.3975\n",
      "Epoch [28/50], Iter [425/439] Loss: 3.6859, average_loss: 3.4001\n",
      "Epoch [28/50], Iter [430/439] Loss: 1.6866, average_loss: 3.3985\n",
      "Epoch [28/50], Iter [435/439] Loss: 5.8863, average_loss: 3.4044\n",
      "Test epoch [28/50], average_loss: 3.4348\n",
      "Epoch [29/50], Iter [5/439] Loss: 2.9051, average_loss: 2.6295\n",
      "Epoch [29/50], Iter [10/439] Loss: 2.5172, average_loss: 2.9996\n",
      "Epoch [29/50], Iter [15/439] Loss: 3.9047, average_loss: 3.3204\n",
      "Epoch [29/50], Iter [20/439] Loss: 3.3075, average_loss: 3.2761\n",
      "Epoch [29/50], Iter [25/439] Loss: 5.0585, average_loss: 3.2982\n",
      "Epoch [29/50], Iter [30/439] Loss: 3.2083, average_loss: 3.2926\n",
      "Epoch [29/50], Iter [35/439] Loss: 4.0925, average_loss: 3.3813\n",
      "Epoch [29/50], Iter [40/439] Loss: 3.0179, average_loss: 3.3163\n",
      "Epoch [29/50], Iter [45/439] Loss: 3.0786, average_loss: 3.3100\n",
      "Epoch [29/50], Iter [50/439] Loss: 2.9870, average_loss: 3.3164\n",
      "Epoch [29/50], Iter [55/439] Loss: 2.5495, average_loss: 3.2852\n",
      "Epoch [29/50], Iter [60/439] Loss: 2.1971, average_loss: 3.2507\n",
      "Epoch [29/50], Iter [65/439] Loss: 2.2061, average_loss: 3.2753\n",
      "Epoch [29/50], Iter [70/439] Loss: 4.5638, average_loss: 3.3366\n",
      "Epoch [29/50], Iter [75/439] Loss: 3.2150, average_loss: 3.3529\n",
      "Epoch [29/50], Iter [80/439] Loss: 3.8536, average_loss: 3.3669\n",
      "Epoch [29/50], Iter [85/439] Loss: 3.1960, average_loss: 3.3527\n",
      "Epoch [29/50], Iter [90/439] Loss: 4.1425, average_loss: 3.3897\n",
      "Epoch [29/50], Iter [95/439] Loss: 3.2046, average_loss: 3.3883\n",
      "Epoch [29/50], Iter [100/439] Loss: 4.0371, average_loss: 3.4030\n",
      "Epoch [29/50], Iter [105/439] Loss: 3.4729, average_loss: 3.4178\n",
      "Epoch [29/50], Iter [110/439] Loss: 2.3351, average_loss: 3.4020\n",
      "Epoch [29/50], Iter [115/439] Loss: 6.1000, average_loss: 3.4313\n",
      "Epoch [29/50], Iter [120/439] Loss: 5.9406, average_loss: 3.5088\n",
      "Epoch [29/50], Iter [125/439] Loss: 2.7580, average_loss: 3.4938\n",
      "Epoch [29/50], Iter [130/439] Loss: 2.2770, average_loss: 3.4872\n",
      "Epoch [29/50], Iter [135/439] Loss: 4.5603, average_loss: 3.4844\n",
      "Epoch [29/50], Iter [140/439] Loss: 3.7782, average_loss: 3.4705\n",
      "Epoch [29/50], Iter [145/439] Loss: 3.1814, average_loss: 3.4858\n",
      "Epoch [29/50], Iter [150/439] Loss: 3.6636, average_loss: 3.4774\n",
      "Epoch [29/50], Iter [155/439] Loss: 3.9084, average_loss: 3.4754\n",
      "Epoch [29/50], Iter [160/439] Loss: 3.8359, average_loss: 3.4550\n",
      "Epoch [29/50], Iter [165/439] Loss: 2.0894, average_loss: 3.4614\n",
      "Epoch [29/50], Iter [170/439] Loss: 2.2709, average_loss: 3.4463\n",
      "Epoch [29/50], Iter [175/439] Loss: 3.8765, average_loss: 3.4539\n",
      "Epoch [29/50], Iter [180/439] Loss: 2.8683, average_loss: 3.4467\n",
      "Epoch [29/50], Iter [185/439] Loss: 2.5779, average_loss: 3.4297\n",
      "Epoch [29/50], Iter [190/439] Loss: 3.3934, average_loss: 3.4448\n",
      "Epoch [29/50], Iter [195/439] Loss: 3.8251, average_loss: 3.4397\n",
      "Epoch [29/50], Iter [200/439] Loss: 2.0087, average_loss: 3.4188\n",
      "Epoch [29/50], Iter [205/439] Loss: 5.6284, average_loss: 3.4260\n",
      "Epoch [29/50], Iter [210/439] Loss: 3.9187, average_loss: 3.4220\n",
      "Epoch [29/50], Iter [215/439] Loss: 3.5760, average_loss: 3.4377\n",
      "Epoch [29/50], Iter [220/439] Loss: 3.3518, average_loss: 3.4292\n",
      "Epoch [29/50], Iter [225/439] Loss: 2.0480, average_loss: 3.4223\n",
      "Epoch [29/50], Iter [230/439] Loss: 2.4665, average_loss: 3.4277\n",
      "Epoch [29/50], Iter [235/439] Loss: 2.4716, average_loss: 3.4223\n",
      "Epoch [29/50], Iter [240/439] Loss: 3.6812, average_loss: 3.4190\n",
      "Epoch [29/50], Iter [245/439] Loss: 3.7268, average_loss: 3.4125\n",
      "Epoch [29/50], Iter [250/439] Loss: 2.9551, average_loss: 3.3968\n",
      "Epoch [29/50], Iter [255/439] Loss: 3.3911, average_loss: 3.3878\n",
      "Epoch [29/50], Iter [260/439] Loss: 2.2302, average_loss: 3.4000\n",
      "Epoch [29/50], Iter [265/439] Loss: 1.8638, average_loss: 3.3828\n",
      "Epoch [29/50], Iter [270/439] Loss: 3.1549, average_loss: 3.3766\n",
      "Epoch [29/50], Iter [275/439] Loss: 4.7629, average_loss: 3.4072\n",
      "Epoch [29/50], Iter [280/439] Loss: 3.6823, average_loss: 3.4217\n",
      "Epoch [29/50], Iter [285/439] Loss: 6.1435, average_loss: 3.4209\n",
      "Epoch [29/50], Iter [290/439] Loss: 3.1320, average_loss: 3.4312\n",
      "Epoch [29/50], Iter [295/439] Loss: 2.3132, average_loss: 3.4414\n",
      "Epoch [29/50], Iter [300/439] Loss: 3.7028, average_loss: 3.4282\n",
      "Epoch [29/50], Iter [305/439] Loss: 3.5690, average_loss: 3.4280\n",
      "Epoch [29/50], Iter [310/439] Loss: 2.0569, average_loss: 3.4357\n",
      "Epoch [29/50], Iter [315/439] Loss: 2.6476, average_loss: 3.4274\n",
      "Epoch [29/50], Iter [320/439] Loss: 3.9979, average_loss: 3.4222\n",
      "Epoch [29/50], Iter [325/439] Loss: 2.8206, average_loss: 3.4166\n",
      "Epoch [29/50], Iter [330/439] Loss: 3.6989, average_loss: 3.4075\n",
      "Epoch [29/50], Iter [335/439] Loss: 2.3543, average_loss: 3.4067\n",
      "Epoch [29/50], Iter [340/439] Loss: 3.4541, average_loss: 3.4098\n",
      "Epoch [29/50], Iter [345/439] Loss: 2.9967, average_loss: 3.4030\n",
      "Epoch [29/50], Iter [350/439] Loss: 4.6839, average_loss: 3.4048\n",
      "Epoch [29/50], Iter [355/439] Loss: 4.6830, average_loss: 3.4036\n",
      "Epoch [29/50], Iter [360/439] Loss: 2.9313, average_loss: 3.4017\n",
      "Epoch [29/50], Iter [365/439] Loss: 3.5060, average_loss: 3.4095\n",
      "Epoch [29/50], Iter [370/439] Loss: 2.5359, average_loss: 3.4111\n",
      "Epoch [29/50], Iter [375/439] Loss: 4.0255, average_loss: 3.4123\n",
      "Epoch [29/50], Iter [380/439] Loss: 5.6645, average_loss: 3.4168\n",
      "Epoch [29/50], Iter [385/439] Loss: 2.7646, average_loss: 3.4235\n",
      "Epoch [29/50], Iter [390/439] Loss: 3.9047, average_loss: 3.4203\n",
      "Epoch [29/50], Iter [395/439] Loss: 2.3464, average_loss: 3.4187\n",
      "Epoch [29/50], Iter [400/439] Loss: 5.0719, average_loss: 3.4278\n",
      "Epoch [29/50], Iter [405/439] Loss: 5.0243, average_loss: 3.4278\n",
      "Epoch [29/50], Iter [410/439] Loss: 3.3898, average_loss: 3.4322\n",
      "Epoch [29/50], Iter [415/439] Loss: 2.2136, average_loss: 3.4270\n",
      "Epoch [29/50], Iter [420/439] Loss: 5.0012, average_loss: 3.4256\n",
      "Epoch [29/50], Iter [425/439] Loss: 5.2019, average_loss: 3.4243\n",
      "Epoch [29/50], Iter [430/439] Loss: 5.1154, average_loss: 3.4273\n",
      "Epoch [29/50], Iter [435/439] Loss: 3.0410, average_loss: 3.4260\n",
      "Test epoch [29/50], average_loss: 3.3885\n",
      "Epoch [30/50], Iter [5/439] Loss: 2.0790, average_loss: 3.0359\n",
      "Epoch [30/50], Iter [10/439] Loss: 3.1365, average_loss: 3.1521\n",
      "Epoch [30/50], Iter [15/439] Loss: 2.3686, average_loss: 3.2638\n",
      "Epoch [30/50], Iter [20/439] Loss: 3.1191, average_loss: 3.2141\n",
      "Epoch [30/50], Iter [25/439] Loss: 3.0491, average_loss: 3.3187\n",
      "Epoch [30/50], Iter [30/439] Loss: 2.8950, average_loss: 3.2613\n",
      "Epoch [30/50], Iter [35/439] Loss: 3.2932, average_loss: 3.2807\n",
      "Epoch [30/50], Iter [40/439] Loss: 1.9961, average_loss: 3.2450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Iter [45/439] Loss: 3.2199, average_loss: 3.2181\n",
      "Epoch [30/50], Iter [50/439] Loss: 2.5138, average_loss: 3.2230\n",
      "Epoch [30/50], Iter [55/439] Loss: 3.4885, average_loss: 3.2149\n",
      "Epoch [30/50], Iter [60/439] Loss: 4.5530, average_loss: 3.2788\n",
      "Epoch [30/50], Iter [65/439] Loss: 2.4442, average_loss: 3.2938\n",
      "Epoch [30/50], Iter [70/439] Loss: 4.2451, average_loss: 3.3325\n",
      "Epoch [30/50], Iter [75/439] Loss: 4.9754, average_loss: 3.3572\n",
      "Epoch [30/50], Iter [80/439] Loss: 3.0600, average_loss: 3.3874\n",
      "Epoch [30/50], Iter [85/439] Loss: 1.9268, average_loss: 3.3519\n",
      "Epoch [30/50], Iter [90/439] Loss: 1.9955, average_loss: 3.3052\n",
      "Epoch [30/50], Iter [95/439] Loss: 3.4997, average_loss: 3.2823\n",
      "Epoch [30/50], Iter [100/439] Loss: 2.8028, average_loss: 3.2995\n",
      "Epoch [30/50], Iter [105/439] Loss: 2.5202, average_loss: 3.3239\n",
      "Epoch [30/50], Iter [110/439] Loss: 2.2135, average_loss: 3.2877\n",
      "Epoch [30/50], Iter [115/439] Loss: 2.8695, average_loss: 3.2740\n",
      "Epoch [30/50], Iter [120/439] Loss: 2.1055, average_loss: 3.2355\n",
      "Epoch [30/50], Iter [125/439] Loss: 2.9592, average_loss: 3.2626\n",
      "Epoch [30/50], Iter [130/439] Loss: 2.7096, average_loss: 3.2574\n",
      "Epoch [30/50], Iter [135/439] Loss: 2.0673, average_loss: 3.2587\n",
      "Epoch [30/50], Iter [140/439] Loss: 3.3737, average_loss: 3.2768\n",
      "Epoch [30/50], Iter [145/439] Loss: 3.6236, average_loss: 3.2717\n",
      "Epoch [30/50], Iter [150/439] Loss: 2.6772, average_loss: 3.2771\n",
      "Epoch [30/50], Iter [155/439] Loss: 2.3454, average_loss: 3.2781\n",
      "Epoch [30/50], Iter [160/439] Loss: 3.5896, average_loss: 3.2819\n",
      "Epoch [30/50], Iter [165/439] Loss: 4.1248, average_loss: 3.2872\n",
      "Epoch [30/50], Iter [170/439] Loss: 3.5998, average_loss: 3.2875\n",
      "Epoch [30/50], Iter [175/439] Loss: 5.8501, average_loss: 3.2953\n",
      "Epoch [30/50], Iter [180/439] Loss: 2.3015, average_loss: 3.2836\n",
      "Epoch [30/50], Iter [185/439] Loss: 2.5158, average_loss: 3.2651\n",
      "Epoch [30/50], Iter [190/439] Loss: 2.5082, average_loss: 3.2675\n",
      "Epoch [30/50], Iter [195/439] Loss: 2.6432, average_loss: 3.2657\n",
      "Epoch [30/50], Iter [200/439] Loss: 3.6533, average_loss: 3.2728\n",
      "Epoch [30/50], Iter [205/439] Loss: 5.3729, average_loss: 3.2817\n",
      "Epoch [30/50], Iter [210/439] Loss: 2.1311, average_loss: 3.2600\n",
      "Epoch [30/50], Iter [215/439] Loss: 2.0847, average_loss: 3.2478\n",
      "Epoch [30/50], Iter [220/439] Loss: 4.0316, average_loss: 3.2582\n",
      "Epoch [30/50], Iter [225/439] Loss: 2.5942, average_loss: 3.2509\n",
      "Epoch [30/50], Iter [230/439] Loss: 2.5493, average_loss: 3.2490\n",
      "Epoch [30/50], Iter [235/439] Loss: 2.3075, average_loss: 3.2368\n",
      "Epoch [30/50], Iter [240/439] Loss: 3.3891, average_loss: 3.2606\n",
      "Epoch [30/50], Iter [245/439] Loss: 5.7331, average_loss: 3.2646\n",
      "Epoch [30/50], Iter [250/439] Loss: 1.9764, average_loss: 3.2569\n",
      "Epoch [30/50], Iter [255/439] Loss: 2.7278, average_loss: 3.2472\n",
      "Epoch [30/50], Iter [260/439] Loss: 2.4937, average_loss: 3.2442\n",
      "Epoch [30/50], Iter [265/439] Loss: 3.5515, average_loss: 3.2634\n",
      "Epoch [30/50], Iter [270/439] Loss: 2.4292, average_loss: 3.2730\n",
      "Epoch [30/50], Iter [275/439] Loss: 2.0597, average_loss: 3.2692\n",
      "Epoch [30/50], Iter [280/439] Loss: 5.1740, average_loss: 3.2595\n",
      "Epoch [30/50], Iter [285/439] Loss: 2.8980, average_loss: 3.2600\n",
      "Epoch [30/50], Iter [290/439] Loss: 4.4361, average_loss: 3.2586\n",
      "Epoch [30/50], Iter [295/439] Loss: 4.6805, average_loss: 3.2701\n",
      "Epoch [30/50], Iter [300/439] Loss: 3.2315, average_loss: 3.2660\n",
      "Epoch [30/50], Iter [305/439] Loss: 2.5963, average_loss: 3.2614\n",
      "Epoch [30/50], Iter [310/439] Loss: 2.8165, average_loss: 3.2641\n",
      "Epoch [30/50], Iter [315/439] Loss: 4.1911, average_loss: 3.2659\n",
      "Epoch [30/50], Iter [320/439] Loss: 2.7881, average_loss: 3.2673\n",
      "Epoch [30/50], Iter [325/439] Loss: 3.3927, average_loss: 3.2680\n",
      "Epoch [30/50], Iter [330/439] Loss: 2.4223, average_loss: 3.2588\n",
      "Epoch [30/50], Iter [335/439] Loss: 3.2409, average_loss: 3.2582\n",
      "Epoch [30/50], Iter [340/439] Loss: 3.1311, average_loss: 3.2620\n",
      "Epoch [30/50], Iter [345/439] Loss: 5.2090, average_loss: 3.2722\n",
      "Epoch [30/50], Iter [350/439] Loss: 6.1718, average_loss: 3.2787\n",
      "Epoch [30/50], Iter [355/439] Loss: 1.9534, average_loss: 3.2769\n",
      "Epoch [30/50], Iter [360/439] Loss: 3.1633, average_loss: 3.2777\n",
      "Epoch [30/50], Iter [365/439] Loss: 1.9847, average_loss: 3.2697\n",
      "Epoch [30/50], Iter [370/439] Loss: 2.3506, average_loss: 3.2643\n",
      "Epoch [30/50], Iter [375/439] Loss: 2.3858, average_loss: 3.2600\n",
      "Epoch [30/50], Iter [380/439] Loss: 2.2815, average_loss: 3.2590\n",
      "Epoch [30/50], Iter [385/439] Loss: 3.6214, average_loss: 3.2578\n",
      "Epoch [30/50], Iter [390/439] Loss: 3.7526, average_loss: 3.2572\n",
      "Epoch [30/50], Iter [395/439] Loss: 3.5432, average_loss: 3.2680\n",
      "Epoch [30/50], Iter [400/439] Loss: 3.9142, average_loss: 3.2638\n",
      "Epoch [30/50], Iter [405/439] Loss: 2.2417, average_loss: 3.2686\n",
      "Epoch [30/50], Iter [410/439] Loss: 4.6266, average_loss: 3.2787\n",
      "Epoch [30/50], Iter [415/439] Loss: 2.8825, average_loss: 3.2881\n",
      "Epoch [30/50], Iter [420/439] Loss: 5.7260, average_loss: 3.2910\n",
      "Epoch [30/50], Iter [425/439] Loss: 3.8209, average_loss: 3.2987\n",
      "Epoch [30/50], Iter [430/439] Loss: 3.4427, average_loss: 3.2975\n",
      "Epoch [30/50], Iter [435/439] Loss: 2.2614, average_loss: 3.2959\n",
      "Test epoch [30/50], average_loss: 3.4252\n",
      "Epoch [31/50], Iter [5/439] Loss: 2.8152, average_loss: 3.7800\n",
      "Epoch [31/50], Iter [10/439] Loss: 3.8730, average_loss: 3.5944\n",
      "Epoch [31/50], Iter [15/439] Loss: 2.3574, average_loss: 3.4909\n",
      "Epoch [31/50], Iter [20/439] Loss: 2.3019, average_loss: 3.4450\n",
      "Epoch [31/50], Iter [25/439] Loss: 3.8447, average_loss: 3.3778\n",
      "Epoch [31/50], Iter [30/439] Loss: 3.2352, average_loss: 3.3748\n",
      "Epoch [31/50], Iter [35/439] Loss: 2.9499, average_loss: 3.2920\n",
      "Epoch [31/50], Iter [40/439] Loss: 4.3995, average_loss: 3.2973\n",
      "Epoch [31/50], Iter [45/439] Loss: 3.7461, average_loss: 3.3699\n",
      "Epoch [31/50], Iter [50/439] Loss: 2.9825, average_loss: 3.3448\n",
      "Epoch [31/50], Iter [55/439] Loss: 3.0588, average_loss: 3.3379\n",
      "Epoch [31/50], Iter [60/439] Loss: 2.4979, average_loss: 3.3643\n",
      "Epoch [31/50], Iter [65/439] Loss: 1.8071, average_loss: 3.3181\n",
      "Epoch [31/50], Iter [70/439] Loss: 3.4043, average_loss: 3.2911\n",
      "Epoch [31/50], Iter [75/439] Loss: 2.9160, average_loss: 3.2623\n",
      "Epoch [31/50], Iter [80/439] Loss: 2.0122, average_loss: 3.2530\n",
      "Epoch [31/50], Iter [85/439] Loss: 2.0817, average_loss: 3.2623\n",
      "Epoch [31/50], Iter [90/439] Loss: 4.2259, average_loss: 3.2697\n",
      "Epoch [31/50], Iter [95/439] Loss: 2.9759, average_loss: 3.2677\n",
      "Epoch [31/50], Iter [100/439] Loss: 3.5798, average_loss: 3.3017\n",
      "Epoch [31/50], Iter [105/439] Loss: 2.6707, average_loss: 3.3250\n",
      "Epoch [31/50], Iter [110/439] Loss: 2.7822, average_loss: 3.3526\n",
      "Epoch [31/50], Iter [115/439] Loss: 2.7059, average_loss: 3.3235\n",
      "Epoch [31/50], Iter [120/439] Loss: 2.0630, average_loss: 3.3032\n",
      "Epoch [31/50], Iter [125/439] Loss: 2.4715, average_loss: 3.3289\n",
      "Epoch [31/50], Iter [130/439] Loss: 3.2854, average_loss: 3.3356\n",
      "Epoch [31/50], Iter [135/439] Loss: 2.0248, average_loss: 3.3520\n",
      "Epoch [31/50], Iter [140/439] Loss: 3.6444, average_loss: 3.3227\n",
      "Epoch [31/50], Iter [145/439] Loss: 4.2347, average_loss: 3.3157\n",
      "Epoch [31/50], Iter [150/439] Loss: 3.4582, average_loss: 3.3194\n",
      "Epoch [31/50], Iter [155/439] Loss: 2.2037, average_loss: 3.3178\n",
      "Epoch [31/50], Iter [160/439] Loss: 4.5175, average_loss: 3.3409\n",
      "Epoch [31/50], Iter [165/439] Loss: 2.4545, average_loss: 3.3274\n",
      "Epoch [31/50], Iter [170/439] Loss: 3.9037, average_loss: 3.3259\n",
      "Epoch [31/50], Iter [175/439] Loss: 3.3882, average_loss: 3.3165\n",
      "Epoch [31/50], Iter [180/439] Loss: 3.1183, average_loss: 3.3088\n",
      "Epoch [31/50], Iter [185/439] Loss: 3.2939, average_loss: 3.3258\n",
      "Epoch [31/50], Iter [190/439] Loss: 4.0451, average_loss: 3.3311\n",
      "Epoch [31/50], Iter [195/439] Loss: 1.5881, average_loss: 3.3092\n",
      "Epoch [31/50], Iter [200/439] Loss: 3.4130, average_loss: 3.2955\n",
      "Epoch [31/50], Iter [205/439] Loss: 2.4410, average_loss: 3.2754\n",
      "Epoch [31/50], Iter [210/439] Loss: 3.7567, average_loss: 3.2714\n",
      "Epoch [31/50], Iter [215/439] Loss: 3.5826, average_loss: 3.2708\n",
      "Epoch [31/50], Iter [220/439] Loss: 1.3891, average_loss: 3.2665\n",
      "Epoch [31/50], Iter [225/439] Loss: 2.3147, average_loss: 3.2543\n",
      "Epoch [31/50], Iter [230/439] Loss: 1.9928, average_loss: 3.2400\n",
      "Epoch [31/50], Iter [235/439] Loss: 4.2247, average_loss: 3.2355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Iter [240/439] Loss: 3.2691, average_loss: 3.2318\n",
      "Epoch [31/50], Iter [245/439] Loss: 2.3368, average_loss: 3.2444\n",
      "Epoch [31/50], Iter [250/439] Loss: 3.4306, average_loss: 3.2416\n",
      "Epoch [31/50], Iter [255/439] Loss: 2.6409, average_loss: 3.2461\n",
      "Epoch [31/50], Iter [260/439] Loss: 4.5015, average_loss: 3.2465\n",
      "Epoch [31/50], Iter [265/439] Loss: 2.6099, average_loss: 3.2396\n",
      "Epoch [31/50], Iter [270/439] Loss: 2.3282, average_loss: 3.2414\n",
      "Epoch [31/50], Iter [275/439] Loss: 2.9409, average_loss: 3.2427\n",
      "Epoch [31/50], Iter [280/439] Loss: 3.1585, average_loss: 3.2450\n",
      "Epoch [31/50], Iter [285/439] Loss: 3.9698, average_loss: 3.2414\n",
      "Epoch [31/50], Iter [290/439] Loss: 2.8660, average_loss: 3.2329\n",
      "Epoch [31/50], Iter [295/439] Loss: 2.5630, average_loss: 3.2303\n",
      "Epoch [31/50], Iter [300/439] Loss: 2.2291, average_loss: 3.2244\n",
      "Epoch [31/50], Iter [305/439] Loss: 4.9870, average_loss: 3.2395\n",
      "Epoch [31/50], Iter [310/439] Loss: 3.8221, average_loss: 3.2399\n",
      "Epoch [31/50], Iter [315/439] Loss: 4.2122, average_loss: 3.2347\n",
      "Epoch [31/50], Iter [320/439] Loss: 3.3732, average_loss: 3.2253\n",
      "Epoch [31/50], Iter [325/439] Loss: 3.0385, average_loss: 3.2182\n",
      "Epoch [31/50], Iter [330/439] Loss: 3.3685, average_loss: 3.2128\n",
      "Epoch [31/50], Iter [335/439] Loss: 2.8567, average_loss: 3.2038\n",
      "Epoch [31/50], Iter [340/439] Loss: 1.9731, average_loss: 3.2113\n",
      "Epoch [31/50], Iter [345/439] Loss: 3.6658, average_loss: 3.2143\n",
      "Epoch [31/50], Iter [350/439] Loss: 2.3270, average_loss: 3.2184\n",
      "Epoch [31/50], Iter [355/439] Loss: 3.1203, average_loss: 3.2179\n",
      "Epoch [31/50], Iter [360/439] Loss: 4.7084, average_loss: 3.2221\n",
      "Epoch [31/50], Iter [365/439] Loss: 2.8732, average_loss: 3.2272\n",
      "Epoch [31/50], Iter [370/439] Loss: 3.3469, average_loss: 3.2287\n",
      "Epoch [31/50], Iter [375/439] Loss: 2.3471, average_loss: 3.2179\n",
      "Epoch [31/50], Iter [380/439] Loss: 3.6861, average_loss: 3.2191\n",
      "Epoch [31/50], Iter [385/439] Loss: 3.9399, average_loss: 3.2197\n",
      "Epoch [31/50], Iter [390/439] Loss: 3.3367, average_loss: 3.2195\n",
      "Epoch [31/50], Iter [395/439] Loss: 4.5900, average_loss: 3.2227\n",
      "Epoch [31/50], Iter [400/439] Loss: 3.1933, average_loss: 3.2252\n",
      "Epoch [31/50], Iter [405/439] Loss: 3.8827, average_loss: 3.2230\n",
      "Epoch [31/50], Iter [410/439] Loss: 2.4186, average_loss: 3.2325\n",
      "Epoch [31/50], Iter [415/439] Loss: 2.5446, average_loss: 3.2248\n",
      "Epoch [31/50], Iter [420/439] Loss: 2.5448, average_loss: 3.2113\n",
      "Epoch [31/50], Iter [425/439] Loss: 3.1581, average_loss: 3.2046\n",
      "Epoch [31/50], Iter [430/439] Loss: 4.7209, average_loss: 3.2045\n",
      "Epoch [31/50], Iter [435/439] Loss: 1.6302, average_loss: 3.1957\n",
      "Test epoch [31/50], average_loss: 3.1791\n",
      "Epoch [32/50], Iter [5/439] Loss: 3.1996, average_loss: 3.4384\n",
      "Epoch [32/50], Iter [10/439] Loss: 1.8579, average_loss: 2.9536\n",
      "Epoch [32/50], Iter [15/439] Loss: 2.2879, average_loss: 2.8021\n",
      "Epoch [32/50], Iter [20/439] Loss: 3.4413, average_loss: 2.9643\n",
      "Epoch [32/50], Iter [25/439] Loss: 2.2012, average_loss: 2.9068\n",
      "Epoch [32/50], Iter [30/439] Loss: 1.7521, average_loss: 2.8584\n",
      "Epoch [32/50], Iter [35/439] Loss: 2.9377, average_loss: 2.8250\n",
      "Epoch [32/50], Iter [40/439] Loss: 1.9587, average_loss: 2.7985\n",
      "Epoch [32/50], Iter [45/439] Loss: 3.2327, average_loss: 2.7479\n",
      "Epoch [32/50], Iter [50/439] Loss: 2.6278, average_loss: 2.7431\n",
      "Epoch [32/50], Iter [55/439] Loss: 3.8398, average_loss: 2.7629\n",
      "Epoch [32/50], Iter [60/439] Loss: 2.8186, average_loss: 2.8425\n",
      "Epoch [32/50], Iter [65/439] Loss: 4.7892, average_loss: 2.8983\n",
      "Epoch [32/50], Iter [70/439] Loss: 2.7041, average_loss: 2.8804\n",
      "Epoch [32/50], Iter [75/439] Loss: 2.7455, average_loss: 2.8938\n",
      "Epoch [32/50], Iter [80/439] Loss: 3.9821, average_loss: 2.9505\n",
      "Epoch [32/50], Iter [85/439] Loss: 1.5996, average_loss: 2.9503\n",
      "Epoch [32/50], Iter [90/439] Loss: 2.8898, average_loss: 2.9522\n",
      "Epoch [32/50], Iter [95/439] Loss: 3.1063, average_loss: 3.0039\n",
      "Epoch [32/50], Iter [100/439] Loss: 3.2940, average_loss: 3.0494\n",
      "Epoch [32/50], Iter [105/439] Loss: 2.8599, average_loss: 3.0430\n",
      "Epoch [32/50], Iter [110/439] Loss: 2.2559, average_loss: 3.0465\n",
      "Epoch [32/50], Iter [115/439] Loss: 2.7331, average_loss: 3.0387\n",
      "Epoch [32/50], Iter [120/439] Loss: 3.2395, average_loss: 3.0370\n",
      "Epoch [32/50], Iter [125/439] Loss: 3.0621, average_loss: 3.0380\n",
      "Epoch [32/50], Iter [130/439] Loss: 2.3955, average_loss: 3.0176\n",
      "Epoch [32/50], Iter [135/439] Loss: 3.5267, average_loss: 2.9981\n",
      "Epoch [32/50], Iter [140/439] Loss: 3.8947, average_loss: 3.0167\n",
      "Epoch [32/50], Iter [145/439] Loss: 3.7379, average_loss: 3.0446\n",
      "Epoch [32/50], Iter [150/439] Loss: 3.1196, average_loss: 3.0373\n",
      "Epoch [32/50], Iter [155/439] Loss: 3.1862, average_loss: 3.0268\n",
      "Epoch [32/50], Iter [160/439] Loss: 4.3351, average_loss: 3.0452\n",
      "Epoch [32/50], Iter [165/439] Loss: 1.9428, average_loss: 3.0518\n",
      "Epoch [32/50], Iter [170/439] Loss: 4.7086, average_loss: 3.0538\n",
      "Epoch [32/50], Iter [175/439] Loss: 3.1677, average_loss: 3.0518\n",
      "Epoch [32/50], Iter [180/439] Loss: 2.2753, average_loss: 3.0395\n",
      "Epoch [32/50], Iter [185/439] Loss: 6.8939, average_loss: 3.0627\n",
      "Epoch [32/50], Iter [190/439] Loss: 3.2446, average_loss: 3.0771\n",
      "Epoch [32/50], Iter [195/439] Loss: 2.9632, average_loss: 3.0910\n",
      "Epoch [32/50], Iter [200/439] Loss: 2.6952, average_loss: 3.0985\n",
      "Epoch [32/50], Iter [205/439] Loss: 4.3658, average_loss: 3.0966\n",
      "Epoch [32/50], Iter [210/439] Loss: 3.0991, average_loss: 3.1049\n",
      "Epoch [32/50], Iter [215/439] Loss: 4.2540, average_loss: 3.0973\n",
      "Epoch [32/50], Iter [220/439] Loss: 3.2607, average_loss: 3.0910\n",
      "Epoch [32/50], Iter [225/439] Loss: 7.3827, average_loss: 3.0981\n",
      "Epoch [32/50], Iter [230/439] Loss: 4.2196, average_loss: 3.0972\n",
      "Epoch [32/50], Iter [235/439] Loss: 5.4276, average_loss: 3.1086\n",
      "Epoch [32/50], Iter [240/439] Loss: 2.0400, average_loss: 3.0935\n",
      "Epoch [32/50], Iter [245/439] Loss: 1.6508, average_loss: 3.0942\n",
      "Epoch [32/50], Iter [250/439] Loss: 2.5999, average_loss: 3.0864\n",
      "Epoch [32/50], Iter [255/439] Loss: 4.3733, average_loss: 3.0950\n",
      "Epoch [32/50], Iter [260/439] Loss: 2.7401, average_loss: 3.0881\n",
      "Epoch [32/50], Iter [265/439] Loss: 3.7590, average_loss: 3.0926\n",
      "Epoch [32/50], Iter [270/439] Loss: 2.4833, average_loss: 3.0985\n",
      "Epoch [32/50], Iter [275/439] Loss: 2.9670, average_loss: 3.0952\n",
      "Epoch [32/50], Iter [280/439] Loss: 4.6717, average_loss: 3.0980\n",
      "Epoch [32/50], Iter [285/439] Loss: 4.5681, average_loss: 3.1103\n",
      "Epoch [32/50], Iter [290/439] Loss: 3.6182, average_loss: 3.1058\n",
      "Epoch [32/50], Iter [295/439] Loss: 3.4995, average_loss: 3.1019\n",
      "Epoch [32/50], Iter [300/439] Loss: 3.0872, average_loss: 3.1051\n",
      "Epoch [32/50], Iter [305/439] Loss: 2.3857, average_loss: 3.1031\n",
      "Epoch [32/50], Iter [310/439] Loss: 2.3475, average_loss: 3.1038\n",
      "Epoch [32/50], Iter [315/439] Loss: 1.8778, average_loss: 3.0981\n",
      "Epoch [32/50], Iter [320/439] Loss: 3.0599, average_loss: 3.1019\n",
      "Epoch [32/50], Iter [325/439] Loss: 1.9932, average_loss: 3.0979\n",
      "Epoch [32/50], Iter [330/439] Loss: 1.6892, average_loss: 3.0955\n",
      "Epoch [32/50], Iter [335/439] Loss: 3.5583, average_loss: 3.1096\n",
      "Epoch [32/50], Iter [340/439] Loss: 4.2823, average_loss: 3.1045\n",
      "Epoch [32/50], Iter [345/439] Loss: 2.2518, average_loss: 3.0995\n",
      "Epoch [32/50], Iter [350/439] Loss: 3.4830, average_loss: 3.0975\n",
      "Epoch [32/50], Iter [355/439] Loss: 1.8390, average_loss: 3.0934\n",
      "Epoch [32/50], Iter [360/439] Loss: 3.1095, average_loss: 3.1073\n",
      "Epoch [32/50], Iter [365/439] Loss: 2.7675, average_loss: 3.1001\n",
      "Epoch [32/50], Iter [370/439] Loss: 2.5156, average_loss: 3.0947\n",
      "Epoch [32/50], Iter [375/439] Loss: 2.1988, average_loss: 3.0854\n",
      "Epoch [32/50], Iter [380/439] Loss: 3.6681, average_loss: 3.0860\n",
      "Epoch [32/50], Iter [385/439] Loss: 3.4605, average_loss: 3.0878\n",
      "Epoch [32/50], Iter [390/439] Loss: 2.5110, average_loss: 3.0816\n",
      "Epoch [32/50], Iter [395/439] Loss: 2.0731, average_loss: 3.0781\n",
      "Epoch [32/50], Iter [400/439] Loss: 2.9339, average_loss: 3.0787\n",
      "Epoch [32/50], Iter [405/439] Loss: 2.6925, average_loss: 3.0767\n",
      "Epoch [32/50], Iter [410/439] Loss: 3.9153, average_loss: 3.0744\n",
      "Epoch [32/50], Iter [415/439] Loss: 3.0595, average_loss: 3.0747\n",
      "Epoch [32/50], Iter [420/439] Loss: 2.7820, average_loss: 3.0735\n",
      "Epoch [32/50], Iter [425/439] Loss: 3.6125, average_loss: 3.0710\n",
      "Epoch [32/50], Iter [430/439] Loss: 3.8545, average_loss: 3.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Iter [435/439] Loss: 2.5650, average_loss: 3.0735\n",
      "Test epoch [32/50], average_loss: 3.1647\n",
      "Epoch [33/50], Iter [5/439] Loss: 2.7508, average_loss: 2.9077\n",
      "Epoch [33/50], Iter [10/439] Loss: 2.8012, average_loss: 2.7215\n",
      "Epoch [33/50], Iter [15/439] Loss: 2.6915, average_loss: 2.6227\n",
      "Epoch [33/50], Iter [20/439] Loss: 4.2053, average_loss: 2.9751\n",
      "Epoch [33/50], Iter [25/439] Loss: 2.1700, average_loss: 2.8714\n",
      "Epoch [33/50], Iter [30/439] Loss: 3.1520, average_loss: 2.8890\n",
      "Epoch [33/50], Iter [35/439] Loss: 3.0283, average_loss: 2.9438\n",
      "Epoch [33/50], Iter [40/439] Loss: 1.7063, average_loss: 2.9157\n",
      "Epoch [33/50], Iter [45/439] Loss: 3.8408, average_loss: 2.9677\n",
      "Epoch [33/50], Iter [50/439] Loss: 1.7840, average_loss: 2.9020\n",
      "Epoch [33/50], Iter [55/439] Loss: 1.9054, average_loss: 2.8908\n",
      "Epoch [33/50], Iter [60/439] Loss: 2.4342, average_loss: 2.8889\n",
      "Epoch [33/50], Iter [65/439] Loss: 3.3096, average_loss: 2.8582\n",
      "Epoch [33/50], Iter [70/439] Loss: 3.7002, average_loss: 2.8731\n",
      "Epoch [33/50], Iter [75/439] Loss: 3.5233, average_loss: 2.8704\n",
      "Epoch [33/50], Iter [80/439] Loss: 1.6318, average_loss: 2.8298\n",
      "Epoch [33/50], Iter [85/439] Loss: 3.3659, average_loss: 2.8560\n",
      "Epoch [33/50], Iter [90/439] Loss: 1.9609, average_loss: 2.8427\n",
      "Epoch [33/50], Iter [95/439] Loss: 4.4810, average_loss: 2.9135\n",
      "Epoch [33/50], Iter [100/439] Loss: 3.7698, average_loss: 2.9428\n",
      "Epoch [33/50], Iter [105/439] Loss: 2.0606, average_loss: 2.9500\n",
      "Epoch [33/50], Iter [110/439] Loss: 2.8966, average_loss: 2.9290\n",
      "Epoch [33/50], Iter [115/439] Loss: 3.9763, average_loss: 2.9386\n",
      "Epoch [33/50], Iter [120/439] Loss: 3.5806, average_loss: 2.9506\n",
      "Epoch [33/50], Iter [125/439] Loss: 3.8594, average_loss: 2.9572\n",
      "Epoch [33/50], Iter [130/439] Loss: 3.3003, average_loss: 2.9674\n",
      "Epoch [33/50], Iter [135/439] Loss: 4.2516, average_loss: 2.9738\n",
      "Epoch [33/50], Iter [140/439] Loss: 1.3906, average_loss: 2.9732\n",
      "Epoch [33/50], Iter [145/439] Loss: 3.6070, average_loss: 2.9744\n",
      "Epoch [33/50], Iter [150/439] Loss: 2.9989, average_loss: 2.9719\n",
      "Epoch [33/50], Iter [155/439] Loss: 3.0989, average_loss: 2.9672\n",
      "Epoch [33/50], Iter [160/439] Loss: 2.8527, average_loss: 2.9613\n",
      "Epoch [33/50], Iter [165/439] Loss: 2.5301, average_loss: 2.9534\n",
      "Epoch [33/50], Iter [170/439] Loss: 2.4857, average_loss: 2.9509\n",
      "Epoch [33/50], Iter [175/439] Loss: 3.6346, average_loss: 2.9481\n",
      "Epoch [33/50], Iter [180/439] Loss: 2.0690, average_loss: 2.9515\n",
      "Epoch [33/50], Iter [185/439] Loss: 3.7419, average_loss: 2.9579\n",
      "Epoch [33/50], Iter [190/439] Loss: 3.6620, average_loss: 2.9564\n",
      "Epoch [33/50], Iter [195/439] Loss: 1.3439, average_loss: 2.9471\n",
      "Epoch [33/50], Iter [200/439] Loss: 3.3637, average_loss: 2.9390\n",
      "Epoch [33/50], Iter [205/439] Loss: 2.8078, average_loss: 2.9263\n",
      "Epoch [33/50], Iter [210/439] Loss: 2.7885, average_loss: 2.9295\n",
      "Epoch [33/50], Iter [215/439] Loss: 3.7571, average_loss: 2.9262\n",
      "Epoch [33/50], Iter [220/439] Loss: 3.0991, average_loss: 2.9316\n",
      "Epoch [33/50], Iter [225/439] Loss: 5.9740, average_loss: 2.9389\n",
      "Epoch [33/50], Iter [230/439] Loss: 2.5631, average_loss: 2.9403\n",
      "Epoch [33/50], Iter [235/439] Loss: 1.8318, average_loss: 2.9460\n",
      "Epoch [33/50], Iter [240/439] Loss: 3.9611, average_loss: 2.9477\n",
      "Epoch [33/50], Iter [245/439] Loss: 8.2550, average_loss: 2.9663\n",
      "Epoch [33/50], Iter [250/439] Loss: 3.8076, average_loss: 2.9712\n",
      "Epoch [33/50], Iter [255/439] Loss: 2.8170, average_loss: 2.9718\n",
      "Epoch [33/50], Iter [260/439] Loss: 7.2173, average_loss: 2.9933\n",
      "Epoch [33/50], Iter [265/439] Loss: 3.1180, average_loss: 2.9941\n",
      "Epoch [33/50], Iter [270/439] Loss: 7.3940, average_loss: 3.0098\n",
      "Epoch [33/50], Iter [275/439] Loss: 3.9108, average_loss: 3.0126\n",
      "Epoch [33/50], Iter [280/439] Loss: 1.9404, average_loss: 3.0164\n",
      "Epoch [33/50], Iter [285/439] Loss: 2.9315, average_loss: 3.0216\n",
      "Epoch [33/50], Iter [290/439] Loss: 3.1403, average_loss: 3.0221\n",
      "Epoch [33/50], Iter [295/439] Loss: 2.3989, average_loss: 3.0175\n",
      "Epoch [33/50], Iter [300/439] Loss: 3.1286, average_loss: 3.0173\n",
      "Epoch [33/50], Iter [305/439] Loss: 1.6455, average_loss: 3.0228\n",
      "Epoch [33/50], Iter [310/439] Loss: 2.9208, average_loss: 3.0122\n",
      "Epoch [33/50], Iter [315/439] Loss: 4.5928, average_loss: 3.0099\n",
      "Epoch [33/50], Iter [320/439] Loss: 2.0924, average_loss: 3.0055\n",
      "Epoch [33/50], Iter [325/439] Loss: 1.9903, average_loss: 3.0004\n",
      "Epoch [33/50], Iter [330/439] Loss: 2.6812, average_loss: 2.9950\n",
      "Epoch [33/50], Iter [335/439] Loss: 2.8420, average_loss: 3.0016\n",
      "Epoch [33/50], Iter [340/439] Loss: 1.8572, average_loss: 3.0085\n",
      "Epoch [33/50], Iter [345/439] Loss: 1.7726, average_loss: 3.0005\n",
      "Epoch [33/50], Iter [350/439] Loss: 3.8804, average_loss: 2.9913\n",
      "Epoch [33/50], Iter [355/439] Loss: 3.7909, average_loss: 2.9879\n",
      "Epoch [33/50], Iter [360/439] Loss: 2.7473, average_loss: 2.9974\n",
      "Epoch [33/50], Iter [365/439] Loss: 3.0638, average_loss: 2.9999\n",
      "Epoch [33/50], Iter [370/439] Loss: 3.4065, average_loss: 3.0077\n",
      "Epoch [33/50], Iter [375/439] Loss: 2.2013, average_loss: 3.0043\n",
      "Epoch [33/50], Iter [380/439] Loss: 1.5049, average_loss: 3.0009\n",
      "Epoch [33/50], Iter [385/439] Loss: 4.8649, average_loss: 3.0046\n",
      "Epoch [33/50], Iter [390/439] Loss: 2.3972, average_loss: 3.0079\n",
      "Epoch [33/50], Iter [395/439] Loss: 3.9387, average_loss: 3.0213\n",
      "Epoch [33/50], Iter [400/439] Loss: 3.8531, average_loss: 3.0218\n",
      "Epoch [33/50], Iter [405/439] Loss: 3.1392, average_loss: 3.0338\n",
      "Epoch [33/50], Iter [410/439] Loss: 2.0890, average_loss: 3.0276\n",
      "Epoch [33/50], Iter [415/439] Loss: 2.0759, average_loss: 3.0256\n",
      "Epoch [33/50], Iter [420/439] Loss: 2.8162, average_loss: 3.0194\n",
      "Epoch [33/50], Iter [425/439] Loss: 2.7133, average_loss: 3.0168\n",
      "Epoch [33/50], Iter [430/439] Loss: 2.2124, average_loss: 3.0178\n",
      "Epoch [33/50], Iter [435/439] Loss: 2.7490, average_loss: 3.0119\n",
      "Test epoch [33/50], average_loss: 3.1347\n",
      "Epoch [34/50], Iter [5/439] Loss: 2.9496, average_loss: 2.9022\n",
      "Epoch [34/50], Iter [10/439] Loss: 3.9575, average_loss: 3.0077\n",
      "Epoch [34/50], Iter [15/439] Loss: 2.4420, average_loss: 2.9158\n",
      "Epoch [34/50], Iter [20/439] Loss: 2.4707, average_loss: 2.9375\n",
      "Epoch [34/50], Iter [25/439] Loss: 3.9907, average_loss: 2.9160\n",
      "Epoch [34/50], Iter [30/439] Loss: 2.5021, average_loss: 2.9481\n",
      "Epoch [34/50], Iter [35/439] Loss: 2.1751, average_loss: 2.9475\n",
      "Epoch [34/50], Iter [40/439] Loss: 3.0868, average_loss: 3.2231\n",
      "Epoch [34/50], Iter [45/439] Loss: 2.1968, average_loss: 3.1088\n",
      "Epoch [34/50], Iter [50/439] Loss: 3.2109, average_loss: 3.0482\n",
      "Epoch [34/50], Iter [55/439] Loss: 2.7772, average_loss: 2.9880\n",
      "Epoch [34/50], Iter [60/439] Loss: 4.7284, average_loss: 3.0156\n",
      "Epoch [34/50], Iter [65/439] Loss: 2.6414, average_loss: 3.0038\n",
      "Epoch [34/50], Iter [70/439] Loss: 2.7418, average_loss: 3.0096\n",
      "Epoch [34/50], Iter [75/439] Loss: 3.2088, average_loss: 3.0244\n",
      "Epoch [34/50], Iter [80/439] Loss: 4.8322, average_loss: 3.0208\n",
      "Epoch [34/50], Iter [85/439] Loss: 1.6590, average_loss: 3.0658\n",
      "Epoch [34/50], Iter [90/439] Loss: 2.7741, average_loss: 3.0888\n",
      "Epoch [34/50], Iter [95/439] Loss: 1.5940, average_loss: 3.0865\n",
      "Epoch [34/50], Iter [100/439] Loss: 3.7400, average_loss: 3.1263\n",
      "Epoch [34/50], Iter [105/439] Loss: 5.7613, average_loss: 3.1471\n",
      "Epoch [34/50], Iter [110/439] Loss: 1.9891, average_loss: 3.1229\n",
      "Epoch [34/50], Iter [115/439] Loss: 2.4816, average_loss: 3.1059\n",
      "Epoch [34/50], Iter [120/439] Loss: 2.3631, average_loss: 3.0835\n",
      "Epoch [34/50], Iter [125/439] Loss: 2.3800, average_loss: 3.0565\n",
      "Epoch [34/50], Iter [130/439] Loss: 1.9072, average_loss: 3.0645\n",
      "Epoch [34/50], Iter [135/439] Loss: 3.7671, average_loss: 3.0940\n",
      "Epoch [34/50], Iter [140/439] Loss: 3.3170, average_loss: 3.1065\n",
      "Epoch [34/50], Iter [145/439] Loss: 1.3715, average_loss: 3.0841\n",
      "Epoch [34/50], Iter [150/439] Loss: 2.8774, average_loss: 3.0625\n",
      "Epoch [34/50], Iter [155/439] Loss: 2.8522, average_loss: 3.0565\n",
      "Epoch [34/50], Iter [160/439] Loss: 3.1037, average_loss: 3.0649\n",
      "Epoch [34/50], Iter [165/439] Loss: 2.1711, average_loss: 3.0571\n",
      "Epoch [34/50], Iter [170/439] Loss: 2.8712, average_loss: 3.0440\n",
      "Epoch [34/50], Iter [175/439] Loss: 3.1471, average_loss: 3.0333\n",
      "Epoch [34/50], Iter [180/439] Loss: 2.8746, average_loss: 3.0214\n",
      "Epoch [34/50], Iter [185/439] Loss: 2.1073, average_loss: 3.0347\n",
      "Epoch [34/50], Iter [190/439] Loss: 3.4417, average_loss: 3.0421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Iter [195/439] Loss: 3.0393, average_loss: 3.0370\n",
      "Epoch [34/50], Iter [200/439] Loss: 2.7870, average_loss: 3.0226\n",
      "Epoch [34/50], Iter [205/439] Loss: 1.7006, average_loss: 3.0116\n",
      "Epoch [34/50], Iter [210/439] Loss: 3.1311, average_loss: 3.0123\n",
      "Epoch [34/50], Iter [215/439] Loss: 4.0410, average_loss: 3.0278\n",
      "Epoch [34/50], Iter [220/439] Loss: 2.9362, average_loss: 3.0265\n",
      "Epoch [34/50], Iter [225/439] Loss: 1.0003, average_loss: 3.0185\n",
      "Epoch [34/50], Iter [230/439] Loss: 3.3361, average_loss: 3.0134\n",
      "Epoch [34/50], Iter [235/439] Loss: 1.7493, average_loss: 3.0042\n",
      "Epoch [34/50], Iter [240/439] Loss: 2.1865, average_loss: 2.9996\n",
      "Epoch [34/50], Iter [245/439] Loss: 4.5881, average_loss: 2.9980\n",
      "Epoch [34/50], Iter [250/439] Loss: 4.7739, average_loss: 3.0103\n",
      "Epoch [34/50], Iter [255/439] Loss: 2.2253, average_loss: 2.9974\n",
      "Epoch [34/50], Iter [260/439] Loss: 2.3324, average_loss: 2.9916\n",
      "Epoch [34/50], Iter [265/439] Loss: 3.1661, average_loss: 2.9939\n",
      "Epoch [34/50], Iter [270/439] Loss: 2.8208, average_loss: 2.9817\n",
      "Epoch [34/50], Iter [275/439] Loss: 2.8382, average_loss: 2.9765\n",
      "Epoch [34/50], Iter [280/439] Loss: 2.7840, average_loss: 2.9761\n",
      "Epoch [34/50], Iter [285/439] Loss: 3.2345, average_loss: 2.9815\n",
      "Epoch [34/50], Iter [290/439] Loss: 1.8697, average_loss: 2.9771\n",
      "Epoch [34/50], Iter [295/439] Loss: 4.1640, average_loss: 2.9813\n",
      "Epoch [34/50], Iter [300/439] Loss: 2.2531, average_loss: 2.9897\n",
      "Epoch [34/50], Iter [305/439] Loss: 3.0067, average_loss: 2.9921\n",
      "Epoch [34/50], Iter [310/439] Loss: 2.8605, average_loss: 2.9985\n",
      "Epoch [34/50], Iter [315/439] Loss: 3.3965, average_loss: 3.0009\n",
      "Epoch [34/50], Iter [320/439] Loss: 2.4594, average_loss: 3.0050\n",
      "Epoch [34/50], Iter [325/439] Loss: 3.5514, average_loss: 3.0021\n",
      "Epoch [34/50], Iter [330/439] Loss: 4.2919, average_loss: 2.9968\n",
      "Epoch [34/50], Iter [335/439] Loss: 2.9606, average_loss: 3.0005\n",
      "Epoch [34/50], Iter [340/439] Loss: 2.8779, average_loss: 2.9978\n",
      "Epoch [34/50], Iter [345/439] Loss: 3.2048, average_loss: 2.9984\n",
      "Epoch [34/50], Iter [350/439] Loss: 1.3124, average_loss: 2.9979\n",
      "Epoch [34/50], Iter [355/439] Loss: 3.1043, average_loss: 3.0026\n",
      "Epoch [34/50], Iter [360/439] Loss: 2.8632, average_loss: 3.0126\n",
      "Epoch [34/50], Iter [365/439] Loss: 3.3336, average_loss: 3.0160\n",
      "Epoch [34/50], Iter [370/439] Loss: 2.6216, average_loss: 3.0099\n",
      "Epoch [34/50], Iter [375/439] Loss: 3.8978, average_loss: 3.0101\n",
      "Epoch [34/50], Iter [380/439] Loss: 2.0733, average_loss: 3.0008\n",
      "Epoch [34/50], Iter [385/439] Loss: 2.2713, average_loss: 3.0065\n",
      "Epoch [34/50], Iter [390/439] Loss: 3.5995, average_loss: 3.0156\n",
      "Epoch [34/50], Iter [395/439] Loss: 2.8432, average_loss: 3.0189\n",
      "Epoch [34/50], Iter [400/439] Loss: 2.3676, average_loss: 3.0240\n",
      "Epoch [34/50], Iter [405/439] Loss: 1.9723, average_loss: 3.0262\n",
      "Epoch [34/50], Iter [410/439] Loss: 1.8106, average_loss: 3.0266\n",
      "Epoch [34/50], Iter [415/439] Loss: 3.3891, average_loss: 3.0333\n",
      "Epoch [34/50], Iter [420/439] Loss: 2.3436, average_loss: 3.0349\n",
      "Epoch [34/50], Iter [425/439] Loss: 3.3265, average_loss: 3.0312\n",
      "Epoch [34/50], Iter [430/439] Loss: 3.1345, average_loss: 3.0268\n",
      "Epoch [34/50], Iter [435/439] Loss: 4.5422, average_loss: 3.0277\n",
      "Test epoch [34/50], average_loss: 3.0882\n",
      "Epoch [35/50], Iter [5/439] Loss: 3.6325, average_loss: 2.5363\n",
      "Epoch [35/50], Iter [10/439] Loss: 2.7012, average_loss: 3.0110\n",
      "Epoch [35/50], Iter [15/439] Loss: 4.4312, average_loss: 3.1578\n",
      "Epoch [35/50], Iter [20/439] Loss: 1.8730, average_loss: 3.1976\n",
      "Epoch [35/50], Iter [25/439] Loss: 4.1931, average_loss: 3.2108\n",
      "Epoch [35/50], Iter [30/439] Loss: 1.5508, average_loss: 3.0976\n",
      "Epoch [35/50], Iter [35/439] Loss: 3.6535, average_loss: 3.1697\n",
      "Epoch [35/50], Iter [40/439] Loss: 3.0410, average_loss: 3.0810\n",
      "Epoch [35/50], Iter [45/439] Loss: 3.2010, average_loss: 3.0515\n",
      "Epoch [35/50], Iter [50/439] Loss: 2.3748, average_loss: 3.0960\n",
      "Epoch [35/50], Iter [55/439] Loss: 2.4901, average_loss: 3.0286\n",
      "Epoch [35/50], Iter [60/439] Loss: 3.1793, average_loss: 3.0439\n",
      "Epoch [35/50], Iter [65/439] Loss: 3.6697, average_loss: 3.0379\n",
      "Epoch [35/50], Iter [70/439] Loss: 1.8711, average_loss: 3.0117\n",
      "Epoch [35/50], Iter [75/439] Loss: 2.7672, average_loss: 3.0100\n",
      "Epoch [35/50], Iter [80/439] Loss: 2.8876, average_loss: 2.9895\n",
      "Epoch [35/50], Iter [85/439] Loss: 2.2724, average_loss: 2.9936\n",
      "Epoch [35/50], Iter [90/439] Loss: 1.9281, average_loss: 2.9902\n",
      "Epoch [35/50], Iter [95/439] Loss: 2.4322, average_loss: 2.9842\n",
      "Epoch [35/50], Iter [100/439] Loss: 1.7113, average_loss: 2.9883\n",
      "Epoch [35/50], Iter [105/439] Loss: 4.7412, average_loss: 3.0195\n",
      "Epoch [35/50], Iter [110/439] Loss: 1.5696, average_loss: 3.0072\n",
      "Epoch [35/50], Iter [115/439] Loss: 2.8773, average_loss: 2.9870\n",
      "Epoch [35/50], Iter [120/439] Loss: 3.0641, average_loss: 2.9805\n",
      "Epoch [35/50], Iter [125/439] Loss: 2.0701, average_loss: 2.9972\n",
      "Epoch [35/50], Iter [130/439] Loss: 1.9221, average_loss: 2.9929\n",
      "Epoch [35/50], Iter [135/439] Loss: 1.9294, average_loss: 2.9794\n",
      "Epoch [35/50], Iter [140/439] Loss: 2.5158, average_loss: 2.9912\n",
      "Epoch [35/50], Iter [145/439] Loss: 2.2766, average_loss: 2.9609\n",
      "Epoch [35/50], Iter [150/439] Loss: 3.0123, average_loss: 2.9625\n",
      "Epoch [35/50], Iter [155/439] Loss: 2.2491, average_loss: 2.9670\n",
      "Epoch [35/50], Iter [160/439] Loss: 3.8340, average_loss: 2.9626\n",
      "Epoch [35/50], Iter [165/439] Loss: 2.4317, average_loss: 2.9611\n",
      "Epoch [35/50], Iter [170/439] Loss: 3.3958, average_loss: 2.9759\n",
      "Epoch [35/50], Iter [175/439] Loss: 2.2690, average_loss: 2.9790\n",
      "Epoch [35/50], Iter [180/439] Loss: 2.4607, average_loss: 2.9907\n",
      "Epoch [35/50], Iter [185/439] Loss: 4.2269, average_loss: 3.0036\n",
      "Epoch [35/50], Iter [190/439] Loss: 1.9138, average_loss: 2.9932\n",
      "Epoch [35/50], Iter [195/439] Loss: 4.6962, average_loss: 2.9927\n",
      "Epoch [35/50], Iter [200/439] Loss: 2.3337, average_loss: 2.9893\n",
      "Epoch [35/50], Iter [205/439] Loss: 2.2064, average_loss: 2.9685\n",
      "Epoch [35/50], Iter [210/439] Loss: 2.9157, average_loss: 2.9670\n",
      "Epoch [35/50], Iter [215/439] Loss: 2.4242, average_loss: 2.9575\n",
      "Epoch [35/50], Iter [220/439] Loss: 2.2938, average_loss: 2.9516\n",
      "Epoch [35/50], Iter [225/439] Loss: 3.1596, average_loss: 2.9455\n",
      "Epoch [35/50], Iter [230/439] Loss: 3.9514, average_loss: 2.9450\n",
      "Epoch [35/50], Iter [235/439] Loss: 3.3650, average_loss: 2.9428\n",
      "Epoch [35/50], Iter [240/439] Loss: 4.0882, average_loss: 2.9538\n",
      "Epoch [35/50], Iter [245/439] Loss: 2.5605, average_loss: 2.9702\n",
      "Epoch [35/50], Iter [250/439] Loss: 2.7222, average_loss: 2.9681\n",
      "Epoch [35/50], Iter [255/439] Loss: 2.8629, average_loss: 2.9728\n",
      "Epoch [35/50], Iter [260/439] Loss: 2.2211, average_loss: 2.9648\n",
      "Epoch [35/50], Iter [265/439] Loss: 1.5836, average_loss: 2.9491\n",
      "Epoch [35/50], Iter [270/439] Loss: 2.2792, average_loss: 2.9456\n",
      "Epoch [35/50], Iter [275/439] Loss: 2.8940, average_loss: 2.9450\n",
      "Epoch [35/50], Iter [280/439] Loss: 2.2073, average_loss: 2.9457\n",
      "Epoch [35/50], Iter [285/439] Loss: 3.0114, average_loss: 2.9442\n",
      "Epoch [35/50], Iter [290/439] Loss: 2.7385, average_loss: 2.9466\n",
      "Epoch [35/50], Iter [295/439] Loss: 3.0013, average_loss: 2.9487\n",
      "Epoch [35/50], Iter [300/439] Loss: 3.5429, average_loss: 2.9487\n",
      "Epoch [35/50], Iter [305/439] Loss: 3.0603, average_loss: 2.9530\n",
      "Epoch [35/50], Iter [310/439] Loss: 1.9741, average_loss: 2.9560\n",
      "Epoch [35/50], Iter [315/439] Loss: 2.2507, average_loss: 2.9527\n",
      "Epoch [35/50], Iter [320/439] Loss: 3.9232, average_loss: 2.9522\n",
      "Epoch [35/50], Iter [325/439] Loss: 2.3707, average_loss: 2.9545\n",
      "Epoch [35/50], Iter [330/439] Loss: 4.1168, average_loss: 2.9733\n",
      "Epoch [35/50], Iter [335/439] Loss: 3.9637, average_loss: 2.9854\n",
      "Epoch [35/50], Iter [340/439] Loss: 3.9016, average_loss: 2.9856\n",
      "Epoch [35/50], Iter [345/439] Loss: 2.1292, average_loss: 2.9904\n",
      "Epoch [35/50], Iter [350/439] Loss: 3.0637, average_loss: 2.9842\n",
      "Epoch [35/50], Iter [355/439] Loss: 2.8554, average_loss: 2.9808\n",
      "Epoch [35/50], Iter [360/439] Loss: 3.7306, average_loss: 2.9908\n",
      "Epoch [35/50], Iter [365/439] Loss: 3.2098, average_loss: 2.9850\n",
      "Epoch [35/50], Iter [370/439] Loss: 5.8302, average_loss: 3.0082\n",
      "Epoch [35/50], Iter [375/439] Loss: 2.3944, average_loss: 3.0073\n",
      "Epoch [35/50], Iter [380/439] Loss: 1.8462, average_loss: 3.0071\n",
      "Epoch [35/50], Iter [385/439] Loss: 3.0239, average_loss: 3.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Iter [390/439] Loss: 2.3022, average_loss: 3.0068\n",
      "Epoch [35/50], Iter [395/439] Loss: 2.4502, average_loss: 3.0033\n",
      "Epoch [35/50], Iter [400/439] Loss: 2.0892, average_loss: 3.0036\n",
      "Epoch [35/50], Iter [405/439] Loss: 3.1707, average_loss: 3.0038\n",
      "Epoch [35/50], Iter [410/439] Loss: 2.8406, average_loss: 2.9985\n",
      "Epoch [35/50], Iter [415/439] Loss: 3.5413, average_loss: 3.0051\n",
      "Epoch [35/50], Iter [420/439] Loss: 1.5730, average_loss: 2.9990\n",
      "Epoch [35/50], Iter [425/439] Loss: 5.3595, average_loss: 3.0027\n",
      "Epoch [35/50], Iter [430/439] Loss: 4.0999, average_loss: 3.0051\n",
      "Epoch [35/50], Iter [435/439] Loss: 3.5248, average_loss: 2.9985\n",
      "Test epoch [35/50], average_loss: 3.0856\n",
      "Epoch [36/50], Iter [5/439] Loss: 3.8232, average_loss: 3.4653\n",
      "Epoch [36/50], Iter [10/439] Loss: 2.1754, average_loss: 2.9878\n",
      "Epoch [36/50], Iter [15/439] Loss: 1.9168, average_loss: 2.9521\n",
      "Epoch [36/50], Iter [20/439] Loss: 3.4685, average_loss: 2.9879\n",
      "Epoch [36/50], Iter [25/439] Loss: 2.7915, average_loss: 2.9565\n",
      "Epoch [36/50], Iter [30/439] Loss: 3.0734, average_loss: 2.9933\n",
      "Epoch [36/50], Iter [35/439] Loss: 6.5207, average_loss: 3.0851\n",
      "Epoch [36/50], Iter [40/439] Loss: 3.8221, average_loss: 3.0962\n",
      "Epoch [36/50], Iter [45/439] Loss: 2.2329, average_loss: 3.0186\n",
      "Epoch [36/50], Iter [50/439] Loss: 3.3316, average_loss: 2.9624\n",
      "Epoch [36/50], Iter [55/439] Loss: 2.8602, average_loss: 2.9649\n",
      "Epoch [36/50], Iter [60/439] Loss: 3.4897, average_loss: 2.9381\n",
      "Epoch [36/50], Iter [65/439] Loss: 3.2086, average_loss: 2.9356\n",
      "Epoch [36/50], Iter [70/439] Loss: 2.7710, average_loss: 2.9579\n",
      "Epoch [36/50], Iter [75/439] Loss: 3.3489, average_loss: 2.9559\n",
      "Epoch [36/50], Iter [80/439] Loss: 2.1546, average_loss: 2.9668\n",
      "Epoch [36/50], Iter [85/439] Loss: 4.1379, average_loss: 2.9634\n",
      "Epoch [36/50], Iter [90/439] Loss: 2.7527, average_loss: 2.9563\n",
      "Epoch [36/50], Iter [95/439] Loss: 2.6149, average_loss: 2.9340\n",
      "Epoch [36/50], Iter [100/439] Loss: 3.3113, average_loss: 2.9301\n",
      "Epoch [36/50], Iter [105/439] Loss: 2.2480, average_loss: 2.9185\n",
      "Epoch [36/50], Iter [110/439] Loss: 1.6527, average_loss: 2.8977\n",
      "Epoch [36/50], Iter [115/439] Loss: 2.6746, average_loss: 2.9176\n",
      "Epoch [36/50], Iter [120/439] Loss: 4.5117, average_loss: 2.9217\n",
      "Epoch [36/50], Iter [125/439] Loss: 4.1491, average_loss: 2.9406\n",
      "Epoch [36/50], Iter [130/439] Loss: 7.0253, average_loss: 2.9641\n",
      "Epoch [36/50], Iter [135/439] Loss: 5.0193, average_loss: 2.9803\n",
      "Epoch [36/50], Iter [140/439] Loss: 3.8673, average_loss: 3.0174\n",
      "Epoch [36/50], Iter [145/439] Loss: 2.3207, average_loss: 3.0256\n",
      "Epoch [36/50], Iter [150/439] Loss: 2.7024, average_loss: 3.0103\n",
      "Epoch [36/50], Iter [155/439] Loss: 3.1431, average_loss: 3.0068\n",
      "Epoch [36/50], Iter [160/439] Loss: 3.7339, average_loss: 3.0044\n",
      "Epoch [36/50], Iter [165/439] Loss: 1.9464, average_loss: 2.9948\n",
      "Epoch [36/50], Iter [170/439] Loss: 2.9824, average_loss: 2.9951\n",
      "Epoch [36/50], Iter [175/439] Loss: 2.5020, average_loss: 2.9951\n",
      "Epoch [36/50], Iter [180/439] Loss: 3.2009, average_loss: 2.9834\n",
      "Epoch [36/50], Iter [185/439] Loss: 2.0339, average_loss: 2.9734\n",
      "Epoch [36/50], Iter [190/439] Loss: 3.2830, average_loss: 2.9658\n",
      "Epoch [36/50], Iter [195/439] Loss: 1.4257, average_loss: 2.9585\n",
      "Epoch [36/50], Iter [200/439] Loss: 3.1312, average_loss: 2.9706\n",
      "Epoch [36/50], Iter [205/439] Loss: 2.8226, average_loss: 2.9761\n",
      "Epoch [36/50], Iter [210/439] Loss: 3.8033, average_loss: 2.9940\n",
      "Epoch [36/50], Iter [215/439] Loss: 3.1684, average_loss: 2.9937\n",
      "Epoch [36/50], Iter [220/439] Loss: 3.2157, average_loss: 2.9898\n",
      "Epoch [36/50], Iter [225/439] Loss: 3.3265, average_loss: 2.9877\n",
      "Epoch [36/50], Iter [230/439] Loss: 2.9063, average_loss: 2.9793\n",
      "Epoch [36/50], Iter [235/439] Loss: 3.3511, average_loss: 2.9788\n",
      "Epoch [36/50], Iter [240/439] Loss: 3.4945, average_loss: 2.9722\n",
      "Epoch [36/50], Iter [245/439] Loss: 3.4397, average_loss: 2.9713\n",
      "Epoch [36/50], Iter [250/439] Loss: 2.3628, average_loss: 2.9726\n",
      "Epoch [36/50], Iter [255/439] Loss: 3.5377, average_loss: 2.9739\n",
      "Epoch [36/50], Iter [260/439] Loss: 4.3132, average_loss: 2.9893\n",
      "Epoch [36/50], Iter [265/439] Loss: 2.8867, average_loss: 2.9856\n",
      "Epoch [36/50], Iter [270/439] Loss: 2.9936, average_loss: 2.9859\n",
      "Epoch [36/50], Iter [275/439] Loss: 3.0948, average_loss: 2.9917\n",
      "Epoch [36/50], Iter [280/439] Loss: 2.4362, average_loss: 2.9804\n",
      "Epoch [36/50], Iter [285/439] Loss: 3.3855, average_loss: 2.9849\n",
      "Epoch [36/50], Iter [290/439] Loss: 2.1468, average_loss: 2.9707\n",
      "Epoch [36/50], Iter [295/439] Loss: 2.8139, average_loss: 2.9618\n",
      "Epoch [36/50], Iter [300/439] Loss: 2.7848, average_loss: 2.9680\n",
      "Epoch [36/50], Iter [305/439] Loss: 2.3265, average_loss: 2.9613\n",
      "Epoch [36/50], Iter [310/439] Loss: 2.7432, average_loss: 2.9644\n",
      "Epoch [36/50], Iter [315/439] Loss: 3.4609, average_loss: 2.9672\n",
      "Epoch [36/50], Iter [320/439] Loss: 3.3598, average_loss: 2.9700\n",
      "Epoch [36/50], Iter [325/439] Loss: 3.1446, average_loss: 2.9771\n",
      "Epoch [36/50], Iter [330/439] Loss: 2.2751, average_loss: 2.9665\n",
      "Epoch [36/50], Iter [335/439] Loss: 2.4708, average_loss: 2.9590\n",
      "Epoch [36/50], Iter [340/439] Loss: 2.5844, average_loss: 2.9614\n",
      "Epoch [36/50], Iter [345/439] Loss: 2.5102, average_loss: 2.9555\n",
      "Epoch [36/50], Iter [350/439] Loss: 2.9867, average_loss: 2.9600\n",
      "Epoch [36/50], Iter [355/439] Loss: 5.1078, average_loss: 2.9595\n",
      "Epoch [36/50], Iter [360/439] Loss: 2.4197, average_loss: 2.9588\n",
      "Epoch [36/50], Iter [365/439] Loss: 2.7801, average_loss: 2.9731\n",
      "Epoch [36/50], Iter [370/439] Loss: 2.2353, average_loss: 2.9735\n",
      "Epoch [36/50], Iter [375/439] Loss: 2.0761, average_loss: 2.9700\n",
      "Epoch [36/50], Iter [380/439] Loss: 1.5415, average_loss: 2.9672\n",
      "Epoch [36/50], Iter [385/439] Loss: 4.2878, average_loss: 2.9757\n",
      "Epoch [36/50], Iter [390/439] Loss: 2.9003, average_loss: 2.9810\n",
      "Epoch [36/50], Iter [395/439] Loss: 3.4677, average_loss: 2.9871\n",
      "Epoch [36/50], Iter [400/439] Loss: 1.8250, average_loss: 2.9837\n",
      "Epoch [36/50], Iter [405/439] Loss: 2.5505, average_loss: 2.9803\n",
      "Epoch [36/50], Iter [410/439] Loss: 1.8450, average_loss: 2.9860\n",
      "Epoch [36/50], Iter [415/439] Loss: 3.1614, average_loss: 2.9848\n",
      "Epoch [36/50], Iter [420/439] Loss: 2.0993, average_loss: 2.9852\n",
      "Epoch [36/50], Iter [425/439] Loss: 2.5634, average_loss: 2.9813\n",
      "Epoch [36/50], Iter [430/439] Loss: 1.6723, average_loss: 2.9747\n",
      "Epoch [36/50], Iter [435/439] Loss: 1.9454, average_loss: 2.9716\n",
      "Test epoch [36/50], average_loss: 3.0606\n",
      "Epoch [37/50], Iter [5/439] Loss: 2.4876, average_loss: 2.4680\n",
      "Epoch [37/50], Iter [10/439] Loss: 3.5058, average_loss: 3.0200\n",
      "Epoch [37/50], Iter [15/439] Loss: 2.5279, average_loss: 2.9768\n",
      "Epoch [37/50], Iter [20/439] Loss: 2.1564, average_loss: 2.9332\n",
      "Epoch [37/50], Iter [25/439] Loss: 4.5303, average_loss: 3.1656\n",
      "Epoch [37/50], Iter [30/439] Loss: 2.9233, average_loss: 3.1065\n",
      "Epoch [37/50], Iter [35/439] Loss: 4.4158, average_loss: 3.1002\n",
      "Epoch [37/50], Iter [40/439] Loss: 2.4766, average_loss: 3.0442\n",
      "Epoch [37/50], Iter [45/439] Loss: 2.8416, average_loss: 2.9879\n",
      "Epoch [37/50], Iter [50/439] Loss: 3.2934, average_loss: 2.9796\n",
      "Epoch [37/50], Iter [55/439] Loss: 2.2710, average_loss: 2.9333\n",
      "Epoch [37/50], Iter [60/439] Loss: 2.6953, average_loss: 2.9007\n",
      "Epoch [37/50], Iter [65/439] Loss: 2.0089, average_loss: 2.8814\n",
      "Epoch [37/50], Iter [70/439] Loss: 5.3415, average_loss: 2.9064\n",
      "Epoch [37/50], Iter [75/439] Loss: 2.0781, average_loss: 2.9012\n",
      "Epoch [37/50], Iter [80/439] Loss: 3.2984, average_loss: 2.9036\n",
      "Epoch [37/50], Iter [85/439] Loss: 3.4988, average_loss: 2.9171\n",
      "Epoch [37/50], Iter [90/439] Loss: 2.9801, average_loss: 2.8828\n",
      "Epoch [37/50], Iter [95/439] Loss: 1.5851, average_loss: 2.8546\n",
      "Epoch [37/50], Iter [100/439] Loss: 4.2386, average_loss: 2.8831\n",
      "Epoch [37/50], Iter [105/439] Loss: 3.3073, average_loss: 2.8958\n",
      "Epoch [37/50], Iter [110/439] Loss: 3.5312, average_loss: 2.8825\n",
      "Epoch [37/50], Iter [115/439] Loss: 1.6266, average_loss: 2.8479\n",
      "Epoch [37/50], Iter [120/439] Loss: 2.7025, average_loss: 2.8548\n",
      "Epoch [37/50], Iter [125/439] Loss: 2.9870, average_loss: 2.8452\n",
      "Epoch [37/50], Iter [130/439] Loss: 3.3658, average_loss: 2.8429\n",
      "Epoch [37/50], Iter [135/439] Loss: 2.4047, average_loss: 2.8252\n",
      "Epoch [37/50], Iter [140/439] Loss: 3.1824, average_loss: 2.8325\n",
      "Epoch [37/50], Iter [145/439] Loss: 2.1288, average_loss: 2.8259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Iter [150/439] Loss: 2.0818, average_loss: 2.8126\n",
      "Epoch [37/50], Iter [155/439] Loss: 2.3907, average_loss: 2.7948\n",
      "Epoch [37/50], Iter [160/439] Loss: 1.9433, average_loss: 2.8216\n",
      "Epoch [37/50], Iter [165/439] Loss: 4.1155, average_loss: 2.8332\n",
      "Epoch [37/50], Iter [170/439] Loss: 3.2485, average_loss: 2.8268\n",
      "Epoch [37/50], Iter [175/439] Loss: 4.7784, average_loss: 2.8405\n",
      "Epoch [37/50], Iter [180/439] Loss: 1.1251, average_loss: 2.8268\n",
      "Epoch [37/50], Iter [185/439] Loss: 2.8275, average_loss: 2.8352\n",
      "Epoch [37/50], Iter [190/439] Loss: 3.7829, average_loss: 2.8423\n",
      "Epoch [37/50], Iter [195/439] Loss: 2.6024, average_loss: 2.8330\n",
      "Epoch [37/50], Iter [200/439] Loss: 2.4149, average_loss: 2.8430\n",
      "Epoch [37/50], Iter [205/439] Loss: 2.3533, average_loss: 2.8339\n",
      "Epoch [37/50], Iter [210/439] Loss: 3.7975, average_loss: 2.8581\n",
      "Epoch [37/50], Iter [215/439] Loss: 3.2245, average_loss: 2.8615\n",
      "Epoch [37/50], Iter [220/439] Loss: 3.1951, average_loss: 2.8651\n",
      "Epoch [37/50], Iter [225/439] Loss: 3.0185, average_loss: 2.8851\n",
      "Epoch [37/50], Iter [230/439] Loss: 3.5012, average_loss: 2.8993\n",
      "Epoch [37/50], Iter [235/439] Loss: 2.8747, average_loss: 2.9187\n",
      "Epoch [37/50], Iter [240/439] Loss: 4.2202, average_loss: 2.9296\n",
      "Epoch [37/50], Iter [245/439] Loss: 2.2495, average_loss: 2.9243\n",
      "Epoch [37/50], Iter [250/439] Loss: 3.5212, average_loss: 2.9315\n",
      "Epoch [37/50], Iter [255/439] Loss: 3.1668, average_loss: 2.9389\n",
      "Epoch [37/50], Iter [260/439] Loss: 2.5968, average_loss: 2.9374\n",
      "Epoch [37/50], Iter [265/439] Loss: 1.7946, average_loss: 2.9345\n",
      "Epoch [37/50], Iter [270/439] Loss: 3.2422, average_loss: 2.9359\n",
      "Epoch [37/50], Iter [275/439] Loss: 3.1838, average_loss: 2.9401\n",
      "Epoch [37/50], Iter [280/439] Loss: 3.1490, average_loss: 2.9481\n",
      "Epoch [37/50], Iter [285/439] Loss: 2.4191, average_loss: 2.9442\n",
      "Epoch [37/50], Iter [290/439] Loss: 2.4297, average_loss: 2.9383\n",
      "Epoch [37/50], Iter [295/439] Loss: 2.3191, average_loss: 2.9401\n",
      "Epoch [37/50], Iter [300/439] Loss: 3.2171, average_loss: 2.9397\n",
      "Epoch [37/50], Iter [305/439] Loss: 2.5937, average_loss: 2.9354\n",
      "Epoch [37/50], Iter [310/439] Loss: 1.8690, average_loss: 2.9339\n",
      "Epoch [37/50], Iter [315/439] Loss: 4.3492, average_loss: 2.9352\n",
      "Epoch [37/50], Iter [320/439] Loss: 4.5894, average_loss: 2.9413\n",
      "Epoch [37/50], Iter [325/439] Loss: 1.7916, average_loss: 2.9360\n",
      "Epoch [37/50], Iter [330/439] Loss: 1.8709, average_loss: 2.9323\n",
      "Epoch [37/50], Iter [335/439] Loss: 3.9445, average_loss: 2.9397\n",
      "Epoch [37/50], Iter [340/439] Loss: 2.6572, average_loss: 2.9302\n",
      "Epoch [37/50], Iter [345/439] Loss: 4.4925, average_loss: 2.9305\n",
      "Epoch [37/50], Iter [350/439] Loss: 2.3525, average_loss: 2.9292\n",
      "Epoch [37/50], Iter [355/439] Loss: 2.8753, average_loss: 2.9253\n",
      "Epoch [37/50], Iter [360/439] Loss: 3.4826, average_loss: 2.9236\n",
      "Epoch [37/50], Iter [365/439] Loss: 2.9096, average_loss: 2.9309\n",
      "Epoch [37/50], Iter [370/439] Loss: 3.9842, average_loss: 2.9282\n",
      "Epoch [37/50], Iter [375/439] Loss: 3.2378, average_loss: 2.9295\n",
      "Epoch [37/50], Iter [380/439] Loss: 2.3222, average_loss: 2.9292\n",
      "Epoch [37/50], Iter [385/439] Loss: 2.1618, average_loss: 2.9230\n",
      "Epoch [37/50], Iter [390/439] Loss: 3.9625, average_loss: 2.9201\n",
      "Epoch [37/50], Iter [395/439] Loss: 1.9317, average_loss: 2.9187\n",
      "Epoch [37/50], Iter [400/439] Loss: 4.0808, average_loss: 2.9212\n",
      "Epoch [37/50], Iter [405/439] Loss: 3.9624, average_loss: 2.9287\n",
      "Epoch [37/50], Iter [410/439] Loss: 2.4769, average_loss: 2.9308\n",
      "Epoch [37/50], Iter [415/439] Loss: 2.4453, average_loss: 2.9287\n",
      "Epoch [37/50], Iter [420/439] Loss: 3.5597, average_loss: 2.9303\n",
      "Epoch [37/50], Iter [425/439] Loss: 5.6268, average_loss: 2.9344\n",
      "Epoch [37/50], Iter [430/439] Loss: 1.9203, average_loss: 2.9298\n",
      "Epoch [37/50], Iter [435/439] Loss: 2.8173, average_loss: 2.9335\n",
      "Test epoch [37/50], average_loss: 3.0450\n",
      "Epoch [38/50], Iter [5/439] Loss: 3.7420, average_loss: 2.6556\n",
      "Epoch [38/50], Iter [10/439] Loss: 2.5152, average_loss: 3.0477\n",
      "Epoch [38/50], Iter [15/439] Loss: 2.9483, average_loss: 3.2011\n",
      "Epoch [38/50], Iter [20/439] Loss: 3.2821, average_loss: 3.0826\n",
      "Epoch [38/50], Iter [25/439] Loss: 2.9209, average_loss: 3.1536\n",
      "Epoch [38/50], Iter [30/439] Loss: 2.4509, average_loss: 3.0293\n",
      "Epoch [38/50], Iter [35/439] Loss: 3.5816, average_loss: 2.9907\n",
      "Epoch [38/50], Iter [40/439] Loss: 1.9540, average_loss: 2.9009\n",
      "Epoch [38/50], Iter [45/439] Loss: 3.5347, average_loss: 2.9095\n",
      "Epoch [38/50], Iter [50/439] Loss: 2.0317, average_loss: 2.9054\n",
      "Epoch [38/50], Iter [55/439] Loss: 3.2320, average_loss: 2.9027\n",
      "Epoch [38/50], Iter [60/439] Loss: 4.1577, average_loss: 2.9302\n",
      "Epoch [38/50], Iter [65/439] Loss: 2.0121, average_loss: 2.8529\n",
      "Epoch [38/50], Iter [70/439] Loss: 2.5810, average_loss: 2.8846\n",
      "Epoch [38/50], Iter [75/439] Loss: 1.8102, average_loss: 2.8486\n",
      "Epoch [38/50], Iter [80/439] Loss: 1.6935, average_loss: 2.8800\n",
      "Epoch [38/50], Iter [85/439] Loss: 2.3192, average_loss: 2.8967\n",
      "Epoch [38/50], Iter [90/439] Loss: 1.2210, average_loss: 2.8667\n",
      "Epoch [38/50], Iter [95/439] Loss: 2.9680, average_loss: 2.8656\n",
      "Epoch [38/50], Iter [100/439] Loss: 3.7914, average_loss: 2.8440\n",
      "Epoch [38/50], Iter [105/439] Loss: 3.2577, average_loss: 2.8431\n",
      "Epoch [38/50], Iter [110/439] Loss: 5.3873, average_loss: 2.8515\n",
      "Epoch [38/50], Iter [115/439] Loss: 2.8740, average_loss: 2.8543\n",
      "Epoch [38/50], Iter [120/439] Loss: 1.8442, average_loss: 2.8502\n",
      "Epoch [38/50], Iter [125/439] Loss: 3.9068, average_loss: 2.8924\n",
      "Epoch [38/50], Iter [130/439] Loss: 3.5565, average_loss: 2.9220\n",
      "Epoch [38/50], Iter [135/439] Loss: 3.8087, average_loss: 2.9069\n",
      "Epoch [38/50], Iter [140/439] Loss: 4.5548, average_loss: 2.9110\n",
      "Epoch [38/50], Iter [145/439] Loss: 2.2383, average_loss: 2.9037\n",
      "Epoch [38/50], Iter [150/439] Loss: 3.3042, average_loss: 2.9079\n",
      "Epoch [38/50], Iter [155/439] Loss: 3.6386, average_loss: 2.9174\n",
      "Epoch [38/50], Iter [160/439] Loss: 3.3444, average_loss: 2.9405\n",
      "Epoch [38/50], Iter [165/439] Loss: 3.8390, average_loss: 2.9454\n",
      "Epoch [38/50], Iter [170/439] Loss: 2.3629, average_loss: 2.9472\n",
      "Epoch [38/50], Iter [175/439] Loss: 2.1727, average_loss: 2.9245\n",
      "Epoch [38/50], Iter [180/439] Loss: 2.0370, average_loss: 2.9275\n",
      "Epoch [38/50], Iter [185/439] Loss: 1.7459, average_loss: 2.9323\n",
      "Epoch [38/50], Iter [190/439] Loss: 2.3940, average_loss: 2.9353\n",
      "Epoch [38/50], Iter [195/439] Loss: 4.0603, average_loss: 2.9562\n",
      "Epoch [38/50], Iter [200/439] Loss: 4.7128, average_loss: 2.9581\n",
      "Epoch [38/50], Iter [205/439] Loss: 2.1771, average_loss: 2.9530\n",
      "Epoch [38/50], Iter [210/439] Loss: 1.8446, average_loss: 2.9422\n",
      "Epoch [38/50], Iter [215/439] Loss: 4.9484, average_loss: 2.9472\n",
      "Epoch [38/50], Iter [220/439] Loss: 4.8424, average_loss: 2.9530\n",
      "Epoch [38/50], Iter [225/439] Loss: 1.8288, average_loss: 2.9414\n",
      "Epoch [38/50], Iter [230/439] Loss: 2.0705, average_loss: 2.9530\n",
      "Epoch [38/50], Iter [235/439] Loss: 2.6309, average_loss: 2.9687\n",
      "Epoch [38/50], Iter [240/439] Loss: 3.1180, average_loss: 2.9549\n",
      "Epoch [38/50], Iter [245/439] Loss: 3.3253, average_loss: 2.9490\n",
      "Epoch [38/50], Iter [250/439] Loss: 5.0326, average_loss: 2.9537\n",
      "Epoch [38/50], Iter [255/439] Loss: 2.9156, average_loss: 2.9513\n",
      "Epoch [38/50], Iter [260/439] Loss: 2.4340, average_loss: 2.9567\n",
      "Epoch [38/50], Iter [265/439] Loss: 2.5674, average_loss: 2.9548\n",
      "Epoch [38/50], Iter [270/439] Loss: 2.8827, average_loss: 2.9568\n",
      "Epoch [38/50], Iter [275/439] Loss: 2.4796, average_loss: 2.9518\n",
      "Epoch [38/50], Iter [280/439] Loss: 1.9880, average_loss: 2.9377\n",
      "Epoch [38/50], Iter [285/439] Loss: 3.0299, average_loss: 2.9405\n",
      "Epoch [38/50], Iter [290/439] Loss: 3.0664, average_loss: 2.9403\n",
      "Epoch [38/50], Iter [295/439] Loss: 2.6796, average_loss: 2.9454\n",
      "Epoch [38/50], Iter [300/439] Loss: 2.4121, average_loss: 2.9390\n",
      "Epoch [38/50], Iter [305/439] Loss: 2.7336, average_loss: 2.9342\n",
      "Epoch [38/50], Iter [310/439] Loss: 3.5153, average_loss: 2.9290\n",
      "Epoch [38/50], Iter [315/439] Loss: 3.2289, average_loss: 2.9266\n",
      "Epoch [38/50], Iter [320/439] Loss: 2.4808, average_loss: 2.9275\n",
      "Epoch [38/50], Iter [325/439] Loss: 5.7528, average_loss: 2.9280\n",
      "Epoch [38/50], Iter [330/439] Loss: 1.9890, average_loss: 2.9215\n",
      "Epoch [38/50], Iter [335/439] Loss: 2.3698, average_loss: 2.9164\n",
      "Epoch [38/50], Iter [340/439] Loss: 3.8641, average_loss: 2.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Iter [345/439] Loss: 2.4862, average_loss: 2.9157\n",
      "Epoch [38/50], Iter [350/439] Loss: 3.4161, average_loss: 2.9118\n",
      "Epoch [38/50], Iter [355/439] Loss: 2.3719, average_loss: 2.9252\n",
      "Epoch [38/50], Iter [360/439] Loss: 3.4686, average_loss: 2.9264\n",
      "Epoch [38/50], Iter [365/439] Loss: 1.6170, average_loss: 2.9230\n",
      "Epoch [38/50], Iter [370/439] Loss: 3.6557, average_loss: 2.9229\n",
      "Epoch [38/50], Iter [375/439] Loss: 3.2682, average_loss: 2.9236\n",
      "Epoch [38/50], Iter [380/439] Loss: 2.7761, average_loss: 2.9190\n",
      "Epoch [38/50], Iter [385/439] Loss: 3.1184, average_loss: 2.9206\n",
      "Epoch [38/50], Iter [390/439] Loss: 2.2047, average_loss: 2.9139\n",
      "Epoch [38/50], Iter [395/439] Loss: 2.8310, average_loss: 2.9116\n",
      "Epoch [38/50], Iter [400/439] Loss: 3.6897, average_loss: 2.9083\n",
      "Epoch [38/50], Iter [405/439] Loss: 1.7863, average_loss: 2.9022\n",
      "Epoch [38/50], Iter [410/439] Loss: 3.3416, average_loss: 2.9087\n",
      "Epoch [38/50], Iter [415/439] Loss: 2.5489, average_loss: 2.9108\n",
      "Epoch [38/50], Iter [420/439] Loss: 3.8631, average_loss: 2.9119\n",
      "Epoch [38/50], Iter [425/439] Loss: 4.2549, average_loss: 2.9115\n",
      "Epoch [38/50], Iter [430/439] Loss: 2.2158, average_loss: 2.9175\n",
      "Epoch [38/50], Iter [435/439] Loss: 3.5950, average_loss: 2.9151\n",
      "Test epoch [38/50], average_loss: 3.0481\n",
      "Epoch [39/50], Iter [5/439] Loss: 2.6708, average_loss: 2.6076\n",
      "Epoch [39/50], Iter [10/439] Loss: 1.9209, average_loss: 2.5103\n",
      "Epoch [39/50], Iter [15/439] Loss: 3.6118, average_loss: 2.8065\n",
      "Epoch [39/50], Iter [20/439] Loss: 3.2450, average_loss: 2.9664\n",
      "Epoch [39/50], Iter [25/439] Loss: 4.1751, average_loss: 2.9369\n",
      "Epoch [39/50], Iter [30/439] Loss: 3.6143, average_loss: 2.9493\n",
      "Epoch [39/50], Iter [35/439] Loss: 3.6104, average_loss: 3.1121\n",
      "Epoch [39/50], Iter [40/439] Loss: 2.5811, average_loss: 3.0516\n",
      "Epoch [39/50], Iter [45/439] Loss: 4.4300, average_loss: 3.0116\n",
      "Epoch [39/50], Iter [50/439] Loss: 3.0047, average_loss: 3.0296\n",
      "Epoch [39/50], Iter [55/439] Loss: 2.2257, average_loss: 3.1009\n",
      "Epoch [39/50], Iter [60/439] Loss: 1.4815, average_loss: 3.0262\n",
      "Epoch [39/50], Iter [65/439] Loss: 2.8487, average_loss: 3.0048\n",
      "Epoch [39/50], Iter [70/439] Loss: 2.1452, average_loss: 2.9700\n",
      "Epoch [39/50], Iter [75/439] Loss: 3.6139, average_loss: 2.9675\n",
      "Epoch [39/50], Iter [80/439] Loss: 2.2494, average_loss: 2.9008\n",
      "Epoch [39/50], Iter [85/439] Loss: 2.2732, average_loss: 2.8926\n",
      "Epoch [39/50], Iter [90/439] Loss: 2.7484, average_loss: 2.9092\n",
      "Epoch [39/50], Iter [95/439] Loss: 2.8534, average_loss: 2.9078\n",
      "Epoch [39/50], Iter [100/439] Loss: 1.9707, average_loss: 2.9019\n",
      "Epoch [39/50], Iter [105/439] Loss: 2.4563, average_loss: 2.9077\n",
      "Epoch [39/50], Iter [110/439] Loss: 3.4032, average_loss: 2.9207\n",
      "Epoch [39/50], Iter [115/439] Loss: 5.1296, average_loss: 2.9129\n",
      "Epoch [39/50], Iter [120/439] Loss: 2.8107, average_loss: 2.9718\n",
      "Epoch [39/50], Iter [125/439] Loss: 2.8206, average_loss: 2.9444\n",
      "Epoch [39/50], Iter [130/439] Loss: 3.5571, average_loss: 2.9627\n",
      "Epoch [39/50], Iter [135/439] Loss: 2.0130, average_loss: 2.9462\n",
      "Epoch [39/50], Iter [140/439] Loss: 2.1039, average_loss: 2.9303\n",
      "Epoch [39/50], Iter [145/439] Loss: 3.6902, average_loss: 2.9406\n",
      "Epoch [39/50], Iter [150/439] Loss: 3.1988, average_loss: 2.9263\n",
      "Epoch [39/50], Iter [155/439] Loss: 2.9338, average_loss: 2.9331\n",
      "Epoch [39/50], Iter [160/439] Loss: 3.2743, average_loss: 2.9349\n",
      "Epoch [39/50], Iter [165/439] Loss: 3.5081, average_loss: 2.9376\n",
      "Epoch [39/50], Iter [170/439] Loss: 3.4284, average_loss: 2.9342\n",
      "Epoch [39/50], Iter [175/439] Loss: 2.1486, average_loss: 2.9634\n",
      "Epoch [39/50], Iter [180/439] Loss: 2.4924, average_loss: 2.9588\n",
      "Epoch [39/50], Iter [185/439] Loss: 2.9887, average_loss: 2.9572\n",
      "Epoch [39/50], Iter [190/439] Loss: 3.5993, average_loss: 2.9459\n",
      "Epoch [39/50], Iter [195/439] Loss: 2.3054, average_loss: 2.9246\n",
      "Epoch [39/50], Iter [200/439] Loss: 2.7605, average_loss: 2.9122\n",
      "Epoch [39/50], Iter [205/439] Loss: 1.6965, average_loss: 2.8896\n",
      "Epoch [39/50], Iter [210/439] Loss: 2.7160, average_loss: 2.8919\n",
      "Epoch [39/50], Iter [215/439] Loss: 4.7437, average_loss: 2.9019\n",
      "Epoch [39/50], Iter [220/439] Loss: 3.6405, average_loss: 2.9155\n",
      "Epoch [39/50], Iter [225/439] Loss: 2.9861, average_loss: 2.9306\n",
      "Epoch [39/50], Iter [230/439] Loss: 3.4593, average_loss: 2.9326\n",
      "Epoch [39/50], Iter [235/439] Loss: 1.8296, average_loss: 2.9431\n",
      "Epoch [39/50], Iter [240/439] Loss: 2.6358, average_loss: 2.9437\n",
      "Epoch [39/50], Iter [245/439] Loss: 2.3148, average_loss: 2.9349\n",
      "Epoch [39/50], Iter [250/439] Loss: 4.2305, average_loss: 2.9318\n",
      "Epoch [39/50], Iter [255/439] Loss: 4.2845, average_loss: 2.9287\n",
      "Epoch [39/50], Iter [260/439] Loss: 3.1756, average_loss: 2.9295\n",
      "Epoch [39/50], Iter [265/439] Loss: 2.2417, average_loss: 2.9236\n",
      "Epoch [39/50], Iter [270/439] Loss: 2.0555, average_loss: 2.9306\n",
      "Epoch [39/50], Iter [275/439] Loss: 1.6389, average_loss: 2.9197\n",
      "Epoch [39/50], Iter [280/439] Loss: 1.8792, average_loss: 2.9335\n",
      "Epoch [39/50], Iter [285/439] Loss: 3.0980, average_loss: 2.9314\n",
      "Epoch [39/50], Iter [290/439] Loss: 2.8425, average_loss: 2.9305\n",
      "Epoch [39/50], Iter [295/439] Loss: 3.0324, average_loss: 2.9359\n",
      "Epoch [39/50], Iter [300/439] Loss: 3.9787, average_loss: 2.9412\n",
      "Epoch [39/50], Iter [305/439] Loss: 3.2805, average_loss: 2.9350\n",
      "Epoch [39/50], Iter [310/439] Loss: 2.2433, average_loss: 2.9323\n",
      "Epoch [39/50], Iter [315/439] Loss: 3.5942, average_loss: 2.9241\n",
      "Epoch [39/50], Iter [320/439] Loss: 3.7666, average_loss: 2.9161\n",
      "Epoch [39/50], Iter [325/439] Loss: 1.6940, average_loss: 2.9202\n",
      "Epoch [39/50], Iter [330/439] Loss: 2.9386, average_loss: 2.9208\n",
      "Epoch [39/50], Iter [335/439] Loss: 3.2273, average_loss: 2.9139\n",
      "Epoch [39/50], Iter [340/439] Loss: 3.6796, average_loss: 2.9128\n",
      "Epoch [39/50], Iter [345/439] Loss: 2.7087, average_loss: 2.9023\n",
      "Epoch [39/50], Iter [350/439] Loss: 2.8649, average_loss: 2.8989\n",
      "Epoch [39/50], Iter [355/439] Loss: 3.7293, average_loss: 2.9030\n",
      "Epoch [39/50], Iter [360/439] Loss: 2.0089, average_loss: 2.8970\n",
      "Epoch [39/50], Iter [365/439] Loss: 2.8450, average_loss: 2.8984\n",
      "Epoch [39/50], Iter [370/439] Loss: 2.2666, average_loss: 2.8981\n",
      "Epoch [39/50], Iter [375/439] Loss: 2.6842, average_loss: 2.8946\n",
      "Epoch [39/50], Iter [380/439] Loss: 2.5212, average_loss: 2.8903\n",
      "Epoch [39/50], Iter [385/439] Loss: 3.5350, average_loss: 2.8881\n",
      "Epoch [39/50], Iter [390/439] Loss: 2.9017, average_loss: 2.8866\n",
      "Epoch [39/50], Iter [395/439] Loss: 2.5725, average_loss: 2.8878\n",
      "Epoch [39/50], Iter [400/439] Loss: 2.8492, average_loss: 2.8973\n",
      "Epoch [39/50], Iter [405/439] Loss: 3.6743, average_loss: 2.8964\n",
      "Epoch [39/50], Iter [410/439] Loss: 3.5916, average_loss: 2.8961\n",
      "Epoch [39/50], Iter [415/439] Loss: 3.4708, average_loss: 2.9004\n",
      "Epoch [39/50], Iter [420/439] Loss: 3.0925, average_loss: 2.9002\n",
      "Epoch [39/50], Iter [425/439] Loss: 5.6412, average_loss: 2.9057\n",
      "Epoch [39/50], Iter [430/439] Loss: 3.7590, average_loss: 2.9093\n",
      "Epoch [39/50], Iter [435/439] Loss: 1.9610, average_loss: 2.9020\n",
      "Test epoch [39/50], average_loss: 3.0400\n",
      "Epoch [40/50], Iter [5/439] Loss: 2.7036, average_loss: 2.6432\n",
      "Epoch [40/50], Iter [10/439] Loss: 4.0449, average_loss: 3.1823\n",
      "Epoch [40/50], Iter [15/439] Loss: 1.8904, average_loss: 3.1309\n",
      "Epoch [40/50], Iter [20/439] Loss: 3.0162, average_loss: 3.0453\n",
      "Epoch [40/50], Iter [25/439] Loss: 1.7858, average_loss: 3.0303\n",
      "Epoch [40/50], Iter [30/439] Loss: 3.0564, average_loss: 3.0481\n",
      "Epoch [40/50], Iter [35/439] Loss: 3.1767, average_loss: 3.0588\n",
      "Epoch [40/50], Iter [40/439] Loss: 2.3344, average_loss: 3.0425\n",
      "Epoch [40/50], Iter [45/439] Loss: 2.5474, average_loss: 2.9477\n",
      "Epoch [40/50], Iter [50/439] Loss: 2.6651, average_loss: 2.9152\n",
      "Epoch [40/50], Iter [55/439] Loss: 2.2515, average_loss: 2.9094\n",
      "Epoch [40/50], Iter [60/439] Loss: 2.2139, average_loss: 2.8303\n",
      "Epoch [40/50], Iter [65/439] Loss: 1.5206, average_loss: 2.8245\n",
      "Epoch [40/50], Iter [70/439] Loss: 1.7819, average_loss: 2.8369\n",
      "Epoch [40/50], Iter [75/439] Loss: 3.0888, average_loss: 2.8410\n",
      "Epoch [40/50], Iter [80/439] Loss: 1.9899, average_loss: 2.8166\n",
      "Epoch [40/50], Iter [85/439] Loss: 3.0986, average_loss: 2.8152\n",
      "Epoch [40/50], Iter [90/439] Loss: 3.3236, average_loss: 2.8482\n",
      "Epoch [40/50], Iter [95/439] Loss: 3.2334, average_loss: 2.8524\n",
      "Epoch [40/50], Iter [100/439] Loss: 5.2670, average_loss: 2.8713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Iter [105/439] Loss: 1.8114, average_loss: 2.8473\n",
      "Epoch [40/50], Iter [110/439] Loss: 1.8841, average_loss: 2.8544\n",
      "Epoch [40/50], Iter [115/439] Loss: 3.2332, average_loss: 2.8534\n",
      "Epoch [40/50], Iter [120/439] Loss: 2.7185, average_loss: 2.8605\n",
      "Epoch [40/50], Iter [125/439] Loss: 2.9524, average_loss: 2.8436\n",
      "Epoch [40/50], Iter [130/439] Loss: 1.6950, average_loss: 2.8166\n",
      "Epoch [40/50], Iter [135/439] Loss: 1.3520, average_loss: 2.8004\n",
      "Epoch [40/50], Iter [140/439] Loss: 3.8118, average_loss: 2.8322\n",
      "Epoch [40/50], Iter [145/439] Loss: 3.1355, average_loss: 2.8335\n",
      "Epoch [40/50], Iter [150/439] Loss: 3.1346, average_loss: 2.8305\n",
      "Epoch [40/50], Iter [155/439] Loss: 2.8003, average_loss: 2.8071\n",
      "Epoch [40/50], Iter [160/439] Loss: 1.6006, average_loss: 2.8159\n",
      "Epoch [40/50], Iter [165/439] Loss: 2.7265, average_loss: 2.8028\n",
      "Epoch [40/50], Iter [170/439] Loss: 2.6694, average_loss: 2.8079\n",
      "Epoch [40/50], Iter [175/439] Loss: 1.9366, average_loss: 2.8094\n",
      "Epoch [40/50], Iter [180/439] Loss: 3.5653, average_loss: 2.8112\n",
      "Epoch [40/50], Iter [185/439] Loss: 3.1662, average_loss: 2.8183\n",
      "Epoch [40/50], Iter [190/439] Loss: 2.3826, average_loss: 2.8109\n",
      "Epoch [40/50], Iter [195/439] Loss: 2.7951, average_loss: 2.8096\n",
      "Epoch [40/50], Iter [200/439] Loss: 3.0536, average_loss: 2.7967\n",
      "Epoch [40/50], Iter [205/439] Loss: 3.1893, average_loss: 2.7927\n",
      "Epoch [40/50], Iter [210/439] Loss: 3.3392, average_loss: 2.7980\n",
      "Epoch [40/50], Iter [215/439] Loss: 2.0754, average_loss: 2.7972\n",
      "Epoch [40/50], Iter [220/439] Loss: 3.0977, average_loss: 2.8195\n",
      "Epoch [40/50], Iter [225/439] Loss: 3.2580, average_loss: 2.8222\n",
      "Epoch [40/50], Iter [230/439] Loss: 5.4319, average_loss: 2.8621\n",
      "Epoch [40/50], Iter [235/439] Loss: 4.3505, average_loss: 2.8793\n",
      "Epoch [40/50], Iter [240/439] Loss: 2.2264, average_loss: 2.8911\n",
      "Epoch [40/50], Iter [245/439] Loss: 4.5310, average_loss: 2.8981\n",
      "Epoch [40/50], Iter [250/439] Loss: 2.3686, average_loss: 2.8900\n",
      "Epoch [40/50], Iter [255/439] Loss: 5.3000, average_loss: 2.9009\n",
      "Epoch [40/50], Iter [260/439] Loss: 1.7467, average_loss: 2.8982\n",
      "Epoch [40/50], Iter [265/439] Loss: 2.7953, average_loss: 2.9003\n",
      "Epoch [40/50], Iter [270/439] Loss: 2.2279, average_loss: 2.9028\n",
      "Epoch [40/50], Iter [275/439] Loss: 3.4749, average_loss: 2.9212\n",
      "Epoch [40/50], Iter [280/439] Loss: 3.6862, average_loss: 2.9214\n",
      "Epoch [40/50], Iter [285/439] Loss: 3.2181, average_loss: 2.9180\n",
      "Epoch [40/50], Iter [290/439] Loss: 2.3905, average_loss: 2.9121\n",
      "Epoch [40/50], Iter [295/439] Loss: 2.9035, average_loss: 2.9134\n",
      "Epoch [40/50], Iter [300/439] Loss: 3.4678, average_loss: 2.9083\n",
      "Epoch [40/50], Iter [305/439] Loss: 2.0990, average_loss: 2.9087\n",
      "Epoch [40/50], Iter [310/439] Loss: 2.6447, average_loss: 2.9048\n",
      "Epoch [40/50], Iter [315/439] Loss: 2.2506, average_loss: 2.9015\n",
      "Epoch [40/50], Iter [320/439] Loss: 2.0784, average_loss: 2.8988\n",
      "Epoch [40/50], Iter [325/439] Loss: 4.4222, average_loss: 2.9153\n",
      "Epoch [40/50], Iter [330/439] Loss: 1.8543, average_loss: 2.9111\n",
      "Epoch [40/50], Iter [335/439] Loss: 4.6384, average_loss: 2.9152\n",
      "Epoch [40/50], Iter [340/439] Loss: 2.4338, average_loss: 2.9105\n",
      "Epoch [40/50], Iter [345/439] Loss: 3.2408, average_loss: 2.9126\n",
      "Epoch [40/50], Iter [350/439] Loss: 3.4903, average_loss: 2.9193\n",
      "Epoch [40/50], Iter [355/439] Loss: 5.5288, average_loss: 2.9239\n",
      "Epoch [40/50], Iter [360/439] Loss: 2.0869, average_loss: 2.9312\n",
      "Epoch [40/50], Iter [365/439] Loss: 3.6746, average_loss: 2.9311\n",
      "Epoch [40/50], Iter [370/439] Loss: 2.1561, average_loss: 2.9285\n",
      "Epoch [40/50], Iter [375/439] Loss: 3.5192, average_loss: 2.9321\n",
      "Epoch [40/50], Iter [380/439] Loss: 1.0552, average_loss: 2.9210\n",
      "Epoch [40/50], Iter [385/439] Loss: 3.6963, average_loss: 2.9171\n",
      "Epoch [40/50], Iter [390/439] Loss: 1.8036, average_loss: 2.9116\n",
      "Epoch [40/50], Iter [395/439] Loss: 1.7715, average_loss: 2.9042\n",
      "Epoch [40/50], Iter [400/439] Loss: 3.7907, average_loss: 2.8992\n",
      "Epoch [40/50], Iter [405/439] Loss: 4.1081, average_loss: 2.8959\n",
      "Epoch [40/50], Iter [410/439] Loss: 2.4657, average_loss: 2.8973\n",
      "Epoch [40/50], Iter [415/439] Loss: 2.2845, average_loss: 2.8962\n",
      "Epoch [40/50], Iter [420/439] Loss: 2.6527, average_loss: 2.8936\n",
      "Epoch [40/50], Iter [425/439] Loss: 2.3016, average_loss: 2.8893\n",
      "Epoch [40/50], Iter [430/439] Loss: 2.2762, average_loss: 2.8876\n",
      "Epoch [40/50], Iter [435/439] Loss: 1.8301, average_loss: 2.8807\n",
      "Test epoch [40/50], average_loss: 3.0146\n",
      "Epoch [41/50], Iter [5/439] Loss: 3.2392, average_loss: 3.0568\n",
      "Epoch [41/50], Iter [10/439] Loss: 1.5928, average_loss: 2.6669\n",
      "Epoch [41/50], Iter [15/439] Loss: 3.2686, average_loss: 2.8149\n",
      "Epoch [41/50], Iter [20/439] Loss: 1.8217, average_loss: 2.6286\n",
      "Epoch [41/50], Iter [25/439] Loss: 3.7458, average_loss: 2.6290\n",
      "Epoch [41/50], Iter [30/439] Loss: 4.4581, average_loss: 2.6704\n",
      "Epoch [41/50], Iter [35/439] Loss: 2.2401, average_loss: 2.7222\n",
      "Epoch [41/50], Iter [40/439] Loss: 3.8680, average_loss: 2.7421\n",
      "Epoch [41/50], Iter [45/439] Loss: 3.7251, average_loss: 2.8301\n",
      "Epoch [41/50], Iter [50/439] Loss: 4.8133, average_loss: 2.8094\n",
      "Epoch [41/50], Iter [55/439] Loss: 2.9587, average_loss: 2.7851\n",
      "Epoch [41/50], Iter [60/439] Loss: 2.0921, average_loss: 2.8401\n",
      "Epoch [41/50], Iter [65/439] Loss: 3.2425, average_loss: 2.8366\n",
      "Epoch [41/50], Iter [70/439] Loss: 3.4139, average_loss: 2.8205\n",
      "Epoch [41/50], Iter [75/439] Loss: 3.1021, average_loss: 2.8080\n",
      "Epoch [41/50], Iter [80/439] Loss: 1.5182, average_loss: 2.8097\n",
      "Epoch [41/50], Iter [85/439] Loss: 2.5261, average_loss: 2.7998\n",
      "Epoch [41/50], Iter [90/439] Loss: 2.2047, average_loss: 2.8098\n",
      "Epoch [41/50], Iter [95/439] Loss: 2.1566, average_loss: 2.8121\n",
      "Epoch [41/50], Iter [100/439] Loss: 2.9993, average_loss: 2.8036\n",
      "Epoch [41/50], Iter [105/439] Loss: 2.6931, average_loss: 2.8043\n",
      "Epoch [41/50], Iter [110/439] Loss: 2.9347, average_loss: 2.8034\n",
      "Epoch [41/50], Iter [115/439] Loss: 2.9883, average_loss: 2.8073\n",
      "Epoch [41/50], Iter [120/439] Loss: 3.1185, average_loss: 2.8133\n",
      "Epoch [41/50], Iter [125/439] Loss: 1.8527, average_loss: 2.8224\n",
      "Epoch [41/50], Iter [130/439] Loss: 3.9785, average_loss: 2.8360\n",
      "Epoch [41/50], Iter [135/439] Loss: 2.4054, average_loss: 2.8333\n",
      "Epoch [41/50], Iter [140/439] Loss: 2.1473, average_loss: 2.8330\n",
      "Epoch [41/50], Iter [145/439] Loss: 2.0935, average_loss: 2.8192\n",
      "Epoch [41/50], Iter [150/439] Loss: 1.9177, average_loss: 2.8038\n",
      "Epoch [41/50], Iter [155/439] Loss: 2.8161, average_loss: 2.8113\n",
      "Epoch [41/50], Iter [160/439] Loss: 2.9376, average_loss: 2.7981\n",
      "Epoch [41/50], Iter [165/439] Loss: 2.3130, average_loss: 2.8047\n",
      "Epoch [41/50], Iter [170/439] Loss: 2.0051, average_loss: 2.8054\n",
      "Epoch [41/50], Iter [175/439] Loss: 2.6527, average_loss: 2.8108\n",
      "Epoch [41/50], Iter [180/439] Loss: 2.5750, average_loss: 2.7960\n",
      "Epoch [41/50], Iter [185/439] Loss: 2.0259, average_loss: 2.7757\n",
      "Epoch [41/50], Iter [190/439] Loss: 2.3299, average_loss: 2.7808\n",
      "Epoch [41/50], Iter [195/439] Loss: 2.7955, average_loss: 2.7784\n",
      "Epoch [41/50], Iter [200/439] Loss: 2.1574, average_loss: 2.7926\n",
      "Epoch [41/50], Iter [205/439] Loss: 3.2807, average_loss: 2.7801\n",
      "Epoch [41/50], Iter [210/439] Loss: 4.2982, average_loss: 2.7900\n",
      "Epoch [41/50], Iter [215/439] Loss: 1.5776, average_loss: 2.7996\n",
      "Epoch [41/50], Iter [220/439] Loss: 2.1271, average_loss: 2.7933\n",
      "Epoch [41/50], Iter [225/439] Loss: 1.6196, average_loss: 2.7858\n",
      "Epoch [41/50], Iter [230/439] Loss: 4.3048, average_loss: 2.8027\n",
      "Epoch [41/50], Iter [235/439] Loss: 3.3195, average_loss: 2.7989\n",
      "Epoch [41/50], Iter [240/439] Loss: 2.9519, average_loss: 2.7959\n",
      "Epoch [41/50], Iter [245/439] Loss: 2.8536, average_loss: 2.8135\n",
      "Epoch [41/50], Iter [250/439] Loss: 3.3127, average_loss: 2.8167\n",
      "Epoch [41/50], Iter [255/439] Loss: 4.4608, average_loss: 2.8220\n",
      "Epoch [41/50], Iter [260/439] Loss: 2.8279, average_loss: 2.8271\n",
      "Epoch [41/50], Iter [265/439] Loss: 3.5556, average_loss: 2.8339\n",
      "Epoch [41/50], Iter [270/439] Loss: 6.1050, average_loss: 2.8504\n",
      "Epoch [41/50], Iter [275/439] Loss: 2.3142, average_loss: 2.8528\n",
      "Epoch [41/50], Iter [280/439] Loss: 3.2516, average_loss: 2.8617\n",
      "Epoch [41/50], Iter [285/439] Loss: 5.9594, average_loss: 2.8700\n",
      "Epoch [41/50], Iter [290/439] Loss: 2.1984, average_loss: 2.8594\n",
      "Epoch [41/50], Iter [295/439] Loss: 5.0197, average_loss: 2.8591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Iter [300/439] Loss: 2.8074, average_loss: 2.8546\n",
      "Epoch [41/50], Iter [305/439] Loss: 4.5104, average_loss: 2.8589\n",
      "Epoch [41/50], Iter [310/439] Loss: 2.4126, average_loss: 2.8596\n",
      "Epoch [41/50], Iter [315/439] Loss: 4.1841, average_loss: 2.8689\n",
      "Epoch [41/50], Iter [320/439] Loss: 3.1142, average_loss: 2.8754\n",
      "Epoch [41/50], Iter [325/439] Loss: 2.8415, average_loss: 2.8831\n",
      "Epoch [41/50], Iter [330/439] Loss: 2.9695, average_loss: 2.8841\n",
      "Epoch [41/50], Iter [335/439] Loss: 2.2168, average_loss: 2.8846\n",
      "Epoch [41/50], Iter [340/439] Loss: 3.2425, average_loss: 2.8788\n",
      "Epoch [41/50], Iter [345/439] Loss: 2.3140, average_loss: 2.8711\n",
      "Epoch [41/50], Iter [350/439] Loss: 2.4696, average_loss: 2.8679\n",
      "Epoch [41/50], Iter [355/439] Loss: 2.5466, average_loss: 2.8709\n",
      "Epoch [41/50], Iter [360/439] Loss: 2.7960, average_loss: 2.8670\n",
      "Epoch [41/50], Iter [365/439] Loss: 3.2772, average_loss: 2.8715\n",
      "Epoch [41/50], Iter [370/439] Loss: 3.1466, average_loss: 2.8651\n",
      "Epoch [41/50], Iter [375/439] Loss: 1.7947, average_loss: 2.8619\n",
      "Epoch [41/50], Iter [380/439] Loss: 3.1803, average_loss: 2.8703\n",
      "Epoch [41/50], Iter [385/439] Loss: 3.0119, average_loss: 2.8704\n",
      "Epoch [41/50], Iter [390/439] Loss: 1.9023, average_loss: 2.8586\n",
      "Epoch [41/50], Iter [395/439] Loss: 6.1410, average_loss: 2.8603\n",
      "Epoch [41/50], Iter [400/439] Loss: 2.2686, average_loss: 2.8531\n",
      "Epoch [41/50], Iter [405/439] Loss: 3.8355, average_loss: 2.8703\n",
      "Epoch [41/50], Iter [410/439] Loss: 2.2358, average_loss: 2.8692\n",
      "Epoch [41/50], Iter [415/439] Loss: 3.1312, average_loss: 2.8721\n",
      "Epoch [41/50], Iter [420/439] Loss: 1.8268, average_loss: 2.8756\n",
      "Epoch [41/50], Iter [425/439] Loss: 2.3842, average_loss: 2.8730\n",
      "Epoch [41/50], Iter [430/439] Loss: 4.1011, average_loss: 2.8769\n",
      "Epoch [41/50], Iter [435/439] Loss: 1.9880, average_loss: 2.8727\n",
      "Test epoch [41/50], average_loss: 3.0070\n",
      "Epoch [42/50], Iter [5/439] Loss: 1.9830, average_loss: 2.1998\n",
      "Epoch [42/50], Iter [10/439] Loss: 4.5790, average_loss: 2.6560\n",
      "Epoch [42/50], Iter [15/439] Loss: 2.3447, average_loss: 2.6611\n",
      "Epoch [42/50], Iter [20/439] Loss: 4.3146, average_loss: 2.7899\n",
      "Epoch [42/50], Iter [25/439] Loss: 1.9680, average_loss: 2.8789\n",
      "Epoch [42/50], Iter [30/439] Loss: 3.2938, average_loss: 2.8672\n",
      "Epoch [42/50], Iter [35/439] Loss: 3.6295, average_loss: 2.8723\n",
      "Epoch [42/50], Iter [40/439] Loss: 2.9750, average_loss: 2.8779\n",
      "Epoch [42/50], Iter [45/439] Loss: 2.3572, average_loss: 2.9064\n",
      "Epoch [42/50], Iter [50/439] Loss: 2.8517, average_loss: 2.8960\n",
      "Epoch [42/50], Iter [55/439] Loss: 2.1165, average_loss: 2.9011\n",
      "Epoch [42/50], Iter [60/439] Loss: 2.8471, average_loss: 2.8941\n",
      "Epoch [42/50], Iter [65/439] Loss: 3.7621, average_loss: 2.8588\n",
      "Epoch [42/50], Iter [70/439] Loss: 2.5191, average_loss: 2.9161\n",
      "Epoch [42/50], Iter [75/439] Loss: 4.2460, average_loss: 2.9083\n",
      "Epoch [42/50], Iter [80/439] Loss: 3.7917, average_loss: 2.9750\n",
      "Epoch [42/50], Iter [85/439] Loss: 2.2705, average_loss: 2.9371\n",
      "Epoch [42/50], Iter [90/439] Loss: 3.5258, average_loss: 2.9368\n",
      "Epoch [42/50], Iter [95/439] Loss: 3.6929, average_loss: 2.9360\n",
      "Epoch [42/50], Iter [100/439] Loss: 1.3109, average_loss: 2.9167\n",
      "Epoch [42/50], Iter [105/439] Loss: 4.3471, average_loss: 2.9428\n",
      "Epoch [42/50], Iter [110/439] Loss: 2.5563, average_loss: 2.9773\n",
      "Epoch [42/50], Iter [115/439] Loss: 2.5703, average_loss: 2.9477\n",
      "Epoch [42/50], Iter [120/439] Loss: 2.6957, average_loss: 2.9461\n",
      "Epoch [42/50], Iter [125/439] Loss: 1.8935, average_loss: 2.9307\n",
      "Epoch [42/50], Iter [130/439] Loss: 2.2435, average_loss: 2.9250\n",
      "Epoch [42/50], Iter [135/439] Loss: 1.8332, average_loss: 2.9075\n",
      "Epoch [42/50], Iter [140/439] Loss: 1.9933, average_loss: 2.8835\n",
      "Epoch [42/50], Iter [145/439] Loss: 3.0398, average_loss: 2.9009\n",
      "Epoch [42/50], Iter [150/439] Loss: 3.2354, average_loss: 2.8998\n",
      "Epoch [42/50], Iter [155/439] Loss: 3.9045, average_loss: 2.9126\n",
      "Epoch [42/50], Iter [160/439] Loss: 3.1077, average_loss: 2.9069\n",
      "Epoch [42/50], Iter [165/439] Loss: 2.4791, average_loss: 2.9151\n",
      "Epoch [42/50], Iter [170/439] Loss: 3.6541, average_loss: 2.9244\n",
      "Epoch [42/50], Iter [175/439] Loss: 2.8830, average_loss: 2.9186\n",
      "Epoch [42/50], Iter [180/439] Loss: 3.4148, average_loss: 2.9053\n",
      "Epoch [42/50], Iter [185/439] Loss: 4.2549, average_loss: 2.9097\n",
      "Epoch [42/50], Iter [190/439] Loss: 2.0017, average_loss: 2.9055\n",
      "Epoch [42/50], Iter [195/439] Loss: 3.9105, average_loss: 2.9189\n",
      "Epoch [42/50], Iter [200/439] Loss: 3.2514, average_loss: 2.9068\n",
      "Epoch [42/50], Iter [205/439] Loss: 2.3694, average_loss: 2.8945\n",
      "Epoch [42/50], Iter [210/439] Loss: 2.4023, average_loss: 2.8814\n",
      "Epoch [42/50], Iter [215/439] Loss: 3.1289, average_loss: 2.8852\n",
      "Epoch [42/50], Iter [220/439] Loss: 4.0018, average_loss: 2.8918\n",
      "Epoch [42/50], Iter [225/439] Loss: 2.1193, average_loss: 2.8925\n",
      "Epoch [42/50], Iter [230/439] Loss: 3.5738, average_loss: 2.8793\n",
      "Epoch [42/50], Iter [235/439] Loss: 3.5663, average_loss: 2.8918\n",
      "Epoch [42/50], Iter [240/439] Loss: 3.1386, average_loss: 2.8993\n",
      "Epoch [42/50], Iter [245/439] Loss: 2.0402, average_loss: 2.8886\n",
      "Epoch [42/50], Iter [250/439] Loss: 3.1807, average_loss: 2.9019\n",
      "Epoch [42/50], Iter [255/439] Loss: 2.3751, average_loss: 2.8921\n",
      "Epoch [42/50], Iter [260/439] Loss: 4.9058, average_loss: 2.9076\n",
      "Epoch [42/50], Iter [265/439] Loss: 1.8481, average_loss: 2.8924\n",
      "Epoch [42/50], Iter [270/439] Loss: 2.2363, average_loss: 2.8849\n",
      "Epoch [42/50], Iter [275/439] Loss: 3.4845, average_loss: 2.8790\n",
      "Epoch [42/50], Iter [280/439] Loss: 2.5153, average_loss: 2.8747\n",
      "Epoch [42/50], Iter [285/439] Loss: 2.1497, average_loss: 2.8680\n",
      "Epoch [42/50], Iter [290/439] Loss: 2.5820, average_loss: 2.8606\n",
      "Epoch [42/50], Iter [295/439] Loss: 1.9929, average_loss: 2.8586\n",
      "Epoch [42/50], Iter [300/439] Loss: 2.3242, average_loss: 2.8635\n",
      "Epoch [42/50], Iter [305/439] Loss: 2.3724, average_loss: 2.8482\n",
      "Epoch [42/50], Iter [310/439] Loss: 2.2771, average_loss: 2.8500\n",
      "Epoch [42/50], Iter [315/439] Loss: 3.0728, average_loss: 2.8455\n",
      "Epoch [42/50], Iter [320/439] Loss: 2.1020, average_loss: 2.8437\n",
      "Epoch [42/50], Iter [325/439] Loss: 2.1206, average_loss: 2.8503\n",
      "Epoch [42/50], Iter [330/439] Loss: 2.0246, average_loss: 2.8509\n",
      "Epoch [42/50], Iter [335/439] Loss: 4.1642, average_loss: 2.8560\n",
      "Epoch [42/50], Iter [340/439] Loss: 3.4688, average_loss: 2.8511\n",
      "Epoch [42/50], Iter [345/439] Loss: 2.2831, average_loss: 2.8581\n",
      "Epoch [42/50], Iter [350/439] Loss: 1.7338, average_loss: 2.8550\n",
      "Epoch [42/50], Iter [355/439] Loss: 1.9327, average_loss: 2.8492\n",
      "Epoch [42/50], Iter [360/439] Loss: 1.9269, average_loss: 2.8427\n",
      "Epoch [42/50], Iter [365/439] Loss: 4.9900, average_loss: 2.8441\n",
      "Epoch [42/50], Iter [370/439] Loss: 1.8138, average_loss: 2.8456\n",
      "Epoch [42/50], Iter [375/439] Loss: 2.4924, average_loss: 2.8424\n",
      "Epoch [42/50], Iter [380/439] Loss: 2.7574, average_loss: 2.8363\n",
      "Epoch [42/50], Iter [385/439] Loss: 2.8995, average_loss: 2.8316\n",
      "Epoch [42/50], Iter [390/439] Loss: 3.9779, average_loss: 2.8360\n",
      "Epoch [42/50], Iter [395/439] Loss: 2.0189, average_loss: 2.8329\n",
      "Epoch [42/50], Iter [400/439] Loss: 3.4009, average_loss: 2.8385\n",
      "Epoch [42/50], Iter [405/439] Loss: 1.9162, average_loss: 2.8386\n",
      "Epoch [42/50], Iter [410/439] Loss: 2.2898, average_loss: 2.8419\n",
      "Epoch [42/50], Iter [415/439] Loss: 1.8603, average_loss: 2.8393\n",
      "Epoch [42/50], Iter [420/439] Loss: 1.9396, average_loss: 2.8435\n",
      "Epoch [42/50], Iter [425/439] Loss: 4.7651, average_loss: 2.8449\n",
      "Epoch [42/50], Iter [430/439] Loss: 1.4720, average_loss: 2.8480\n",
      "Epoch [42/50], Iter [435/439] Loss: 3.3414, average_loss: 2.8574\n",
      "Test epoch [42/50], average_loss: 3.0147\n",
      "Epoch [43/50], Iter [5/439] Loss: 3.2433, average_loss: 2.3206\n",
      "Epoch [43/50], Iter [10/439] Loss: 2.2083, average_loss: 2.4183\n",
      "Epoch [43/50], Iter [15/439] Loss: 2.6408, average_loss: 2.6298\n",
      "Epoch [43/50], Iter [20/439] Loss: 1.9041, average_loss: 2.6794\n",
      "Epoch [43/50], Iter [25/439] Loss: 1.9718, average_loss: 2.7291\n",
      "Epoch [43/50], Iter [30/439] Loss: 2.3198, average_loss: 2.8217\n",
      "Epoch [43/50], Iter [35/439] Loss: 1.6814, average_loss: 2.7711\n",
      "Epoch [43/50], Iter [40/439] Loss: 3.4175, average_loss: 2.8256\n",
      "Epoch [43/50], Iter [45/439] Loss: 2.7391, average_loss: 2.8709\n",
      "Epoch [43/50], Iter [50/439] Loss: 3.2019, average_loss: 2.8575\n",
      "Epoch [43/50], Iter [55/439] Loss: 2.3136, average_loss: 2.8233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Iter [60/439] Loss: 6.2157, average_loss: 2.8717\n",
      "Epoch [43/50], Iter [65/439] Loss: 2.3366, average_loss: 2.8476\n",
      "Epoch [43/50], Iter [70/439] Loss: 2.3867, average_loss: 2.8680\n",
      "Epoch [43/50], Iter [75/439] Loss: 3.8541, average_loss: 2.8703\n",
      "Epoch [43/50], Iter [80/439] Loss: 2.1915, average_loss: 2.8562\n",
      "Epoch [43/50], Iter [85/439] Loss: 3.6481, average_loss: 2.8498\n",
      "Epoch [43/50], Iter [90/439] Loss: 3.4215, average_loss: 2.8551\n",
      "Epoch [43/50], Iter [95/439] Loss: 2.4936, average_loss: 2.8428\n",
      "Epoch [43/50], Iter [100/439] Loss: 1.8454, average_loss: 2.8445\n",
      "Epoch [43/50], Iter [105/439] Loss: 4.4386, average_loss: 2.8376\n",
      "Epoch [43/50], Iter [110/439] Loss: 2.9320, average_loss: 2.8343\n",
      "Epoch [43/50], Iter [115/439] Loss: 3.5346, average_loss: 2.8278\n",
      "Epoch [43/50], Iter [120/439] Loss: 2.4358, average_loss: 2.8221\n",
      "Epoch [43/50], Iter [125/439] Loss: 6.3992, average_loss: 2.8248\n",
      "Epoch [43/50], Iter [130/439] Loss: 3.4587, average_loss: 2.8214\n",
      "Epoch [43/50], Iter [135/439] Loss: 2.7349, average_loss: 2.8228\n",
      "Epoch [43/50], Iter [140/439] Loss: 3.9672, average_loss: 2.8297\n",
      "Epoch [43/50], Iter [145/439] Loss: 2.2900, average_loss: 2.8337\n",
      "Epoch [43/50], Iter [150/439] Loss: 3.1316, average_loss: 2.8545\n",
      "Epoch [43/50], Iter [155/439] Loss: 3.6566, average_loss: 2.8754\n",
      "Epoch [43/50], Iter [160/439] Loss: 1.5305, average_loss: 2.8432\n",
      "Epoch [43/50], Iter [165/439] Loss: 1.3830, average_loss: 2.8508\n",
      "Epoch [43/50], Iter [170/439] Loss: 4.5552, average_loss: 2.8803\n",
      "Epoch [43/50], Iter [175/439] Loss: 3.3761, average_loss: 2.8822\n",
      "Epoch [43/50], Iter [180/439] Loss: 1.9940, average_loss: 2.8738\n",
      "Epoch [43/50], Iter [185/439] Loss: 2.5458, average_loss: 2.8606\n",
      "Epoch [43/50], Iter [190/439] Loss: 1.9871, average_loss: 2.8411\n",
      "Epoch [43/50], Iter [195/439] Loss: 2.2921, average_loss: 2.8516\n",
      "Epoch [43/50], Iter [200/439] Loss: 2.7971, average_loss: 2.8437\n",
      "Epoch [43/50], Iter [205/439] Loss: 2.4401, average_loss: 2.8312\n",
      "Epoch [43/50], Iter [210/439] Loss: 1.7004, average_loss: 2.8274\n",
      "Epoch [43/50], Iter [215/439] Loss: 2.1371, average_loss: 2.8237\n",
      "Epoch [43/50], Iter [220/439] Loss: 1.6779, average_loss: 2.8159\n",
      "Epoch [43/50], Iter [225/439] Loss: 3.2018, average_loss: 2.8079\n",
      "Epoch [43/50], Iter [230/439] Loss: 3.6732, average_loss: 2.8199\n",
      "Epoch [43/50], Iter [235/439] Loss: 3.1560, average_loss: 2.8251\n",
      "Epoch [43/50], Iter [240/439] Loss: 1.9931, average_loss: 2.8315\n",
      "Epoch [43/50], Iter [245/439] Loss: 3.1292, average_loss: 2.8297\n",
      "Epoch [43/50], Iter [250/439] Loss: 3.2846, average_loss: 2.8321\n",
      "Epoch [43/50], Iter [255/439] Loss: 3.2427, average_loss: 2.8217\n",
      "Epoch [43/50], Iter [260/439] Loss: 2.1345, average_loss: 2.8132\n",
      "Epoch [43/50], Iter [265/439] Loss: 1.6381, average_loss: 2.8114\n",
      "Epoch [43/50], Iter [270/439] Loss: 2.7495, average_loss: 2.8238\n",
      "Epoch [43/50], Iter [275/439] Loss: 3.5973, average_loss: 2.8286\n",
      "Epoch [43/50], Iter [280/439] Loss: 3.0164, average_loss: 2.8256\n",
      "Epoch [43/50], Iter [285/439] Loss: 3.3726, average_loss: 2.8299\n",
      "Epoch [43/50], Iter [290/439] Loss: 3.0685, average_loss: 2.8272\n",
      "Epoch [43/50], Iter [295/439] Loss: 4.8887, average_loss: 2.8265\n",
      "Epoch [43/50], Iter [300/439] Loss: 2.6981, average_loss: 2.8273\n",
      "Epoch [43/50], Iter [305/439] Loss: 3.3743, average_loss: 2.8325\n",
      "Epoch [43/50], Iter [310/439] Loss: 3.5972, average_loss: 2.8317\n",
      "Epoch [43/50], Iter [315/439] Loss: 3.4047, average_loss: 2.8358\n",
      "Epoch [43/50], Iter [320/439] Loss: 2.6514, average_loss: 2.8347\n",
      "Epoch [43/50], Iter [325/439] Loss: 2.7676, average_loss: 2.8405\n",
      "Epoch [43/50], Iter [330/439] Loss: 2.6783, average_loss: 2.8412\n",
      "Epoch [43/50], Iter [335/439] Loss: 1.4379, average_loss: 2.8369\n",
      "Epoch [43/50], Iter [340/439] Loss: 3.7770, average_loss: 2.8373\n",
      "Epoch [43/50], Iter [345/439] Loss: 3.2151, average_loss: 2.8309\n",
      "Epoch [43/50], Iter [350/439] Loss: 1.9677, average_loss: 2.8311\n",
      "Epoch [43/50], Iter [355/439] Loss: 3.6760, average_loss: 2.8332\n",
      "Epoch [43/50], Iter [360/439] Loss: 3.9934, average_loss: 2.8303\n",
      "Epoch [43/50], Iter [365/439] Loss: 3.2852, average_loss: 2.8280\n",
      "Epoch [43/50], Iter [370/439] Loss: 2.9105, average_loss: 2.8351\n",
      "Epoch [43/50], Iter [375/439] Loss: 2.0019, average_loss: 2.8231\n",
      "Epoch [43/50], Iter [380/439] Loss: 1.4230, average_loss: 2.8172\n",
      "Epoch [43/50], Iter [385/439] Loss: 2.7713, average_loss: 2.8134\n",
      "Epoch [43/50], Iter [390/439] Loss: 2.2761, average_loss: 2.8041\n",
      "Epoch [43/50], Iter [395/439] Loss: 2.6613, average_loss: 2.8080\n",
      "Epoch [43/50], Iter [400/439] Loss: 3.6475, average_loss: 2.8143\n",
      "Epoch [43/50], Iter [405/439] Loss: 3.0568, average_loss: 2.8100\n",
      "Epoch [43/50], Iter [410/439] Loss: 1.8740, average_loss: 2.8120\n",
      "Epoch [43/50], Iter [415/439] Loss: 2.3574, average_loss: 2.8112\n",
      "Epoch [43/50], Iter [420/439] Loss: 3.9915, average_loss: 2.8119\n",
      "Epoch [43/50], Iter [425/439] Loss: 2.5008, average_loss: 2.8061\n",
      "Epoch [43/50], Iter [430/439] Loss: 3.0837, average_loss: 2.8092\n",
      "Epoch [43/50], Iter [435/439] Loss: 3.3210, average_loss: 2.8175\n",
      "Test epoch [43/50], average_loss: 3.0138\n",
      "Epoch [44/50], Iter [5/439] Loss: 3.5089, average_loss: 2.9183\n",
      "Epoch [44/50], Iter [10/439] Loss: 4.6635, average_loss: 3.1400\n",
      "Epoch [44/50], Iter [15/439] Loss: 1.6705, average_loss: 2.9049\n",
      "Epoch [44/50], Iter [20/439] Loss: 1.7109, average_loss: 2.8955\n",
      "Epoch [44/50], Iter [25/439] Loss: 2.4164, average_loss: 2.8572\n",
      "Epoch [44/50], Iter [30/439] Loss: 1.9191, average_loss: 2.7566\n",
      "Epoch [44/50], Iter [35/439] Loss: 2.9223, average_loss: 2.7742\n",
      "Epoch [44/50], Iter [40/439] Loss: 2.7018, average_loss: 2.7749\n",
      "Epoch [44/50], Iter [45/439] Loss: 4.1218, average_loss: 2.8299\n",
      "Epoch [44/50], Iter [50/439] Loss: 2.8486, average_loss: 2.7515\n",
      "Epoch [44/50], Iter [55/439] Loss: 1.9502, average_loss: 2.8344\n",
      "Epoch [44/50], Iter [60/439] Loss: 3.3526, average_loss: 2.8323\n",
      "Epoch [44/50], Iter [65/439] Loss: 3.6317, average_loss: 2.8736\n",
      "Epoch [44/50], Iter [70/439] Loss: 4.1079, average_loss: 2.9330\n",
      "Epoch [44/50], Iter [75/439] Loss: 2.1851, average_loss: 2.9173\n",
      "Epoch [44/50], Iter [80/439] Loss: 2.0228, average_loss: 2.9395\n",
      "Epoch [44/50], Iter [85/439] Loss: 2.8161, average_loss: 2.9336\n",
      "Epoch [44/50], Iter [90/439] Loss: 1.4489, average_loss: 2.8779\n",
      "Epoch [44/50], Iter [95/439] Loss: 5.5744, average_loss: 2.8931\n",
      "Epoch [44/50], Iter [100/439] Loss: 1.8334, average_loss: 2.8777\n",
      "Epoch [44/50], Iter [105/439] Loss: 3.6572, average_loss: 2.8653\n",
      "Epoch [44/50], Iter [110/439] Loss: 3.7584, average_loss: 2.8693\n",
      "Epoch [44/50], Iter [115/439] Loss: 1.9807, average_loss: 2.8709\n",
      "Epoch [44/50], Iter [120/439] Loss: 3.0273, average_loss: 2.8453\n",
      "Epoch [44/50], Iter [125/439] Loss: 3.0976, average_loss: 2.8565\n",
      "Epoch [44/50], Iter [130/439] Loss: 3.3614, average_loss: 2.8501\n",
      "Epoch [44/50], Iter [135/439] Loss: 3.8812, average_loss: 2.8668\n",
      "Epoch [44/50], Iter [140/439] Loss: 2.4031, average_loss: 2.8628\n",
      "Epoch [44/50], Iter [145/439] Loss: 3.6645, average_loss: 2.8664\n",
      "Epoch [44/50], Iter [150/439] Loss: 1.7280, average_loss: 2.8599\n",
      "Epoch [44/50], Iter [155/439] Loss: 2.2209, average_loss: 2.8408\n",
      "Epoch [44/50], Iter [160/439] Loss: 1.8224, average_loss: 2.8343\n",
      "Epoch [44/50], Iter [165/439] Loss: 3.3384, average_loss: 2.8353\n",
      "Epoch [44/50], Iter [170/439] Loss: 3.5188, average_loss: 2.8623\n",
      "Epoch [44/50], Iter [175/439] Loss: 2.2773, average_loss: 2.8528\n",
      "Epoch [44/50], Iter [180/439] Loss: 2.1252, average_loss: 2.8451\n",
      "Epoch [44/50], Iter [185/439] Loss: 4.7571, average_loss: 2.8503\n",
      "Epoch [44/50], Iter [190/439] Loss: 3.7667, average_loss: 2.8556\n",
      "Epoch [44/50], Iter [195/439] Loss: 1.9780, average_loss: 2.8544\n",
      "Epoch [44/50], Iter [200/439] Loss: 3.0123, average_loss: 2.8456\n",
      "Epoch [44/50], Iter [205/439] Loss: 2.8332, average_loss: 2.8510\n",
      "Epoch [44/50], Iter [210/439] Loss: 1.9006, average_loss: 2.8456\n",
      "Epoch [44/50], Iter [215/439] Loss: 2.2412, average_loss: 2.8476\n",
      "Epoch [44/50], Iter [220/439] Loss: 2.9543, average_loss: 2.8506\n",
      "Epoch [44/50], Iter [225/439] Loss: 1.5488, average_loss: 2.8456\n",
      "Epoch [44/50], Iter [230/439] Loss: 2.3316, average_loss: 2.8407\n",
      "Epoch [44/50], Iter [235/439] Loss: 1.9240, average_loss: 2.8340\n",
      "Epoch [44/50], Iter [240/439] Loss: 3.0790, average_loss: 2.8357\n",
      "Epoch [44/50], Iter [245/439] Loss: 2.4294, average_loss: 2.8253\n",
      "Epoch [44/50], Iter [250/439] Loss: 3.5972, average_loss: 2.8359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Iter [255/439] Loss: 1.4338, average_loss: 2.8388\n",
      "Epoch [44/50], Iter [260/439] Loss: 3.2730, average_loss: 2.8337\n",
      "Epoch [44/50], Iter [265/439] Loss: 1.8488, average_loss: 2.8307\n",
      "Epoch [44/50], Iter [270/439] Loss: 2.1268, average_loss: 2.8359\n",
      "Epoch [44/50], Iter [275/439] Loss: 2.7582, average_loss: 2.8320\n",
      "Epoch [44/50], Iter [280/439] Loss: 1.9375, average_loss: 2.8219\n",
      "Epoch [44/50], Iter [285/439] Loss: 1.7419, average_loss: 2.8140\n",
      "Epoch [44/50], Iter [290/439] Loss: 2.3525, average_loss: 2.8134\n",
      "Epoch [44/50], Iter [295/439] Loss: 2.6761, average_loss: 2.8047\n",
      "Epoch [44/50], Iter [300/439] Loss: 3.0730, average_loss: 2.8132\n",
      "Epoch [44/50], Iter [305/439] Loss: 1.4184, average_loss: 2.8044\n",
      "Epoch [44/50], Iter [310/439] Loss: 2.3580, average_loss: 2.8079\n",
      "Epoch [44/50], Iter [315/439] Loss: 2.0710, average_loss: 2.7989\n",
      "Epoch [44/50], Iter [320/439] Loss: 3.0875, average_loss: 2.8118\n",
      "Epoch [44/50], Iter [325/439] Loss: 2.5726, average_loss: 2.8173\n",
      "Epoch [44/50], Iter [330/439] Loss: 3.1659, average_loss: 2.8185\n",
      "Epoch [44/50], Iter [335/439] Loss: 3.7690, average_loss: 2.8230\n",
      "Epoch [44/50], Iter [340/439] Loss: 4.1483, average_loss: 2.8254\n",
      "Epoch [44/50], Iter [345/439] Loss: 1.3235, average_loss: 2.8166\n",
      "Epoch [44/50], Iter [350/439] Loss: 4.3454, average_loss: 2.8260\n",
      "Epoch [44/50], Iter [355/439] Loss: 6.3631, average_loss: 2.8356\n",
      "Epoch [44/50], Iter [360/439] Loss: 3.5719, average_loss: 2.8317\n",
      "Epoch [44/50], Iter [365/439] Loss: 2.7342, average_loss: 2.8430\n",
      "Epoch [44/50], Iter [370/439] Loss: 2.8160, average_loss: 2.8447\n",
      "Epoch [44/50], Iter [375/439] Loss: 2.0240, average_loss: 2.8407\n",
      "Epoch [44/50], Iter [380/439] Loss: 1.7897, average_loss: 2.8311\n",
      "Epoch [44/50], Iter [385/439] Loss: 2.5147, average_loss: 2.8300\n",
      "Epoch [44/50], Iter [390/439] Loss: 2.5769, average_loss: 2.8305\n",
      "Epoch [44/50], Iter [395/439] Loss: 2.5038, average_loss: 2.8305\n",
      "Epoch [44/50], Iter [400/439] Loss: 1.5962, average_loss: 2.8277\n",
      "Epoch [44/50], Iter [405/439] Loss: 1.8085, average_loss: 2.8191\n",
      "Epoch [44/50], Iter [410/439] Loss: 2.4532, average_loss: 2.8219\n",
      "Epoch [44/50], Iter [415/439] Loss: 2.0206, average_loss: 2.8224\n",
      "Epoch [44/50], Iter [420/439] Loss: 3.4949, average_loss: 2.8284\n",
      "Epoch [44/50], Iter [425/439] Loss: 1.6701, average_loss: 2.8317\n",
      "Epoch [44/50], Iter [430/439] Loss: 2.9635, average_loss: 2.8349\n",
      "Epoch [44/50], Iter [435/439] Loss: 2.8378, average_loss: 2.8351\n",
      "Test epoch [44/50], average_loss: 2.9890\n",
      "Epoch [45/50], Iter [5/439] Loss: 2.9165, average_loss: 2.6136\n",
      "Epoch [45/50], Iter [10/439] Loss: 2.4022, average_loss: 2.8434\n",
      "Epoch [45/50], Iter [15/439] Loss: 3.1531, average_loss: 2.8607\n",
      "Epoch [45/50], Iter [20/439] Loss: 3.4431, average_loss: 2.8523\n",
      "Epoch [45/50], Iter [25/439] Loss: 1.8862, average_loss: 2.8664\n",
      "Epoch [45/50], Iter [30/439] Loss: 2.7883, average_loss: 2.8154\n",
      "Epoch [45/50], Iter [35/439] Loss: 2.5699, average_loss: 2.7550\n",
      "Epoch [45/50], Iter [40/439] Loss: 5.0822, average_loss: 2.7779\n",
      "Epoch [45/50], Iter [45/439] Loss: 2.8750, average_loss: 2.8093\n",
      "Epoch [45/50], Iter [50/439] Loss: 2.0452, average_loss: 2.7855\n",
      "Epoch [45/50], Iter [55/439] Loss: 2.5721, average_loss: 2.7343\n",
      "Epoch [45/50], Iter [60/439] Loss: 2.1316, average_loss: 2.7650\n",
      "Epoch [45/50], Iter [65/439] Loss: 2.2281, average_loss: 2.7334\n",
      "Epoch [45/50], Iter [70/439] Loss: 2.9323, average_loss: 2.7614\n",
      "Epoch [45/50], Iter [75/439] Loss: 4.7736, average_loss: 2.7873\n",
      "Epoch [45/50], Iter [80/439] Loss: 2.5218, average_loss: 2.7779\n",
      "Epoch [45/50], Iter [85/439] Loss: 3.0974, average_loss: 2.7620\n",
      "Epoch [45/50], Iter [90/439] Loss: 2.4364, average_loss: 2.7476\n",
      "Epoch [45/50], Iter [95/439] Loss: 3.0631, average_loss: 2.7558\n",
      "Epoch [45/50], Iter [100/439] Loss: 1.5440, average_loss: 2.7191\n",
      "Epoch [45/50], Iter [105/439] Loss: 2.3059, average_loss: 2.7216\n",
      "Epoch [45/50], Iter [110/439] Loss: 3.0081, average_loss: 2.7071\n",
      "Epoch [45/50], Iter [115/439] Loss: 2.1998, average_loss: 2.7161\n",
      "Epoch [45/50], Iter [120/439] Loss: 3.6339, average_loss: 2.7136\n",
      "Epoch [45/50], Iter [125/439] Loss: 2.6503, average_loss: 2.7090\n",
      "Epoch [45/50], Iter [130/439] Loss: 5.1772, average_loss: 2.7274\n",
      "Epoch [45/50], Iter [135/439] Loss: 3.9301, average_loss: 2.7288\n",
      "Epoch [45/50], Iter [140/439] Loss: 2.3573, average_loss: 2.7260\n",
      "Epoch [45/50], Iter [145/439] Loss: 2.7084, average_loss: 2.7147\n",
      "Epoch [45/50], Iter [150/439] Loss: 3.3889, average_loss: 2.7141\n",
      "Epoch [45/50], Iter [155/439] Loss: 2.2260, average_loss: 2.7139\n",
      "Epoch [45/50], Iter [160/439] Loss: 2.1160, average_loss: 2.6970\n",
      "Epoch [45/50], Iter [165/439] Loss: 2.4456, average_loss: 2.6931\n",
      "Epoch [45/50], Iter [170/439] Loss: 2.1740, average_loss: 2.7155\n",
      "Epoch [45/50], Iter [175/439] Loss: 3.7140, average_loss: 2.7155\n",
      "Epoch [45/50], Iter [180/439] Loss: 1.7431, average_loss: 2.7052\n",
      "Epoch [45/50], Iter [185/439] Loss: 2.9129, average_loss: 2.7095\n",
      "Epoch [45/50], Iter [190/439] Loss: 3.0525, average_loss: 2.7147\n",
      "Epoch [45/50], Iter [195/439] Loss: 3.8326, average_loss: 2.7216\n",
      "Epoch [45/50], Iter [200/439] Loss: 4.2268, average_loss: 2.7319\n",
      "Epoch [45/50], Iter [205/439] Loss: 3.2480, average_loss: 2.7194\n",
      "Epoch [45/50], Iter [210/439] Loss: 2.7046, average_loss: 2.7231\n",
      "Epoch [45/50], Iter [215/439] Loss: 2.2093, average_loss: 2.7173\n",
      "Epoch [45/50], Iter [220/439] Loss: 3.3210, average_loss: 2.7210\n",
      "Epoch [45/50], Iter [225/439] Loss: 3.4719, average_loss: 2.7292\n",
      "Epoch [45/50], Iter [230/439] Loss: 2.7181, average_loss: 2.7325\n",
      "Epoch [45/50], Iter [235/439] Loss: 2.9693, average_loss: 2.7434\n",
      "Epoch [45/50], Iter [240/439] Loss: 1.7503, average_loss: 2.7512\n",
      "Epoch [45/50], Iter [245/439] Loss: 0.9211, average_loss: 2.7362\n",
      "Epoch [45/50], Iter [250/439] Loss: 2.5443, average_loss: 2.7449\n",
      "Epoch [45/50], Iter [255/439] Loss: 1.5988, average_loss: 2.7482\n",
      "Epoch [45/50], Iter [260/439] Loss: 1.6757, average_loss: 2.7426\n",
      "Epoch [45/50], Iter [265/439] Loss: 2.5722, average_loss: 2.7373\n",
      "Epoch [45/50], Iter [270/439] Loss: 1.7414, average_loss: 2.7261\n",
      "Epoch [45/50], Iter [275/439] Loss: 3.1283, average_loss: 2.7277\n",
      "Epoch [45/50], Iter [280/439] Loss: 4.2256, average_loss: 2.7359\n",
      "Epoch [45/50], Iter [285/439] Loss: 2.6231, average_loss: 2.7294\n",
      "Epoch [45/50], Iter [290/439] Loss: 1.9250, average_loss: 2.7230\n",
      "Epoch [45/50], Iter [295/439] Loss: 3.6469, average_loss: 2.7180\n",
      "Epoch [45/50], Iter [300/439] Loss: 2.8664, average_loss: 2.7124\n",
      "Epoch [45/50], Iter [305/439] Loss: 4.3481, average_loss: 2.7145\n",
      "Epoch [45/50], Iter [310/439] Loss: 3.6353, average_loss: 2.7204\n",
      "Epoch [45/50], Iter [315/439] Loss: 2.5061, average_loss: 2.7210\n",
      "Epoch [45/50], Iter [320/439] Loss: 5.7274, average_loss: 2.7383\n",
      "Epoch [45/50], Iter [325/439] Loss: 2.4375, average_loss: 2.7377\n",
      "Epoch [45/50], Iter [330/439] Loss: 3.2644, average_loss: 2.7375\n",
      "Epoch [45/50], Iter [335/439] Loss: 2.0663, average_loss: 2.7340\n",
      "Epoch [45/50], Iter [340/439] Loss: 1.5447, average_loss: 2.7322\n",
      "Epoch [45/50], Iter [345/439] Loss: 3.1397, average_loss: 2.7358\n",
      "Epoch [45/50], Iter [350/439] Loss: 3.6492, average_loss: 2.7403\n",
      "Epoch [45/50], Iter [355/439] Loss: 2.5355, average_loss: 2.7463\n",
      "Epoch [45/50], Iter [360/439] Loss: 4.2543, average_loss: 2.7552\n",
      "Epoch [45/50], Iter [365/439] Loss: 1.9022, average_loss: 2.7530\n",
      "Epoch [45/50], Iter [370/439] Loss: 1.9545, average_loss: 2.7585\n",
      "Epoch [45/50], Iter [375/439] Loss: 2.2845, average_loss: 2.7526\n",
      "Epoch [45/50], Iter [380/439] Loss: 2.4496, average_loss: 2.7571\n",
      "Epoch [45/50], Iter [385/439] Loss: 2.8351, average_loss: 2.7499\n",
      "Epoch [45/50], Iter [390/439] Loss: 3.6850, average_loss: 2.7605\n",
      "Epoch [45/50], Iter [395/439] Loss: 6.2961, average_loss: 2.7702\n",
      "Epoch [45/50], Iter [400/439] Loss: 3.4207, average_loss: 2.7808\n",
      "Epoch [45/50], Iter [405/439] Loss: 4.3032, average_loss: 2.7850\n",
      "Epoch [45/50], Iter [410/439] Loss: 2.6784, average_loss: 2.7764\n",
      "Epoch [45/50], Iter [415/439] Loss: 2.5503, average_loss: 2.7774\n",
      "Epoch [45/50], Iter [420/439] Loss: 1.7469, average_loss: 2.7701\n",
      "Epoch [45/50], Iter [425/439] Loss: 3.4371, average_loss: 2.7731\n",
      "Epoch [45/50], Iter [430/439] Loss: 2.8836, average_loss: 2.7740\n",
      "Epoch [45/50], Iter [435/439] Loss: 2.6546, average_loss: 2.7727\n",
      "Test epoch [45/50], average_loss: 2.9756\n",
      "Epoch [46/50], Iter [5/439] Loss: 2.3432, average_loss: 2.4598\n",
      "Epoch [46/50], Iter [10/439] Loss: 4.8084, average_loss: 2.8331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Iter [15/439] Loss: 1.6249, average_loss: 2.8300\n",
      "Epoch [46/50], Iter [20/439] Loss: 1.7093, average_loss: 2.6948\n",
      "Epoch [46/50], Iter [25/439] Loss: 5.2867, average_loss: 2.6676\n",
      "Epoch [46/50], Iter [30/439] Loss: 1.8777, average_loss: 2.6238\n",
      "Epoch [46/50], Iter [35/439] Loss: 2.4969, average_loss: 2.5909\n",
      "Epoch [46/50], Iter [40/439] Loss: 4.2842, average_loss: 2.7189\n",
      "Epoch [46/50], Iter [45/439] Loss: 3.2140, average_loss: 2.7153\n",
      "Epoch [46/50], Iter [50/439] Loss: 1.6041, average_loss: 2.6931\n",
      "Epoch [46/50], Iter [55/439] Loss: 3.1115, average_loss: 2.6847\n",
      "Epoch [46/50], Iter [60/439] Loss: 2.9974, average_loss: 2.7236\n",
      "Epoch [46/50], Iter [65/439] Loss: 3.3557, average_loss: 2.6899\n",
      "Epoch [46/50], Iter [70/439] Loss: 3.5225, average_loss: 2.7003\n",
      "Epoch [46/50], Iter [75/439] Loss: 1.9463, average_loss: 2.7009\n",
      "Epoch [46/50], Iter [80/439] Loss: 2.2323, average_loss: 2.7104\n",
      "Epoch [46/50], Iter [85/439] Loss: 2.1155, average_loss: 2.6973\n",
      "Epoch [46/50], Iter [90/439] Loss: 2.0896, average_loss: 2.6985\n",
      "Epoch [46/50], Iter [95/439] Loss: 2.9867, average_loss: 2.7080\n",
      "Epoch [46/50], Iter [100/439] Loss: 2.9094, average_loss: 2.7057\n",
      "Epoch [46/50], Iter [105/439] Loss: 2.8000, average_loss: 2.7056\n",
      "Epoch [46/50], Iter [110/439] Loss: 2.1250, average_loss: 2.6916\n",
      "Epoch [46/50], Iter [115/439] Loss: 2.4233, average_loss: 2.6868\n",
      "Epoch [46/50], Iter [120/439] Loss: 2.4435, average_loss: 2.6813\n",
      "Epoch [46/50], Iter [125/439] Loss: 2.0157, average_loss: 2.6698\n",
      "Epoch [46/50], Iter [130/439] Loss: 1.4505, average_loss: 2.6700\n",
      "Epoch [46/50], Iter [135/439] Loss: 3.3343, average_loss: 2.6883\n",
      "Epoch [46/50], Iter [140/439] Loss: 1.5466, average_loss: 2.6896\n",
      "Epoch [46/50], Iter [145/439] Loss: 3.3580, average_loss: 2.6970\n",
      "Epoch [46/50], Iter [150/439] Loss: 2.6454, average_loss: 2.7081\n",
      "Epoch [46/50], Iter [155/439] Loss: 2.9526, average_loss: 2.7091\n",
      "Epoch [46/50], Iter [160/439] Loss: 3.2154, average_loss: 2.7103\n",
      "Epoch [46/50], Iter [165/439] Loss: 3.1592, average_loss: 2.7044\n",
      "Epoch [46/50], Iter [170/439] Loss: 3.5246, average_loss: 2.7405\n",
      "Epoch [46/50], Iter [175/439] Loss: 2.6772, average_loss: 2.7589\n",
      "Epoch [46/50], Iter [180/439] Loss: 3.4511, average_loss: 2.7665\n",
      "Epoch [46/50], Iter [185/439] Loss: 3.2630, average_loss: 2.7739\n",
      "Epoch [46/50], Iter [190/439] Loss: 1.9041, average_loss: 2.7629\n",
      "Epoch [46/50], Iter [195/439] Loss: 3.2623, average_loss: 2.7616\n",
      "Epoch [46/50], Iter [200/439] Loss: 1.2390, average_loss: 2.7726\n",
      "Epoch [46/50], Iter [205/439] Loss: 2.2900, average_loss: 2.7795\n",
      "Epoch [46/50], Iter [210/439] Loss: 2.1230, average_loss: 2.7819\n",
      "Epoch [46/50], Iter [215/439] Loss: 2.2012, average_loss: 2.7657\n",
      "Epoch [46/50], Iter [220/439] Loss: 1.8788, average_loss: 2.7769\n",
      "Epoch [46/50], Iter [225/439] Loss: 1.5466, average_loss: 2.7668\n",
      "Epoch [46/50], Iter [230/439] Loss: 2.2684, average_loss: 2.7608\n",
      "Epoch [46/50], Iter [235/439] Loss: 2.5937, average_loss: 2.7512\n",
      "Epoch [46/50], Iter [240/439] Loss: 2.2941, average_loss: 2.7463\n",
      "Epoch [46/50], Iter [245/439] Loss: 3.1386, average_loss: 2.7453\n",
      "Epoch [46/50], Iter [250/439] Loss: 2.1293, average_loss: 2.7371\n",
      "Epoch [46/50], Iter [255/439] Loss: 2.6933, average_loss: 2.7315\n",
      "Epoch [46/50], Iter [260/439] Loss: 3.1952, average_loss: 2.7431\n",
      "Epoch [46/50], Iter [265/439] Loss: 1.8614, average_loss: 2.7427\n",
      "Epoch [46/50], Iter [270/439] Loss: 3.1755, average_loss: 2.7349\n",
      "Epoch [46/50], Iter [275/439] Loss: 2.1328, average_loss: 2.7309\n",
      "Epoch [46/50], Iter [280/439] Loss: 2.3579, average_loss: 2.7265\n",
      "Epoch [46/50], Iter [285/439] Loss: 3.7330, average_loss: 2.7421\n",
      "Epoch [46/50], Iter [290/439] Loss: 2.7665, average_loss: 2.7442\n",
      "Epoch [46/50], Iter [295/439] Loss: 2.1255, average_loss: 2.7372\n",
      "Epoch [46/50], Iter [300/439] Loss: 1.8682, average_loss: 2.7510\n",
      "Epoch [46/50], Iter [305/439] Loss: 2.9383, average_loss: 2.7435\n",
      "Epoch [46/50], Iter [310/439] Loss: 2.6331, average_loss: 2.7419\n",
      "Epoch [46/50], Iter [315/439] Loss: 2.8645, average_loss: 2.7648\n",
      "Epoch [46/50], Iter [320/439] Loss: 2.3408, average_loss: 2.7559\n",
      "Epoch [46/50], Iter [325/439] Loss: 3.4376, average_loss: 2.7561\n",
      "Epoch [46/50], Iter [330/439] Loss: 1.7811, average_loss: 2.7664\n",
      "Epoch [46/50], Iter [335/439] Loss: 3.6187, average_loss: 2.7619\n",
      "Epoch [46/50], Iter [340/439] Loss: 1.6424, average_loss: 2.7602\n",
      "Epoch [46/50], Iter [345/439] Loss: 2.7311, average_loss: 2.7766\n",
      "Epoch [46/50], Iter [350/439] Loss: 2.5981, average_loss: 2.7801\n",
      "Epoch [46/50], Iter [355/439] Loss: 2.7698, average_loss: 2.7764\n",
      "Epoch [46/50], Iter [360/439] Loss: 1.9894, average_loss: 2.7684\n",
      "Epoch [46/50], Iter [365/439] Loss: 3.6697, average_loss: 2.7722\n",
      "Epoch [46/50], Iter [370/439] Loss: 2.5577, average_loss: 2.7867\n",
      "Epoch [46/50], Iter [375/439] Loss: 2.9137, average_loss: 2.7879\n",
      "Epoch [46/50], Iter [380/439] Loss: 3.7125, average_loss: 2.7855\n",
      "Epoch [46/50], Iter [385/439] Loss: 1.4866, average_loss: 2.7890\n",
      "Epoch [46/50], Iter [390/439] Loss: 2.4951, average_loss: 2.7920\n",
      "Epoch [46/50], Iter [395/439] Loss: 3.5350, average_loss: 2.8013\n",
      "Epoch [46/50], Iter [400/439] Loss: 3.2389, average_loss: 2.7979\n",
      "Epoch [46/50], Iter [405/439] Loss: 2.4688, average_loss: 2.7944\n",
      "Epoch [46/50], Iter [410/439] Loss: 1.9963, average_loss: 2.7887\n",
      "Epoch [46/50], Iter [415/439] Loss: 3.1638, average_loss: 2.7934\n",
      "Epoch [46/50], Iter [420/439] Loss: 1.8197, average_loss: 2.7893\n",
      "Epoch [46/50], Iter [425/439] Loss: 3.0991, average_loss: 2.7894\n",
      "Epoch [46/50], Iter [430/439] Loss: 2.4823, average_loss: 2.7856\n",
      "Epoch [46/50], Iter [435/439] Loss: 1.7423, average_loss: 2.7823\n",
      "Test epoch [46/50], average_loss: 2.9574\n",
      "Epoch [47/50], Iter [5/439] Loss: 2.0212, average_loss: 2.8190\n",
      "Epoch [47/50], Iter [10/439] Loss: 1.6407, average_loss: 2.8085\n",
      "Epoch [47/50], Iter [15/439] Loss: 2.5704, average_loss: 2.5434\n",
      "Epoch [47/50], Iter [20/439] Loss: 3.4266, average_loss: 2.6289\n",
      "Epoch [47/50], Iter [25/439] Loss: 1.3009, average_loss: 2.6941\n",
      "Epoch [47/50], Iter [30/439] Loss: 2.8540, average_loss: 2.6583\n",
      "Epoch [47/50], Iter [35/439] Loss: 2.4173, average_loss: 2.6506\n",
      "Epoch [47/50], Iter [40/439] Loss: 2.4171, average_loss: 2.6016\n",
      "Epoch [47/50], Iter [45/439] Loss: 2.4058, average_loss: 2.6006\n",
      "Epoch [47/50], Iter [50/439] Loss: 2.8602, average_loss: 2.5825\n",
      "Epoch [47/50], Iter [55/439] Loss: 5.2881, average_loss: 2.6416\n",
      "Epoch [47/50], Iter [60/439] Loss: 3.2997, average_loss: 2.6722\n",
      "Epoch [47/50], Iter [65/439] Loss: 4.0430, average_loss: 2.7151\n",
      "Epoch [47/50], Iter [70/439] Loss: 3.0049, average_loss: 2.7079\n",
      "Epoch [47/50], Iter [75/439] Loss: 2.0397, average_loss: 2.7567\n",
      "Epoch [47/50], Iter [80/439] Loss: 3.1730, average_loss: 2.7499\n",
      "Epoch [47/50], Iter [85/439] Loss: 1.5826, average_loss: 2.7592\n",
      "Epoch [47/50], Iter [90/439] Loss: 2.5818, average_loss: 2.7534\n",
      "Epoch [47/50], Iter [95/439] Loss: 3.3397, average_loss: 2.7585\n",
      "Epoch [47/50], Iter [100/439] Loss: 2.9997, average_loss: 2.7610\n",
      "Epoch [47/50], Iter [105/439] Loss: 2.6361, average_loss: 2.7624\n",
      "Epoch [47/50], Iter [110/439] Loss: 2.2268, average_loss: 2.7426\n",
      "Epoch [47/50], Iter [115/439] Loss: 4.7762, average_loss: 2.7274\n",
      "Epoch [47/50], Iter [120/439] Loss: 2.9077, average_loss: 2.7306\n",
      "Epoch [47/50], Iter [125/439] Loss: 3.5690, average_loss: 2.7158\n",
      "Epoch [47/50], Iter [130/439] Loss: 3.5895, average_loss: 2.7227\n",
      "Epoch [47/50], Iter [135/439] Loss: 3.3777, average_loss: 2.7286\n",
      "Epoch [47/50], Iter [140/439] Loss: 2.2314, average_loss: 2.7305\n",
      "Epoch [47/50], Iter [145/439] Loss: 1.6158, average_loss: 2.7240\n",
      "Epoch [47/50], Iter [150/439] Loss: 4.9882, average_loss: 2.7363\n",
      "Epoch [47/50], Iter [155/439] Loss: 2.6398, average_loss: 2.7423\n",
      "Epoch [47/50], Iter [160/439] Loss: 2.7206, average_loss: 2.7446\n",
      "Epoch [47/50], Iter [165/439] Loss: 1.3228, average_loss: 2.7465\n",
      "Epoch [47/50], Iter [170/439] Loss: 2.3323, average_loss: 2.7519\n",
      "Epoch [47/50], Iter [175/439] Loss: 3.1365, average_loss: 2.7425\n",
      "Epoch [47/50], Iter [180/439] Loss: 2.6003, average_loss: 2.7407\n",
      "Epoch [47/50], Iter [185/439] Loss: 3.0195, average_loss: 2.7475\n",
      "Epoch [47/50], Iter [190/439] Loss: 4.1799, average_loss: 2.7534\n",
      "Epoch [47/50], Iter [195/439] Loss: 2.0591, average_loss: 2.7425\n",
      "Epoch [47/50], Iter [200/439] Loss: 2.4115, average_loss: 2.7427\n",
      "Epoch [47/50], Iter [205/439] Loss: 1.5432, average_loss: 2.7384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Iter [210/439] Loss: 3.4119, average_loss: 2.7383\n",
      "Epoch [47/50], Iter [215/439] Loss: 1.5880, average_loss: 2.7424\n",
      "Epoch [47/50], Iter [220/439] Loss: 1.8842, average_loss: 2.7364\n",
      "Epoch [47/50], Iter [225/439] Loss: 3.3420, average_loss: 2.7569\n",
      "Epoch [47/50], Iter [230/439] Loss: 2.0162, average_loss: 2.7415\n",
      "Epoch [47/50], Iter [235/439] Loss: 2.6656, average_loss: 2.7486\n",
      "Epoch [47/50], Iter [240/439] Loss: 1.4373, average_loss: 2.7350\n",
      "Epoch [47/50], Iter [245/439] Loss: 2.2400, average_loss: 2.7278\n",
      "Epoch [47/50], Iter [250/439] Loss: 2.0250, average_loss: 2.7415\n",
      "Epoch [47/50], Iter [255/439] Loss: 3.3432, average_loss: 2.7337\n",
      "Epoch [47/50], Iter [260/439] Loss: 1.6483, average_loss: 2.7363\n",
      "Epoch [47/50], Iter [265/439] Loss: 1.9510, average_loss: 2.7344\n",
      "Epoch [47/50], Iter [270/439] Loss: 1.5350, average_loss: 2.7218\n",
      "Epoch [47/50], Iter [275/439] Loss: 2.4435, average_loss: 2.7269\n",
      "Epoch [47/50], Iter [280/439] Loss: 1.7180, average_loss: 2.7121\n",
      "Epoch [47/50], Iter [285/439] Loss: 1.6157, average_loss: 2.7089\n",
      "Epoch [47/50], Iter [290/439] Loss: 2.9895, average_loss: 2.7119\n",
      "Epoch [47/50], Iter [295/439] Loss: 2.4203, average_loss: 2.7203\n",
      "Epoch [47/50], Iter [300/439] Loss: 1.4745, average_loss: 2.7223\n",
      "Epoch [47/50], Iter [305/439] Loss: 3.0781, average_loss: 2.7117\n",
      "Epoch [47/50], Iter [310/439] Loss: 2.8740, average_loss: 2.7076\n",
      "Epoch [47/50], Iter [315/439] Loss: 3.2448, average_loss: 2.7058\n",
      "Epoch [47/50], Iter [320/439] Loss: 1.9168, average_loss: 2.7097\n",
      "Epoch [47/50], Iter [325/439] Loss: 1.5679, average_loss: 2.7031\n",
      "Epoch [47/50], Iter [330/439] Loss: 3.7252, average_loss: 2.7045\n",
      "Epoch [47/50], Iter [335/439] Loss: 3.5859, average_loss: 2.7151\n",
      "Epoch [47/50], Iter [340/439] Loss: 1.1488, average_loss: 2.7150\n",
      "Epoch [47/50], Iter [345/439] Loss: 2.5374, average_loss: 2.7099\n",
      "Epoch [47/50], Iter [350/439] Loss: 3.7681, average_loss: 2.7094\n",
      "Epoch [47/50], Iter [355/439] Loss: 4.0996, average_loss: 2.7221\n",
      "Epoch [47/50], Iter [360/439] Loss: 1.9233, average_loss: 2.7280\n",
      "Epoch [47/50], Iter [365/439] Loss: 4.1168, average_loss: 2.7310\n",
      "Epoch [47/50], Iter [370/439] Loss: 2.5488, average_loss: 2.7307\n",
      "Epoch [47/50], Iter [375/439] Loss: 3.5470, average_loss: 2.7344\n",
      "Epoch [47/50], Iter [380/439] Loss: 2.5460, average_loss: 2.7396\n",
      "Epoch [47/50], Iter [385/439] Loss: 3.1055, average_loss: 2.7433\n",
      "Epoch [47/50], Iter [390/439] Loss: 1.6880, average_loss: 2.7448\n",
      "Epoch [47/50], Iter [395/439] Loss: 2.8480, average_loss: 2.7414\n",
      "Epoch [47/50], Iter [400/439] Loss: 3.7523, average_loss: 2.7471\n",
      "Epoch [47/50], Iter [405/439] Loss: 2.1399, average_loss: 2.7429\n",
      "Epoch [47/50], Iter [410/439] Loss: 2.0515, average_loss: 2.7352\n",
      "Epoch [47/50], Iter [415/439] Loss: 1.2618, average_loss: 2.7342\n",
      "Epoch [47/50], Iter [420/439] Loss: 1.5918, average_loss: 2.7313\n",
      "Epoch [47/50], Iter [425/439] Loss: 1.2097, average_loss: 2.7261\n",
      "Epoch [47/50], Iter [430/439] Loss: 2.2274, average_loss: 2.7177\n",
      "Epoch [47/50], Iter [435/439] Loss: 1.8495, average_loss: 2.7212\n",
      "Test epoch [47/50], average_loss: 2.9416\n",
      "Epoch [48/50], Iter [5/439] Loss: 3.2978, average_loss: 2.4429\n",
      "Epoch [48/50], Iter [10/439] Loss: 4.4188, average_loss: 2.7036\n",
      "Epoch [48/50], Iter [15/439] Loss: 7.1114, average_loss: 2.9429\n",
      "Epoch [48/50], Iter [20/439] Loss: 1.9313, average_loss: 2.7428\n",
      "Epoch [48/50], Iter [25/439] Loss: 2.7711, average_loss: 2.7195\n",
      "Epoch [48/50], Iter [30/439] Loss: 3.2769, average_loss: 2.7142\n",
      "Epoch [48/50], Iter [35/439] Loss: 3.0769, average_loss: 2.6854\n",
      "Epoch [48/50], Iter [40/439] Loss: 2.3082, average_loss: 2.6360\n",
      "Epoch [48/50], Iter [45/439] Loss: 2.5853, average_loss: 2.6404\n",
      "Epoch [48/50], Iter [50/439] Loss: 4.1500, average_loss: 2.6866\n",
      "Epoch [48/50], Iter [55/439] Loss: 2.0708, average_loss: 2.6581\n",
      "Epoch [48/50], Iter [60/439] Loss: 1.7224, average_loss: 2.6322\n",
      "Epoch [48/50], Iter [65/439] Loss: 2.5939, average_loss: 2.6259\n",
      "Epoch [48/50], Iter [70/439] Loss: 3.3069, average_loss: 2.6721\n",
      "Epoch [48/50], Iter [75/439] Loss: 2.4002, average_loss: 2.6755\n",
      "Epoch [48/50], Iter [80/439] Loss: 2.5653, average_loss: 2.6773\n",
      "Epoch [48/50], Iter [85/439] Loss: 2.2591, average_loss: 2.6592\n",
      "Epoch [48/50], Iter [90/439] Loss: 4.7905, average_loss: 2.6561\n",
      "Epoch [48/50], Iter [95/439] Loss: 2.5260, average_loss: 2.6524\n",
      "Epoch [48/50], Iter [100/439] Loss: 2.6881, average_loss: 2.6657\n",
      "Epoch [48/50], Iter [105/439] Loss: 3.2354, average_loss: 2.6824\n",
      "Epoch [48/50], Iter [110/439] Loss: 4.3392, average_loss: 2.7161\n",
      "Epoch [48/50], Iter [115/439] Loss: 2.9313, average_loss: 2.7162\n",
      "Epoch [48/50], Iter [120/439] Loss: 2.9753, average_loss: 2.7329\n",
      "Epoch [48/50], Iter [125/439] Loss: 2.4831, average_loss: 2.7148\n",
      "Epoch [48/50], Iter [130/439] Loss: 1.7701, average_loss: 2.6769\n",
      "Epoch [48/50], Iter [135/439] Loss: 4.2771, average_loss: 2.6895\n",
      "Epoch [48/50], Iter [140/439] Loss: 2.1707, average_loss: 2.6694\n",
      "Epoch [48/50], Iter [145/439] Loss: 3.4293, average_loss: 2.6673\n",
      "Epoch [48/50], Iter [150/439] Loss: 2.4345, average_loss: 2.6692\n",
      "Epoch [48/50], Iter [155/439] Loss: 2.8845, average_loss: 2.6984\n",
      "Epoch [48/50], Iter [160/439] Loss: 2.1884, average_loss: 2.7143\n",
      "Epoch [48/50], Iter [165/439] Loss: 3.3714, average_loss: 2.7170\n",
      "Epoch [48/50], Iter [170/439] Loss: 1.2775, average_loss: 2.7027\n",
      "Epoch [48/50], Iter [175/439] Loss: 3.0997, average_loss: 2.7140\n",
      "Epoch [48/50], Iter [180/439] Loss: 2.3272, average_loss: 2.7217\n",
      "Epoch [48/50], Iter [185/439] Loss: 2.0724, average_loss: 2.7237\n",
      "Epoch [48/50], Iter [190/439] Loss: 2.5402, average_loss: 2.7372\n",
      "Epoch [48/50], Iter [195/439] Loss: 1.9847, average_loss: 2.7406\n",
      "Epoch [48/50], Iter [200/439] Loss: 2.8602, average_loss: 2.7409\n",
      "Epoch [48/50], Iter [205/439] Loss: 2.2725, average_loss: 2.7320\n",
      "Epoch [48/50], Iter [210/439] Loss: 2.3601, average_loss: 2.7174\n",
      "Epoch [48/50], Iter [215/439] Loss: 2.8474, average_loss: 2.7130\n",
      "Epoch [48/50], Iter [220/439] Loss: 3.4666, average_loss: 2.7208\n",
      "Epoch [48/50], Iter [225/439] Loss: 1.6561, average_loss: 2.7233\n",
      "Epoch [48/50], Iter [230/439] Loss: 2.5050, average_loss: 2.7208\n",
      "Epoch [48/50], Iter [235/439] Loss: 1.8370, average_loss: 2.7203\n",
      "Epoch [48/50], Iter [240/439] Loss: 2.1662, average_loss: 2.7185\n",
      "Epoch [48/50], Iter [245/439] Loss: 3.4256, average_loss: 2.7231\n",
      "Epoch [48/50], Iter [250/439] Loss: 1.7580, average_loss: 2.7132\n",
      "Epoch [48/50], Iter [255/439] Loss: 2.1968, average_loss: 2.7020\n",
      "Epoch [48/50], Iter [260/439] Loss: 7.3035, average_loss: 2.7125\n",
      "Epoch [48/50], Iter [265/439] Loss: 3.3393, average_loss: 2.7075\n",
      "Epoch [48/50], Iter [270/439] Loss: 2.4908, average_loss: 2.6958\n",
      "Epoch [48/50], Iter [275/439] Loss: 1.8010, average_loss: 2.6906\n",
      "Epoch [48/50], Iter [280/439] Loss: 2.2873, average_loss: 2.6770\n",
      "Epoch [48/50], Iter [285/439] Loss: 4.2882, average_loss: 2.6885\n",
      "Epoch [48/50], Iter [290/439] Loss: 3.2950, average_loss: 2.6969\n",
      "Epoch [48/50], Iter [295/439] Loss: 2.2759, average_loss: 2.7075\n",
      "Epoch [48/50], Iter [300/439] Loss: 2.6414, average_loss: 2.7089\n",
      "Epoch [48/50], Iter [305/439] Loss: 2.0891, average_loss: 2.7065\n",
      "Epoch [48/50], Iter [310/439] Loss: 2.3006, average_loss: 2.7035\n",
      "Epoch [48/50], Iter [315/439] Loss: 3.1233, average_loss: 2.7058\n",
      "Epoch [48/50], Iter [320/439] Loss: 2.6197, average_loss: 2.6960\n",
      "Epoch [48/50], Iter [325/439] Loss: 2.6909, average_loss: 2.7003\n",
      "Epoch [48/50], Iter [330/439] Loss: 3.4603, average_loss: 2.7069\n",
      "Epoch [48/50], Iter [335/439] Loss: 2.7162, average_loss: 2.7044\n",
      "Epoch [48/50], Iter [340/439] Loss: 2.4621, average_loss: 2.7024\n",
      "Epoch [48/50], Iter [345/439] Loss: 3.8801, average_loss: 2.7037\n",
      "Epoch [48/50], Iter [350/439] Loss: 3.8003, average_loss: 2.7074\n",
      "Epoch [48/50], Iter [355/439] Loss: 2.6236, average_loss: 2.7014\n",
      "Epoch [48/50], Iter [360/439] Loss: 3.6333, average_loss: 2.7182\n",
      "Epoch [48/50], Iter [365/439] Loss: 2.6519, average_loss: 2.7240\n",
      "Epoch [48/50], Iter [370/439] Loss: 4.1648, average_loss: 2.7260\n",
      "Epoch [48/50], Iter [375/439] Loss: 1.9509, average_loss: 2.7291\n",
      "Epoch [48/50], Iter [380/439] Loss: 3.2025, average_loss: 2.7235\n",
      "Epoch [48/50], Iter [385/439] Loss: 4.4549, average_loss: 2.7309\n",
      "Epoch [48/50], Iter [390/439] Loss: 2.1152, average_loss: 2.7349\n",
      "Epoch [48/50], Iter [395/439] Loss: 2.8421, average_loss: 2.7375\n",
      "Epoch [48/50], Iter [400/439] Loss: 3.2358, average_loss: 2.7394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Iter [405/439] Loss: 3.1859, average_loss: 2.7398\n",
      "Epoch [48/50], Iter [410/439] Loss: 2.6869, average_loss: 2.7337\n",
      "Epoch [48/50], Iter [415/439] Loss: 3.0551, average_loss: 2.7322\n",
      "Epoch [48/50], Iter [420/439] Loss: 2.8549, average_loss: 2.7313\n",
      "Epoch [48/50], Iter [425/439] Loss: 2.5945, average_loss: 2.7254\n",
      "Epoch [48/50], Iter [430/439] Loss: 3.7432, average_loss: 2.7337\n",
      "Epoch [48/50], Iter [435/439] Loss: 1.3513, average_loss: 2.7467\n",
      "Test epoch [48/50], average_loss: 2.9385\n",
      "Epoch [49/50], Iter [5/439] Loss: 2.5981, average_loss: 2.4625\n",
      "Epoch [49/50], Iter [10/439] Loss: 2.5340, average_loss: 2.5093\n",
      "Epoch [49/50], Iter [15/439] Loss: 2.4244, average_loss: 2.3828\n",
      "Epoch [49/50], Iter [20/439] Loss: 3.4618, average_loss: 2.4611\n",
      "Epoch [49/50], Iter [25/439] Loss: 1.8833, average_loss: 2.4791\n",
      "Epoch [49/50], Iter [30/439] Loss: 1.6294, average_loss: 2.4909\n",
      "Epoch [49/50], Iter [35/439] Loss: 3.1964, average_loss: 2.5311\n",
      "Epoch [49/50], Iter [40/439] Loss: 3.2426, average_loss: 2.5608\n",
      "Epoch [49/50], Iter [45/439] Loss: 1.9087, average_loss: 2.5670\n",
      "Epoch [49/50], Iter [50/439] Loss: 2.1626, average_loss: 2.5437\n",
      "Epoch [49/50], Iter [55/439] Loss: 5.8548, average_loss: 2.5863\n",
      "Epoch [49/50], Iter [60/439] Loss: 2.3412, average_loss: 2.6071\n",
      "Epoch [49/50], Iter [65/439] Loss: 1.4230, average_loss: 2.5719\n",
      "Epoch [49/50], Iter [70/439] Loss: 4.2319, average_loss: 2.5755\n",
      "Epoch [49/50], Iter [75/439] Loss: 2.6872, average_loss: 2.5503\n",
      "Epoch [49/50], Iter [80/439] Loss: 3.2747, average_loss: 2.5291\n",
      "Epoch [49/50], Iter [85/439] Loss: 2.3952, average_loss: 2.5629\n",
      "Epoch [49/50], Iter [90/439] Loss: 3.4228, average_loss: 2.6175\n",
      "Epoch [49/50], Iter [95/439] Loss: 2.8585, average_loss: 2.6049\n",
      "Epoch [49/50], Iter [100/439] Loss: 1.7641, average_loss: 2.5889\n",
      "Epoch [49/50], Iter [105/439] Loss: 2.6567, average_loss: 2.5702\n",
      "Epoch [49/50], Iter [110/439] Loss: 2.6105, average_loss: 2.5861\n",
      "Epoch [49/50], Iter [115/439] Loss: 1.2832, average_loss: 2.5893\n",
      "Epoch [49/50], Iter [120/439] Loss: 1.8450, average_loss: 2.5749\n",
      "Epoch [49/50], Iter [125/439] Loss: 2.9731, average_loss: 2.5753\n",
      "Epoch [49/50], Iter [130/439] Loss: 2.5123, average_loss: 2.5878\n",
      "Epoch [49/50], Iter [135/439] Loss: 1.6234, average_loss: 2.5851\n",
      "Epoch [49/50], Iter [140/439] Loss: 2.1684, average_loss: 2.5803\n",
      "Epoch [49/50], Iter [145/439] Loss: 1.4782, average_loss: 2.5745\n",
      "Epoch [49/50], Iter [150/439] Loss: 2.6735, average_loss: 2.5721\n",
      "Epoch [49/50], Iter [155/439] Loss: 2.1896, average_loss: 2.5834\n",
      "Epoch [49/50], Iter [160/439] Loss: 2.1394, average_loss: 2.5875\n",
      "Epoch [49/50], Iter [165/439] Loss: 1.2039, average_loss: 2.5815\n",
      "Epoch [49/50], Iter [170/439] Loss: 3.8770, average_loss: 2.5972\n",
      "Epoch [49/50], Iter [175/439] Loss: 1.7267, average_loss: 2.5936\n",
      "Epoch [49/50], Iter [180/439] Loss: 2.0200, average_loss: 2.5991\n",
      "Epoch [49/50], Iter [185/439] Loss: 2.7674, average_loss: 2.6144\n",
      "Epoch [49/50], Iter [190/439] Loss: 1.6380, average_loss: 2.6300\n",
      "Epoch [49/50], Iter [195/439] Loss: 2.7086, average_loss: 2.6370\n",
      "Epoch [49/50], Iter [200/439] Loss: 1.9824, average_loss: 2.6459\n",
      "Epoch [49/50], Iter [205/439] Loss: 2.7622, average_loss: 2.6412\n",
      "Epoch [49/50], Iter [210/439] Loss: 4.5328, average_loss: 2.6518\n",
      "Epoch [49/50], Iter [215/439] Loss: 1.4634, average_loss: 2.6460\n",
      "Epoch [49/50], Iter [220/439] Loss: 2.1808, average_loss: 2.6364\n",
      "Epoch [49/50], Iter [225/439] Loss: 1.7861, average_loss: 2.6294\n",
      "Epoch [49/50], Iter [230/439] Loss: 2.5217, average_loss: 2.6212\n",
      "Epoch [49/50], Iter [235/439] Loss: 4.4021, average_loss: 2.6288\n",
      "Epoch [49/50], Iter [240/439] Loss: 2.4389, average_loss: 2.6363\n",
      "Epoch [49/50], Iter [245/439] Loss: 4.3136, average_loss: 2.6441\n",
      "Epoch [49/50], Iter [250/439] Loss: 3.1207, average_loss: 2.6478\n",
      "Epoch [49/50], Iter [255/439] Loss: 2.7982, average_loss: 2.6447\n",
      "Epoch [49/50], Iter [260/439] Loss: 3.4857, average_loss: 2.6519\n",
      "Epoch [49/50], Iter [265/439] Loss: 2.8514, average_loss: 2.6684\n",
      "Epoch [49/50], Iter [270/439] Loss: 2.0957, average_loss: 2.6788\n",
      "Epoch [49/50], Iter [275/439] Loss: 3.5180, average_loss: 2.6796\n",
      "Epoch [49/50], Iter [280/439] Loss: 1.8911, average_loss: 2.6693\n",
      "Epoch [49/50], Iter [285/439] Loss: 2.0501, average_loss: 2.6857\n",
      "Epoch [49/50], Iter [290/439] Loss: 1.6068, average_loss: 2.6914\n",
      "Epoch [49/50], Iter [295/439] Loss: 1.8339, average_loss: 2.6847\n",
      "Epoch [49/50], Iter [300/439] Loss: 2.3485, average_loss: 2.6835\n",
      "Epoch [49/50], Iter [305/439] Loss: 2.5249, average_loss: 2.6879\n",
      "Epoch [49/50], Iter [310/439] Loss: 4.4734, average_loss: 2.6935\n",
      "Epoch [49/50], Iter [315/439] Loss: 3.0947, average_loss: 2.6938\n",
      "Epoch [49/50], Iter [320/439] Loss: 1.9014, average_loss: 2.6866\n",
      "Epoch [49/50], Iter [325/439] Loss: 1.9208, average_loss: 2.6920\n",
      "Epoch [49/50], Iter [330/439] Loss: 1.9278, average_loss: 2.7009\n",
      "Epoch [49/50], Iter [335/439] Loss: 2.9678, average_loss: 2.6990\n",
      "Epoch [49/50], Iter [340/439] Loss: 1.4111, average_loss: 2.7006\n",
      "Epoch [49/50], Iter [345/439] Loss: 2.4234, average_loss: 2.6988\n",
      "Epoch [49/50], Iter [350/439] Loss: 2.8168, average_loss: 2.6981\n",
      "Epoch [49/50], Iter [355/439] Loss: 2.4595, average_loss: 2.7006\n",
      "Epoch [49/50], Iter [360/439] Loss: 2.0609, average_loss: 2.6953\n",
      "Epoch [49/50], Iter [365/439] Loss: 2.1973, average_loss: 2.6982\n",
      "Epoch [49/50], Iter [370/439] Loss: 2.6427, average_loss: 2.7058\n",
      "Epoch [49/50], Iter [375/439] Loss: 1.8761, average_loss: 2.7053\n",
      "Epoch [49/50], Iter [380/439] Loss: 2.0270, average_loss: 2.7029\n",
      "Epoch [49/50], Iter [385/439] Loss: 1.8791, average_loss: 2.6956\n",
      "Epoch [49/50], Iter [390/439] Loss: 2.5494, average_loss: 2.7028\n",
      "Epoch [49/50], Iter [395/439] Loss: 3.5615, average_loss: 2.7066\n",
      "Epoch [49/50], Iter [400/439] Loss: 2.5745, average_loss: 2.7104\n",
      "Epoch [49/50], Iter [405/439] Loss: 1.7949, average_loss: 2.7118\n",
      "Epoch [49/50], Iter [410/439] Loss: 3.1197, average_loss: 2.7096\n",
      "Epoch [49/50], Iter [415/439] Loss: 2.6757, average_loss: 2.7123\n",
      "Epoch [49/50], Iter [420/439] Loss: 4.0439, average_loss: 2.7106\n",
      "Epoch [49/50], Iter [425/439] Loss: 2.4552, average_loss: 2.7101\n",
      "Epoch [49/50], Iter [430/439] Loss: 3.5902, average_loss: 2.7087\n",
      "Epoch [49/50], Iter [435/439] Loss: 2.6334, average_loss: 2.7070\n",
      "Test epoch [49/50], average_loss: 2.9351\n",
      "Epoch [50/50], Iter [5/439] Loss: 1.7349, average_loss: 2.8657\n",
      "Epoch [50/50], Iter [10/439] Loss: 3.1206, average_loss: 2.6012\n",
      "Epoch [50/50], Iter [15/439] Loss: 2.8474, average_loss: 2.5769\n",
      "Epoch [50/50], Iter [20/439] Loss: 1.8813, average_loss: 2.5859\n",
      "Epoch [50/50], Iter [25/439] Loss: 3.3406, average_loss: 2.6548\n",
      "Epoch [50/50], Iter [30/439] Loss: 3.3377, average_loss: 2.6904\n",
      "Epoch [50/50], Iter [35/439] Loss: 2.9496, average_loss: 2.7389\n",
      "Epoch [50/50], Iter [40/439] Loss: 1.6795, average_loss: 2.6426\n",
      "Epoch [50/50], Iter [45/439] Loss: 5.0340, average_loss: 2.7220\n",
      "Epoch [50/50], Iter [50/439] Loss: 2.0710, average_loss: 2.7602\n",
      "Epoch [50/50], Iter [55/439] Loss: 3.1587, average_loss: 2.7567\n",
      "Epoch [50/50], Iter [60/439] Loss: 1.8281, average_loss: 2.7635\n",
      "Epoch [50/50], Iter [65/439] Loss: 1.7905, average_loss: 2.7511\n",
      "Epoch [50/50], Iter [70/439] Loss: 3.2444, average_loss: 2.7484\n",
      "Epoch [50/50], Iter [75/439] Loss: 2.2389, average_loss: 2.7288\n",
      "Epoch [50/50], Iter [80/439] Loss: 2.4835, average_loss: 2.7437\n",
      "Epoch [50/50], Iter [85/439] Loss: 4.0295, average_loss: 2.7643\n",
      "Epoch [50/50], Iter [90/439] Loss: 2.5435, average_loss: 2.7198\n",
      "Epoch [50/50], Iter [95/439] Loss: 1.3763, average_loss: 2.7151\n",
      "Epoch [50/50], Iter [100/439] Loss: 3.9896, average_loss: 2.7253\n",
      "Epoch [50/50], Iter [105/439] Loss: 2.5508, average_loss: 2.7308\n",
      "Epoch [50/50], Iter [110/439] Loss: 2.8901, average_loss: 2.7383\n",
      "Epoch [50/50], Iter [115/439] Loss: 1.9535, average_loss: 2.7423\n",
      "Epoch [50/50], Iter [120/439] Loss: 1.9278, average_loss: 2.7361\n",
      "Epoch [50/50], Iter [125/439] Loss: 0.9946, average_loss: 2.7483\n",
      "Epoch [50/50], Iter [130/439] Loss: 1.6480, average_loss: 2.7226\n",
      "Epoch [50/50], Iter [135/439] Loss: 3.0610, average_loss: 2.7008\n",
      "Epoch [50/50], Iter [140/439] Loss: 2.8163, average_loss: 2.7043\n",
      "Epoch [50/50], Iter [145/439] Loss: 2.6512, average_loss: 2.7418\n",
      "Epoch [50/50], Iter [150/439] Loss: 2.8116, average_loss: 2.7332\n",
      "Epoch [50/50], Iter [155/439] Loss: 2.6194, average_loss: 2.7551\n",
      "Epoch [50/50], Iter [160/439] Loss: 2.2806, average_loss: 2.7641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Iter [165/439] Loss: 3.4286, average_loss: 2.7485\n",
      "Epoch [50/50], Iter [170/439] Loss: 2.1364, average_loss: 2.7362\n",
      "Epoch [50/50], Iter [175/439] Loss: 2.2775, average_loss: 2.7487\n",
      "Epoch [50/50], Iter [180/439] Loss: 2.1377, average_loss: 2.7323\n",
      "Epoch [50/50], Iter [185/439] Loss: 4.5111, average_loss: 2.7407\n",
      "Epoch [50/50], Iter [190/439] Loss: 1.7424, average_loss: 2.7395\n",
      "Epoch [50/50], Iter [195/439] Loss: 2.3272, average_loss: 2.7256\n",
      "Epoch [50/50], Iter [200/439] Loss: 3.5129, average_loss: 2.7232\n",
      "Epoch [50/50], Iter [205/439] Loss: 2.6115, average_loss: 2.7231\n",
      "Epoch [50/50], Iter [210/439] Loss: 2.9024, average_loss: 2.7252\n",
      "Epoch [50/50], Iter [215/439] Loss: 2.5161, average_loss: 2.7278\n",
      "Epoch [50/50], Iter [220/439] Loss: 4.1887, average_loss: 2.7281\n",
      "Epoch [50/50], Iter [225/439] Loss: 2.9141, average_loss: 2.7312\n",
      "Epoch [50/50], Iter [230/439] Loss: 2.5351, average_loss: 2.7303\n",
      "Epoch [50/50], Iter [235/439] Loss: 1.3709, average_loss: 2.7311\n",
      "Epoch [50/50], Iter [240/439] Loss: 2.3668, average_loss: 2.7421\n",
      "Epoch [50/50], Iter [245/439] Loss: 2.0993, average_loss: 2.7461\n",
      "Epoch [50/50], Iter [250/439] Loss: 2.2559, average_loss: 2.7381\n",
      "Epoch [50/50], Iter [255/439] Loss: 3.2920, average_loss: 2.7275\n",
      "Epoch [50/50], Iter [260/439] Loss: 1.4722, average_loss: 2.7117\n",
      "Epoch [50/50], Iter [265/439] Loss: 2.6292, average_loss: 2.7134\n",
      "Epoch [50/50], Iter [270/439] Loss: 1.9286, average_loss: 2.7056\n",
      "Epoch [50/50], Iter [275/439] Loss: 2.2371, average_loss: 2.6963\n",
      "Epoch [50/50], Iter [280/439] Loss: 2.0126, average_loss: 2.6907\n",
      "Epoch [50/50], Iter [285/439] Loss: 2.6513, average_loss: 2.6900\n",
      "Epoch [50/50], Iter [290/439] Loss: 1.9271, average_loss: 2.6824\n",
      "Epoch [50/50], Iter [295/439] Loss: 1.3931, average_loss: 2.6918\n",
      "Epoch [50/50], Iter [300/439] Loss: 2.5200, average_loss: 2.6973\n",
      "Epoch [50/50], Iter [305/439] Loss: 1.8686, average_loss: 2.6911\n",
      "Epoch [50/50], Iter [310/439] Loss: 2.8849, average_loss: 2.6959\n",
      "Epoch [50/50], Iter [315/439] Loss: 1.7209, average_loss: 2.6932\n",
      "Epoch [50/50], Iter [320/439] Loss: 1.6844, average_loss: 2.6909\n",
      "Epoch [50/50], Iter [325/439] Loss: 3.8174, average_loss: 2.6930\n",
      "Epoch [50/50], Iter [330/439] Loss: 3.2408, average_loss: 2.6894\n",
      "Epoch [50/50], Iter [335/439] Loss: 2.8828, average_loss: 2.6816\n",
      "Epoch [50/50], Iter [340/439] Loss: 2.6718, average_loss: 2.6813\n",
      "Epoch [50/50], Iter [345/439] Loss: 2.1770, average_loss: 2.6966\n",
      "Epoch [50/50], Iter [350/439] Loss: 2.6915, average_loss: 2.6956\n",
      "Epoch [50/50], Iter [355/439] Loss: 2.1746, average_loss: 2.6971\n",
      "Epoch [50/50], Iter [360/439] Loss: 3.0837, average_loss: 2.6982\n",
      "Epoch [50/50], Iter [365/439] Loss: 3.3196, average_loss: 2.6944\n",
      "Epoch [50/50], Iter [370/439] Loss: 2.7108, average_loss: 2.7076\n",
      "Epoch [50/50], Iter [375/439] Loss: 2.4233, average_loss: 2.7065\n",
      "Epoch [50/50], Iter [380/439] Loss: 4.0001, average_loss: 2.7049\n",
      "Epoch [50/50], Iter [385/439] Loss: 2.8656, average_loss: 2.7033\n",
      "Epoch [50/50], Iter [390/439] Loss: 1.9814, average_loss: 2.7041\n",
      "Epoch [50/50], Iter [395/439] Loss: 5.3169, average_loss: 2.7138\n",
      "Epoch [50/50], Iter [400/439] Loss: 1.8016, average_loss: 2.7143\n",
      "Epoch [50/50], Iter [405/439] Loss: 2.8246, average_loss: 2.7191\n",
      "Epoch [50/50], Iter [410/439] Loss: 1.8490, average_loss: 2.7158\n",
      "Epoch [50/50], Iter [415/439] Loss: 2.2409, average_loss: 2.7152\n",
      "Epoch [50/50], Iter [420/439] Loss: 2.0918, average_loss: 2.7187\n",
      "Epoch [50/50], Iter [425/439] Loss: 4.3258, average_loss: 2.7231\n",
      "Epoch [50/50], Iter [430/439] Loss: 3.0620, average_loss: 2.7224\n",
      "Epoch [50/50], Iter [435/439] Loss: 1.5341, average_loss: 2.7224\n",
      "Test epoch [50/50], average_loss: 2.9271\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8 #64\n",
    "momentum = 0.9\n",
    "decay = 0.0005\n",
    "epochs = 50\n",
    "\n",
    "file_root = 'VOCdevkit/VOC2007/JPEGImages/'\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "def train():\n",
    "  ## model initiate\n",
    "  learning_rate = 0.001\n",
    "  yolov1 = ResNetYoloV1(50)\n",
    "  yolov1 = load_change_weights(yolov1, 'resnet50')\n",
    "\n",
    "  net = yolov1\n",
    "  net.cuda()\n",
    "  optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum = momentum, weight_decay=decay)\n",
    "  # load data\n",
    "  train_dataset = yoloDataset(root=file_root,list_file=file_root+'voc2007train.txt', train=True,transform = [transforms.ToTensor()] )\n",
    "  train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "  test_dataset = yoloDataset(root=file_root,list_file=file_root+'voc2007valid.txt',train=False,transform = [transforms.ToTensor()] )\n",
    "  test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "  print('the dataset has %d images' % (len(train_dataset)))\n",
    "  print('the batch_size is %d' % (batch_size))\n",
    "  # training process\n",
    "  criterion = yolov1Loss(GRID_NUM,2,20,5,0.5)\n",
    "  best_val_loss = np.inf\n",
    "  for ep in range(epochs):\n",
    "    net.train()\n",
    "    if ep >= 2:\n",
    "      learning_rate = 0.01\n",
    "    if ep >= 30:\n",
    "      learning_rate = 0.001\n",
    "    if ep >= 45:\n",
    "      learning_rate = 0.0001\n",
    "    for param_group in optimizer.param_groups:\n",
    "      param_group['lr'] = learning_rate\n",
    "    total_loss = 0.\n",
    "    total_data = 0.\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        target = Variable(target)\n",
    "        images,target = images.cuda(),target.cuda()\n",
    "        batch_size_this_iter = images.size(0)\n",
    "\n",
    "        pred = net(images)\n",
    "        loss = criterion(pred,target)\n",
    "        total_loss += loss.item()*batch_size_this_iter\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_data += batch_size_this_iter\n",
    "\n",
    "        if (i+1) % 5 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, average_loss: %.4f' \n",
    "            %(ep+1, epochs, i+1, len(train_loader), loss.item(), total_loss / total_data))\n",
    "            train_loss.append(total_loss / total_data)\n",
    "    #validation process\n",
    "    validation_loss = 0.0\n",
    "    net.eval()\n",
    "    for i, (images, target) in enumerate(test_loader):\n",
    "      images = Variable(images)\n",
    "      target = Variable(target)\n",
    "      images, target = images.cuda(), target.cuda()\n",
    "\n",
    "      pred = net(images)\n",
    "      loss = criterion(pred, target)\n",
    "      validation_loss += loss.item()\n",
    "    validation_loss/=len(test_loader)\n",
    "    print('Test epoch [%d/%d], average_loss: %.4f'%(ep+1, epochs, validation_loss))\n",
    "    valid_loss.append(validation_loss)\n",
    "    torch.save(net.state_dict(), os.path.join('model_latest.pth'))\n",
    "    if best_val_loss > validation_loss:\n",
    "        best_val_loss = validation_loss\n",
    "        torch.save(net.state_dict(), os.path.join('model_best.pth'))\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_loss)\n",
    "plt.title('model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2ut6a1Ztl24"
   },
   "source": [
    "## Evaluation on VOC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1664613052978,
     "user": {
      "displayName": "夏宇澄",
      "userId": "12299807091212530744"
     },
     "user_tz": -480
    },
    "id": "mZA3yMqntpBV"
   },
   "outputs": [],
   "source": [
    "'''import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"'''\n",
    "import numpy as np\n",
    "VOC_CLASSES = ('aeroplane', 'bicycle', 'bird', 'boat',\n",
    "        'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "        'cow', 'diningtable', 'dog', 'horse',\n",
    "        'motorbike', 'person', 'pottedplant',\n",
    "        'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "\n",
    "def voc_ap(rec,prec,use_07_metric=False):\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0.,1.1,0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec>=t])\n",
    "            ap = ap + p/11.\n",
    "\n",
    "    else:\n",
    "        # correct ap caculation\n",
    "        mrec = np.concatenate(([0.],rec,[1.]))\n",
    "        mpre = np.concatenate(([0.],prec,[0.]))\n",
    "\n",
    "        for i in range(mpre.size -1, 0, -1):\n",
    "            mpre[i-1] = np.maximum(mpre[i-1],mpre[i])\n",
    "\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "\n",
    "    return ap\n",
    "\n",
    "def voc_eval(preds,target,VOC_CLASSES=VOC_CLASSES,threshold=0.5,use_07_metric=False,):\n",
    "    '''\n",
    "    preds {'cat':[[image_id,confidence,x1,y1,x2,y2],...],'dog':[[],...]}\n",
    "    target {(image_id,class):[[],]}\n",
    "    '''\n",
    "    aps = []\n",
    "    for i,class_ in enumerate(VOC_CLASSES):\n",
    "        pred = preds[class_] #[[image_id,confidence,x1,y1,x2,y2],...]\n",
    "        if len(pred) == 0: #如果这个类别一个都没有检测到的异常情况\n",
    "            ap = -1\n",
    "            print('---class {} ap {}---'.format(class_,ap))\n",
    "            aps += [ap]\n",
    "            break\n",
    "        #print(pred)\n",
    "        image_ids = [x[0] for x in pred]\n",
    "        confidence = np.array([float(x[1]) for x in pred])\n",
    "        BB = np.array([x[2:] for x in pred])\n",
    "        # sort by confidence\n",
    "        sorted_ind = np.argsort(-confidence)\n",
    "        sorted_scores = np.sort(-confidence)\n",
    "        BB = BB[sorted_ind, :]\n",
    "        image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "        # go down dets and mark TPs and FPs\n",
    "        npos = 0.\n",
    "        for (key1,key2) in target:\n",
    "            if key2 == class_:\n",
    "                npos += len(target[(key1,key2)]) #统计这个类别的正样本，在这里统计才不会遗漏\n",
    "        nd = len(image_ids)\n",
    "        tp = np.zeros(nd)\n",
    "        fp = np.zeros(nd)\n",
    "        for d,image_id in enumerate(image_ids):\n",
    "            bb = BB[d] #预测框\n",
    "            if (image_id,class_) in target:\n",
    "                BBGT = target[(image_id,class_)] #[[],]\n",
    "                for bbgt in BBGT:\n",
    "                    # compute overlaps\n",
    "                    # intersection\n",
    "                    ixmin = np.maximum(bbgt[0], bb[0])\n",
    "                    iymin = np.maximum(bbgt[1], bb[1])\n",
    "                    ixmax = np.minimum(bbgt[2], bb[2])\n",
    "                    iymax = np.minimum(bbgt[3], bb[3])\n",
    "                    iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "                    ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "                    inters = iw * ih\n",
    "\n",
    "                    union = (bb[2]-bb[0]+1.)*(bb[3]-bb[1]+1.) + (bbgt[2]-bbgt[0]+1.)*(bbgt[3]-bbgt[1]+1.) - inters\n",
    "                    if union == 0:\n",
    "                        print(bb,bbgt)\n",
    "                    \n",
    "                    overlaps = inters/union\n",
    "                    if overlaps > threshold:\n",
    "                        tp[d] = 1\n",
    "                        BBGT.remove(bbgt) #这个框已经匹配到了，不能再匹配\n",
    "                        if len(BBGT) == 0:\n",
    "                            del target[(image_id,class_)] #删除没有box的键值\n",
    "                        break\n",
    "                fp[d] = 1-tp[d]\n",
    "            else:\n",
    "                fp[d] = 1\n",
    "        fp = np.cumsum(fp)\n",
    "        tp = np.cumsum(tp)\n",
    "        rec = tp/float(npos)\n",
    "        prec = tp/np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "        #print(rec,prec)\n",
    "        ap = voc_ap(rec, prec, use_07_metric)\n",
    "        print('---class {} ap {}---'.format(class_,ap))\n",
    "        aps += [ap]\n",
    "    print('---map {}---'.format(np.mean(aps)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1KOlUUMjoobF"
   ],
   "provenance": [
    {
     "file_id": "1TP-dps8rtpZ2G9mVvXEF7WXBuUV1oJFZ",
     "timestamp": 1662903786776
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
